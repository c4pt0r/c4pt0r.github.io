[{"content":"这次我分享的主题和 2019 年还是一样的——《The Future of Database》，如果你是 PingCAP 的老朋友，参加过之前几次 DevCon 就会知道，这是我的一个保留节目。如果要说我哪里有一些与众不同的气质，我觉得除了发型之外，还有一个是对技术的信仰和执著。这个保留节目我们还是聊聊技术。\n过去两年，**TiDB 在技术上发生的最大变化是什么？**可能有很多同学觉得性能变得越来越好，功能变得越来越多，生态功能越来越大，其实不是。\n从一个程序员角度看，在过去两年中 TiDB 其实完成了一个很重要的转变，那就是开发模式的转变。上图中左边是一个工程师对着屏幕在写代码，这是我们早年在第一个办公室里面开始写 TiDB 第一行代码的状态。旁边放了一瓶可乐和披萨，想到什么写什么。现在 TiDB 整个研发流程越来越像右边这张图，一个小工厂流水线化做月饼。虽然现在离中秋节还稍微有点距离，还是很可爱。\nTiDB 这两年最重要的一件事情，是研发流程以一个全新的发版模型去做软件工程，我们称它为“火车发版”模型。这个模型的特点，是我们会把很多大的 feature 以小的迭代进行逐步增量发布，意味着更易于管理发布周期。\n很多人可能会说“关我什么事？”，这件事情非常重要的意义在于，TiDB 从一个纯粹社区的开源软件开始慢慢变成面向企业级的数据库产品。说得再接地气一点，用户真实场景里面需要的 feature 最快两个月就能合并到 TiDB 的主干，并交付给用户。\n两年前，我的演讲题目也是《The Future of Database》，上图是两年前演讲的截图。向量化，当时这是一个挑战，现在已经完成了；TiFlash ，当时只是在草图上设计的一个架构，在 5.0 引入 MPP 后让它变成了一个真正的 Real-time HTAP 的数据库；IPC /异步提交，5.0 的性能和稳定性都得到了稳步提升；TiDB DBaaS，现在 TiDB Cloud 已经是服务千家万户，服务全球各个地方的真实产品；本地事务异地多活，两年时间也做完了。\n两年前的五大构想，今天都变成了现实。\n从 2019 年到现在的两年时间中，在**这些 feature 背后我们经历了什么？**是两年时间超过三万个 PR 的合并。人总是有成长的，两年前的我和现在的我区别是什么？发型没有变，T 恤也是一样的，变化的是 TiDB 合并了三万多个 PR。回头看我两年前的 PPT，我在思考一个问题，TiDB 的竞争力或核心优势是什么？很多数据库都说自己的核心优势是性能好、功能多。那么，TiDB 的优势是什么？\n两年前我的 PPT 里面有一页叫 Everything is Pluggable，我觉得特别有味道，**TiDB****的真正优势在于技术开放性。**架构开放就意味着能够产生更多的连接，更多连接意味着更快的迭代速度、更多的可能性。\n为什么 TiDB 的系统核心优势是开放性？大家可以花几秒钟时间去思考一下，这一个思考的角度，让我这两年慢慢开始变成一个哲学家。这个角度是：单机数据库和分布式数据库最本质的区别是什么？做分布式数据库的工程师的这些痛苦和幸福的根源在哪里？我们真正的敌人是什么？我们要解决什么样的问题？我们怎么解决这些问题？\n作为一个系统的设计者，在思考系统的时候，**我觉得我们真正的敌人是复杂性。**TiDB 这么一个几百万行代码的软件，跑在 3 台机器上，跑在 30 台、300 台、3 万台的服务器上还是这一套代码。大家想象一下， 3 台机器的复杂性和 3 万台机器的复杂性是一样的吗？\n我们生活中见过最复杂的系统是什么？就是活生生的生命，生命是最复杂的系统。包括每个人每天在和这个世界发生各种各样的交互，我们没有办法预料明天。我们去看生命这么一个复杂的系统，我们往里看人的生命最开始就是一个受精卵，细胞不停分裂，很简单。再往下看 DNA，排列组合，所以我觉得从生命和自身的角度看，才能真正找到解决对抗复杂性的办法，这就简单了。\n这里有肖邦老师的一句话，真正难的事情是把系统做简单，简单意味着美。TiDB 在这方面的设计理念和很多的常规做法还是有点不一样的，刚才我提到一句话，我们幸福和痛苦的根源在哪？刚才也提到我们是一个不一样的公司，技术上往深去思考我们到底和其他的数据库区别是什么？最根源的区别我觉得在于核心的设计理念，当理解了 TiDB 核心设计理念再去看 TiDB 的技术架构设计，有很多具体技术问题大家自然就能够想通了，也能想到为什么我们会这么做。\n左边这是一个惯常思维，1） 我要做一个数据库，2） 做一个分布式数据库会怎么做，3） 我试着把这些数据库上面的表给做分片，分区表，不同的分区放在不同的服务器上就是分布式了。\n我们过去从来没有做过数据库，但是我们有一个疯狂的想法，这个想法就是我们要做一个分布式数据库，我们开始是去定义数据最小的流转单元，像刚才看到的那张动图里面的细胞一样，我们去定义这些细胞的分裂、合并、移动，复制，繁殖。把这些规则用最极简，正交，自洽的规则赋予这些细胞生命，让这些细胞长成一个数据库，是 TiDB 最核心的理念。单机数据库和分布式数据库本质区别在什么，分布式数据库在一台台机器上是可以生长的。\n左边这张图解释了一下，常规是这样去设计，几乎所有的数据库都是从上往下设计的，TiDB 是一个 bottom-up 的设计，先定义底层细胞，在让它长成一个数据库的样子。\n下一个问题，让大家思考几秒钟，给大家铺垫一下，左边的名词，两地三中心，异地多活，跨地域数据分布能力，本地事务，动态热点打散，实时在线捞数，只读表。这些功能的共同点是什么？\n问：如果我要去实现这些功能该怎么去实现？这些功能背后的共同点是什么？有没有一个关键的点，解决了这个点所有能力都能马上拥有，有没有这样的东西？\n答案揭晓，刚才所有这些技术的名词和所有的这些刚才提到的用户看到的东西，背后都依赖一个能力就是“调度”，刚才我提到了那个问题，一个单机数据库，一个单机系统和分布式系统最本质的区别到底是什么？我给出答案是可调度能力，这是区别于单机系统最主要的能力。可调度能力是开放的基础，开放架构不能让这个数据库以不变应万变，这个万变就像把自己重塑成更适合用户的场景的数据库，如果没有这样的能力分布式系统就变得没有意义，就不能说自己是一个开放的系统。\n所以，这个其实是 TiDB 在技术架构上最核心最闪光的价值。今天聊技术，我们在可调度性上做了哪些事情，这是一盘大棋，不是一个 feature，这是一个理念，我们看这个理念过去现在和未来会长成什么样子。熟悉 Raft Proxy 技术的朋友，底层架构上，刚才我提到的细胞是基于 Raft 复制协议的复制组，这其实是我们整个调度最细粒度的单元，我们在这些一个个数据复制组上赋予它自我繁殖、分裂、合并、移动的能力。右边这张图有一个 Learner，用户会心一笑，选择这样的单元作为细胞是很合适的，每一个细胞的行为都是一样的，它是同构的。\n我们再放飞一下，原来 Learner 这个技术的第一次引用我们想给它找一个应用场景，这个应用场景就是 TiFlash，本来只是我们脑中一个小实验，我能不能在这个细胞上让它多复制一小块，让它干点别的事情? 当时，我们觉得 AP 能力不太强，需要底层数据存储列存的数据结构，我们把这个架构在副本上让它支持列存，于是 TiDB 就有了 HTAP 的能力，在这个基础上不到两年时间一个小团队把整个 Real-Time HTAP 这个系统就做出来了。\n为什么这么快做出来？TiFlash 是可调度性的理念绝佳的一个例子，而且我脑子里还有很多很奇怪的想法，Real-Time HTAP，TiFlash 只是开始。\n最细粒度的调度能力，可调度上的调度能力，我们再进一步往上看，有一些朋友熟悉 Foreign Data Wrapper（FDW），现在 TiDB 还不支持 Foreign Data Wrapper。这个功能比较好理解的一个说法，让 TiDB 把其他的数据源当作它内部一张表来进行查询，比如说当这个功能支持了以后，我可以把 Redis 作为 TiDB 中的一张外表，把 MySQL 数据作为一张外表，可以一起关联分析 HBase 这些数据。\n但是，FDW 意义仅仅停留在\u0026quot;联邦查询\u0026quot;吗？我在思考这个 feature 是为什么？因为我在看这个 feature 的时候联想到关于数据库的本质，数据库这种软件的本质是什么？**当你抛开所有的数据结构，存储的能力，抛开所有功能，数据库里面到底存了什么东西？**数据库把所有刚才我说的概念都剥离开，它只干两件事情，一是存储真实的数据，另外一部分是叫做索引，数据库无非就是数据和索引，怎么在这两种概念中辗转腾挪。按照刚才的思路把整个数据库当成数据和索引的容器，索引这个概念其实就是一种特殊映射的表关系，索引也是一张表，你要索引的内容对应到数据上的映射关系。\n那我们就跟着这个思路重新思考 FDW。右边是我的灵魂画风，有点难以看懂，今天整个数据库行业的趋势，其中一个趋势是各种各样的细分领域的数据库诞生，图数据库，向量搜索数据库，全文检索数据库，TiDB 能不能把这些数据库的能力变成它的索引能力？比如说我有一张表这里面存储着用户的关系，用户的信息，大家知道在一个关系上的搜索、查询用图的模型更好，如果是用传统的比如说我用索引的数据结构查询得很慢，用图模型可以极大加速这个性能。如果从这个角度去思考，TiDB 的索引能够接入其他的这些数据库，让其他的数据库作为 TiDB 的索引，同时以一个统一的接口给用户提供服务，是不是打开了新世纪大门的感觉？\n今天大会的主题是开放×连接×预见。\n我觉得特别有意思就是这个“×”号，我也不知道这些东西加进去以后能对 TiDB 的生态带来多大的可能性，任何人试图去预估它的价值都是傲慢的，我们能做的就是把这些基础给开发者打好，这是索引的部分。\n我们再把目光往下看，数据库的本质一个是数据，一个是索引，现在我们看数据，关于数据大家第一个联想就是存储引擎，数据的存储是最关键的一个话题。熟悉 TiDB 整体系统架构的同学肯定对左边这张灵魂画风的图不会陌生，刚才我提到 TiDB 在内部其实是把数据已经拆分成了无数个小小的细胞，每个细胞是一个复制组，分裂，合并，移动。但是在物理层面上存储我们现在是使用基于 Database 的 Real-time HTAP。TiKV 底层用的是 Rocks DB ，TiFlash 用的存储引擎我们命名叫 Delta tree，两种引擎。\n还能不能有更多？\n在存储上去体现开放性和可调度性的能力，有一个基础的前提就是对存储引擎进行抽象，熟悉 TiDB 的代码的同学如果去看它的代码仓库，发现有一个很有意思的文件夹叫Engine API，这件事情特别有意思，我直接把代码放上了，意思就是我们试图去对存储本身的能力进行抽象，这个抽象是一个基础。\n这个抽象的意义在哪？我们为什么做这件事情？我对未来的一个判断，为什么一般来说数据库技术负责人总会谈到性能、功能，为什么今天我们来讨论哲学？因为我觉得从更长的一个维度来看，当你的软件在保持高速迭代能力的时候，它是一个动态的进化过程，进化的终局是什么？\n先来看性能，在 TiDB 发展过程中，每一个版本都保持着 100% 性能提升的速度往前走，可以保持到 6.0，7.0 每次都是百分之百增长，未来优化是无止境的。我个人认为，不会说发明了一种新的硬件和算法解决了全世界所有应用场景的性能问题，粒度会变得越来越细，有一些优化用于某些具体场景，比如用来存用户的关联和关系就是图的模型最好。但是有一点，我觉得用户不用去关心他在使用什么样的数据库的结构，哪一块数据在使用哪一种数据结构，这些都不重要。\n右边的图透露了 TiDB 在做的巨大的一个事情，信息量非常大，我们做的事情，刚才 Engine API 的抽象让我们能做一件事情，熟悉 TiDB 的朋友都知道，我们在一台存储节点上是共享一个存储引擎，现在我们慢慢对每一块数据分片，每一个细胞让它能够自己拥有自己的存储引擎，这个事情在我们实验室里已经做完了，效果非常棒，当时都震惊了。\n下一步发展，当我把数据的细胞存储拆分了以后，下一步到底是不是 Delta tree 这件事情不重要了，比如我有一部分数据在业务场景里面一年只访问一次，但是不能丢，我又不希望用 SSD 来存，我能不能用云上 S3 的存储，甚至在一张表里面的一个数据特别热，对一致性要求没有那么高，是不是能在内存中对这一块数据的形态做一个变换。而且更有意思的是，这些所有的变换都是动态的，对业务都是透明的，回想刚才我说的可调度性和细胞这几个概念。\n我刚才说所有这些技术都是为了一件事情，都需要构建在一个基础上，刚才我说了分布式系统的终局，分布式系统可调度是它的核心优势，**这个基础我相信各位大概能够猜出是什么，我需要有一个近乎无限的弹性资源池，就是云。**关于云的重要性我觉得现在整个行业还在低估，现在天天说云，但是我觉得云其实是构建未来新一代软件的最重要的一个基石。\n我觉得对于云有一个很好的说法，我作为一个软件工程师看待云就像什么？我用了无限的资源，就像一堆积木我怎么去拼，手上有多少钱能拼成什么样子。右边这张图是 Flink 的架构，Flink 是一个很有意思的产品，它上市有各种各样的新闻，但是我最早注意到它是在 2016 年，它发表第一篇论文的时候，我看那篇论文，是我这几年最喜欢的论文之一，那篇论文更大意义在于它开创了一种新的软件设计的思路，开创了新的物种，基于云的服务去构建的基础软件，它是第一个，但绝对不是最后一个，TiDB 在这个领域是走在最前面的软件之一。\nTiDB 的核心思想，开放性体现在可插拔，存储和计算可插拔、可调度，借用今天主题“ × ”号，乘以调度能力，可插拔以后还能调度，细粒度，粗粒度调度，乘以云上几乎无限的资源它又等于什么。\n回顾一下我今天的题目，The Future Database，终极的 Future 是什么，这张图是我理想中的数据库的样子：底层各种各样的资源池，各种各样的云，公有云、私有云，混合云；上面中间逻辑这一层是数据平台，用户不同的业务不同数据，对数据库有不同要求，数据库会根据用户的需要自动去重塑自己；在不同的颗粒度上，从副本分布我们去做全球跨数据中心部署，这种能力对于 TiDB 来说工程代价并不是太高，刚我说调度能力，索引，我们通过 FDW 未来可以引入各种各样多种形态的索引。开了一个小小脑洞，图的数据库作为 TiDB 的索引，根据用户需求变换自己的形态。\n所以，大胆预测一下，刚才那个公式“可插拔性 × 调度能力 × 云上几乎无限的资源 = ？”，数据库作为一个独立的软件形态我认为会被颠覆，同时意味着整个数据库的“数据服务平台化”会崛起，我们下一代很多在场的各位为人父母，下一代的小朋友可能到他们写程序的年纪，可能不知道什么是 CPU，什么是内存，什么是磁盘，什么是操作系统，可能看到的就是一个个云服务，比如要用数据库的时候好象有一个 TiDB 的东西，我把信用卡绑上去之后就可以直接用一个 SQL 的接口里操作就完了，不需要知道什么叫索引， 什么叫 Delta tree。\n我们回头看一下今天我们大会三个关键字，开放，连接，预见，只有开放的架构才能有更多连接，更多的连接才能让我们有更好未来，这是今天我关于 TiDB 的技术和设计理念的分享。\n","permalink":"http://c4pt0r.github.io/posts/the-future-of-db-2021/","summary":"这次我分享的主题和 2019 年还是一样的——《The Future of Database》，如果你是 PingCAP 的老朋友，参加过之前几次 DevCon 就会知道，这是我的一个保留节目。如果要说我哪里有一些与众不同的气质，我觉得除了发型之外，还有一个是对技术的信仰和执著。这个保留节目我们还是聊聊技术。\n过去两年，**TiDB 在技术上发生的最大变化是什么？**可能有很多同学觉得性能变得越来越好，功能变得越来越多，生态功能越来越大，其实不是。\n从一个程序员角度看，在过去两年中 TiDB 其实完成了一个很重要的转变，那就是开发模式的转变。上图中左边是一个工程师对着屏幕在写代码，这是我们早年在第一个办公室里面开始写 TiDB 第一行代码的状态。旁边放了一瓶可乐和披萨，想到什么写什么。现在 TiDB 整个研发流程越来越像右边这张图，一个小工厂流水线化做月饼。虽然现在离中秋节还稍微有点距离，还是很可爱。\nTiDB 这两年最重要的一件事情，是研发流程以一个全新的发版模型去做软件工程，我们称它为“火车发版”模型。这个模型的特点，是我们会把很多大的 feature 以小的迭代进行逐步增量发布，意味着更易于管理发布周期。\n很多人可能会说“关我什么事？”，这件事情非常重要的意义在于，TiDB 从一个纯粹社区的开源软件开始慢慢变成面向企业级的数据库产品。说得再接地气一点，用户真实场景里面需要的 feature 最快两个月就能合并到 TiDB 的主干，并交付给用户。\n两年前，我的演讲题目也是《The Future of Database》，上图是两年前演讲的截图。向量化，当时这是一个挑战，现在已经完成了；TiFlash ，当时只是在草图上设计的一个架构，在 5.0 引入 MPP 后让它变成了一个真正的 Real-time HTAP 的数据库；IPC /异步提交，5.0 的性能和稳定性都得到了稳步提升；TiDB DBaaS，现在 TiDB Cloud 已经是服务千家万户，服务全球各个地方的真实产品；本地事务异地多活，两年时间也做完了。\n两年前的五大构想，今天都变成了现实。\n从 2019 年到现在的两年时间中，在**这些 feature 背后我们经历了什么？**是两年时间超过三万个 PR 的合并。人总是有成长的，两年前的我和现在的我区别是什么？发型没有变，T 恤也是一样的，变化的是 TiDB 合并了三万多个 PR。回头看我两年前的 PPT，我在思考一个问题，TiDB 的竞争力或核心优势是什么？很多数据库都说自己的核心优势是性能好、功能多。那么，TiDB 的优势是什么？\n两年前我的 PPT 里面有一页叫 Everything is Pluggable，我觉得特别有味道，**TiDB****的真正优势在于技术开放性。**架构开放就意味着能够产生更多的连接，更多连接意味着更快的迭代速度、更多的可能性。\n为什么 TiDB 的系统核心优势是开放性？大家可以花几秒钟时间去思考一下，这一个思考的角度，让我这两年慢慢开始变成一个哲学家。这个角度是：单机数据库和分布式数据库最本质的区别是什么？做分布式数据库的工程师的这些痛苦和幸福的根源在哪里？我们真正的敌人是什么？我们要解决什么样的问题？我们怎么解决这些问题？","title":"[演讲] The Future of Database 2021"},{"content":"今天的文章我想从这张模糊的照片说起，相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次「看到」了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓「一图胜千言」很多时候一张图传达的信息超过千言万语。 关于黑洞我不想展开太多，今天我们聊聊「望远镜」。\n前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此，在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」，过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。\n举几个直观的小例子，你知道 TPC-C 测试「长」什么样子吗？请看下图：\n图中横轴是时间，纵轴是数据的分布，左半部分有零星的亮点，是数据导入的过程，，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的局部访问热点（最亮的那条线）。 第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面:\n左边比较密集的明亮黄块是导入数据阶段，右半段明暗相间的部分是进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。 如果你看懂了上面两个小例子，下面是一个小作业，这是我们模拟的一个实际用户的生产环境的照片，这个用户的系统遇到了一些瓶颈，你能看出问题吗？\n上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。\n顾名思义，分布式数据库，数据一定是分散在不同机器上的，对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。\n和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。\n现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。 然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？ 过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但是很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的，再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。有经验一些的 DBA 可能能从多个指标里通过自己的经验，模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维，老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。现代医学有 CT 有 B 超有核磁共振，这些现代化的手段极大的促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断，在计算机的世界道理也是相通的，最好通过某些工具让人更清晰的看到系统运行的健康状态、帮助诊断“病灶”，从而降低经验门槛和不确定性。 过去经常有朋友问我：「你说我这个业务适不适合使用 TiDB？」这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。有些信息可能是敏感的，也不方便共享。所以“预判 TiDB 到底适不适合某类业务”就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统都或多或少有类似的问题。 在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：\n这个坐标描述了一个我们对系统的理解程度和可收集信息的关系，在 X 轴的右侧（Known Knows 和 Known Unknowns）这些称为确定性的已知和未知，图中也给出了相对应的例子，这些信息通常是最基础的普适的事实，也就是在系统上线之前我们一定就能想到，一定能够监控起来的（CPU Load，内存，TPS，QPS之类的），我们过去已有的大多数运维监控都是围绕这些确定的东西。 但是有一些情况是这些基础信息很难描述和衡量的，例如这个坐标的左上角：Unknown Knowns，用通俗的话来说，叫做「假设」。举个数据库的例子：有经验的架构师在设计一个基于分布式数据库的应用时，通常不会将表的主键设成自增主键，会尽可能的用 UUID 或者其他方式打散数据，这样在即使有突发写入压力的时候，系统也能很好的扩展。 注意在这个例子中，其实假设的事情（写入压力突然增大）并没有发生，如果在日常压力不大，数据量不多的情况下，即使使用自增主键，从已有的基础监控中，可能也很难看出任何问题。但是到出事的时候，这个设计失误就会变成 Unknown Unkowns（意外），这是任何人都不想看到的。有经验的架构师能通过种种的蛛丝马迹证实自己的推测，也从无数次翻车的 Post-mortem 中将 Unknown Unknowns 的范围变小。但是更合理的做法是通过技术手段描绘系统更全面的状态，在 Cloud Native 和微服务的世界里，最近几年一个行业的大趋势是将系统的可观测性放在一个更高的位置（监控只是可观测性的一个子集），这是有道理的。\n回到数据库的世界，TiDB KeyViz 的意义在于，就像上面提到的，这个工具不仅仅是一个监控工具，而且它能以一个非常低门槛且形象的方式让架构师具象化的看到自己对于业务的「假设」是否符合预期，这些「假设」不一定是能够通过监控反映的，以获得对业务更深刻的 Insight。 还是说回上面那个主键的小例子，对于两种不同的主键设计，KeyViz 这边是怎么表现的呢？看看下面两张图，是不是非常一目了然。\n所以现在如果有朋友问我，这个业务适不适合 TiDB？我只需要通过录制线上流量，或者搭建一个从集群，只需要把 KeyViz 的图给我看一眼，我甚至都不需要压力测试就能判断这个业务是否适合，而且即使不适合，我也能准确的给出修改建议，因为 KeyViz 的图对我的「假设」的可解释性有了很强的支持。 不妨从这个方向我们再放飞一下想象力，为什么人类能够一眼就从这图片中理解这些信息，这说明这些图形背后有模式，有模式我们就可以识别，想象一下，如果所有的 TiDB 用户，都使用 KeyViz 将自己的系统具象化后分享出来（其实这些图片已经高度抽象，已经不具有任何的业务机密信息），我们是不是可以通过机器学习，挖掘背后更深层次的价值？AI 能不能通过这种形式更加理解我们的业务？\n最后，我想以我最喜欢的科幻小说《三体：黑暗森林》中的一段话结束这篇文章，大致是面壁人希恩斯在冬眠后被妻子唤醒后的一个场景： 「\u0026hellip;与此同时，希恩斯感觉到围绕着他们的白雾发生了变化，雾被粗化了，显然是对某一局部进行了放大。他这时发现所谓的雾其实是由无数发光的小微粒组成的，那月光般的光亮是由这些小微粒自身发出的，而不是对外界光源的散射。放大在继续，小微粒都变成了闪亮的星星。希恩斯所看到的，并不是地球上的那种星空，他仿佛置身于银河系的核心，星星密密麻麻，几乎没有给黑夜留出空隙。　“每一颗星星就是一个神经元。”山杉惠子说，一千亿颗星星构成的星海给他们的身躯镀上了银边。」\n","permalink":"http://c4pt0r.github.io/posts/observability-keyviz/","summary":"今天的文章我想从这张模糊的照片说起，相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次「看到」了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓「一图胜千言」很多时候一张图传达的信息超过千言万语。 关于黑洞我不想展开太多，今天我们聊聊「望远镜」。\n前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此，在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」，过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。\n举几个直观的小例子，你知道 TPC-C 测试「长」什么样子吗？请看下图：\n图中横轴是时间，纵轴是数据的分布，左半部分有零星的亮点，是数据导入的过程，，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的局部访问热点（最亮的那条线）。 第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面:\n左边比较密集的明亮黄块是导入数据阶段，右半段明暗相间的部分是进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。 如果你看懂了上面两个小例子，下面是一个小作业，这是我们模拟的一个实际用户的生产环境的照片，这个用户的系统遇到了一些瓶颈，你能看出问题吗？\n上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。\n顾名思义，分布式数据库，数据一定是分散在不同机器上的，对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。\n和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。\n现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。 然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？ 过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但是很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的，再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。有经验一些的 DBA 可能能从多个指标里通过自己的经验，模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维，老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。现代医学有 CT 有 B 超有核磁共振，这些现代化的手段极大的促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断，在计算机的世界道理也是相通的，最好通过某些工具让人更清晰的看到系统运行的健康状态、帮助诊断“病灶”，从而降低经验门槛和不确定性。 过去经常有朋友问我：「你说我这个业务适不适合使用 TiDB？」这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。有些信息可能是敏感的，也不方便共享。所以“预判 TiDB 到底适不适合某类业务”就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统都或多或少有类似的问题。 在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：","title":"我眼中的分布式系统可观测性"},{"content":"作为一个在中国的数据库软件从业者，最近被不少朋友在微信上询问业内某厂商「团队整合」的新闻，我其实并不想对这个事情发表什么评论。我始终坚信：基础软件，未来只有开源一条路。如果不开源，或者说内核不开源的话，产品的生命力是有限的。所以，在这里想分享一些我个人有关开源与闭源的看法，希望大家看完这篇文章后能够有些自己的思考 :）\n顺便提一下，看到这个标题，熟悉开源运动的朋友肯定会心一笑，没错，作为 ESR 的门徒，我从不掩饰对于《大教堂与集市》这篇著作的喜爱。另外作为从事开源的创业者，这几年的实践让我们对于 ESR 的这本书的理解更加的深入，我会试着在这篇文章总结一些我们经常被问到的问题，最后一部分我斗胆给 ESR 的理论在当今云时代的背景下做一些修订，另外我们讨论的软件范围仅限于基础软件（数据库，编译器，操作系统等）。\n一、代码是核心竞争力吗？ 我和一些闭源软件项目的作者聊过，大多数选择闭源的原因不外乎以下几种：\n 觉得自己的核心算法非常厉害，不希望竞争对手模仿 担心用户拿到代码，就不给钱了 没有找到或者建立自己的护城河 代码太丑，不好意思开源 怕被人找到 Bug  其中以前三种答案居多，我非常能理解，这些回答也都是非常正当的理由，只是这篇文章我们好好的就事论事的挨个分析一下，对于第四第五个理由，其实我不想过多展开，我们聊聊前两种，先看第一种，我在后边会聊聊第二种。\n对于第一种原因，我们再深入思考一下，一般可能有下面两种情况：\n 我的核心代码很短，可能是一个很巧妙的算法，或者一套很巧妙的参数 我的工程上的设计和实现得很优秀，系统架构是领先的  ● 对于第一种情况，我一直以来的观点是：如果在同一个行业里面，除非你达到了彻彻底底的人才垄断，那么在一个充分竞争的环境，如果这个问题是一个高价值问题，那么你能想到的短短的 「核心算法」，别人也同样能想得到。天下没有银弹，计算机科学就是在无数种妥协和不完美中寻找平衡的艺术（当然，图灵奖级别的 idea 或者量子计算机这种现象级的东西另说，但是这种机会是很少见的），即使通过闭源创造出短期的垄断优势，但是这个平衡一定会被另一个竞争对手打破，最终也一定会出现一个优质的开源替代品全部吞掉（这个开源事实标准短期看甚至不一定是更好的）。\n其实多数的产品优势是体现在工程实现上，也就是上面的第二种，一群优秀的工程师，在正确的设计下，构建出优质的软件。对于这种情况，无论开源还是不开源，竞争对手都没有办法很好的模仿，就像一个学霸，考了一个100分的答卷，把这个答卷给一个学渣看，学渣朋友肯定也没法马上变成学霸，因为代码只是结果，是什么样的思考和选择得到了这个结果，这个过程是没法开放的，所谓知其然不知其所以然，当然，就算你也很厉害，也有一批优秀工程师，短时间也做出了一个不错的产品，但是没关系，结局和前面提到那种情况也是一样的：只要你是闭源的，这个问题又足够普遍且高价值，那么长远来看一定会有一个开源的解决方案吞掉一切。这背后的原因其实和代码没有什么关系，因为代码在这里其实并不是核心竞争力。关于前面提到的第三种理由，我认为是和第一种类似，作者可能认识到代码并不一定是核心竞争力，但是没有构建好护城河的情况下，只能选择将代码作为护城河。\n二、代码不是核心竞争力，那什么才是？ 在聊真正的核心竞争力之前，我们来聊聊闭源软件的局限性。\n我们看看一个闭源的软件的一生：立项的动机可能是某个公司或者个人对于一个市场机会的洞见找到了一个高价值的场景，通过开发一个软件能够很好的提高效率或创造价值，甚至可能就是一张来自甲方的合同，总之这个公司招募了一伙程序员，设计师，产品经理，开始项目的开发。一切顺利的情况，顺利的满足了甲方的需求，甲方也很开心的付钱了，然后这个公司发现，好像这个软件改一改（甚至不用改）也就能够在同行业另一个客户那边卖出去，这就太好了，感觉找到了一条致富路。可是好境不长，客户这边的场景和需求在变化，原来的软件可能不一定能够满足新的需求了，但是开发团队就这几杆枪，稍有不慎一个方向判断错误，可能时间和机会窗口就错过了。这就意味着，对于项目领头人的要求就很高，要求持续能够引领行业的方向。还有一种方式是挑选一个相对狭窄或迭代不快的领域，存活时间能够延长一些。对于甲方也很难受，总是感觉需求的满足慢半拍，甚至对于有些有着研发能力的甲方，因为受限于没有源码，就算知道如何改进，也只能干瞪眼。\n其实这个问题的本质在于：闭源软件开发商虽然可能是技术的专家，但是并不一定是业务或者场景的专家，软件进化的速度受限于开发团队和产品经理自己的认知和见识的进化速度，除非开发商强大到能够持续引领整个行业的进化方向，否则无解。\n其实这个问题，教员早就给出了答案：「\u0026hellip;凡属正确的领导，必须是从群众中来，到群众中去。这就是说，将群众的意见（分散的无系统的意见）集中起来（经过研究，化为集中的系统的意见），又到群众中去作宣传解释，化为群众的意见，使群众坚持下去，见之于行动，并在群众行动中考验这些意见是否正确。然后再从群众中集中起来，再到群众中坚持下去，如此无限循环，一次比一次地更正确、更生动、更丰富\u0026hellip;」 \u0026mdash; 《关于领导方法的若干问题》, 1943\n要我说教员放在当代，就算是当个程序员，也能是一个大师级别的。教员的这段话，包含两个关键的点，完美的解释了开源软件的生命力的来源，我下面的详细讲讲。\n第一点，开源软件的生命力来自于场景的垄断，而背后更本质的垄断是人才垄断。\n为什么强调从群众中来？回顾刚才我们闭源软件的那段，其实一个关键的点是，软件的初始动机虽然来自于少数人的洞见，但是持续保持洞见并不是一件容易的事情，这就是为什么很多技术团队或者产品团队容易「自嗨」，一旦脱离用户，极易出现这样的问题。闭源软件厂商触及用户的手段不外乎于传统的商业宣传和销售，用户从感兴趣到使用起来的门槛很高，实施的周期也很长，另外通常销售会站在产品团队和客户中间，通过一些信息不对称来获取超额的利润，其中最大的信息不对称就是封闭的源代码本身或者定制化。这导致的问题是，相比流行的开源软件，闭源软件没有办法高效的获取，吸收和理解更多的场景，这对于一个通用的基础软件产品来说通常是一个致命的问题，如果见过的场景不够多，更没有办法判断产品那些需求该做是普遍需求，哪些是伪需求坚决不做，我认为这就是做产品的「触感」。\n对于一个流行的开源软件，本身不会有上面提到的问题：因为有足够多的用户，那么一定能看到足够多的场景，也能看到足够多的稀奇古怪的用法，这一个个用户的反馈，修过的一个个 bug，提出的一个个建议，会持续的产生类似「复利」的效果，你的软件越强壮，见过的场景越广，会进一步让你接触到更大的用户群，帮助软件变得更强大，如此循环。实际上开源软件本质上是通过放弃一部分通过信息不对称产生的潜在利润，换取了极其高效的传播和场景触及效率，但是有意思的是，实际上牺牲掉的这些潜在利润大概率也不一定真的牺牲掉，一来可能本身付费能力有限，二来可能实际上这些用户通过宣传站台二次传播或者代码贡献等方式回馈了项目本身。\n在上面那个过程中还会产生一个更加厉害的效应：人才的垄断。正所谓「事在人为」，上面提到的场景垄断中种种的技术决策和实践都是人来操作的。一个流行的开源软件在变成事实标准的过程中，一定会培养出大量熟悉这个产品的工程师，用户，摇旗呐喊的粉丝，代码贡献者，甚至挑刺吐槽的人。传统意义上，大家理解的开源社区只是狭义上的开发者社区，只有贡献代码才算参与，但是我认为只要和这个产品发生关联的人，都算是社区的一部分，「人尽其材」才是构建开源社区的终极目标。这个优势是会随着时间的流逝不断累积，这个很好理解，举个例子：A 公司的工程师在 A 公司的工作中学习使用了 TiDB 也很好的解决了问题，然后这个工程师作为数据库专家跳槽到了 B 公司，遇到同样的问题时，你猜他会选什么？ :)\n第二点，迭代，迭代，迭代，只有高速迭代才能立于不败之地\n上面教员的话里面有个关键的点，关于正向循环，也就是迭代。这个道理同样也适用于软件开发，软件从来都不是静止的，随着市场和竞争环境的变化，你今天的竞争优势，很可能明天就不是了。很多人都喜欢用静态的眼光看待问题，热衷于各种方案的横向对比，而忽略了进化速度，在这点上，我可能更看重的是同一个产品的纵向对比，举个例子：目前有 A, B, C三个方案，可能当下看这三个方案差距不大，也许在百分之五十之内。但是如果其中一个开源方案每次和自己半年前比都是在翻倍的提升（背后开源社区推动），但是闭源的方案的进步受限于团队规模和资源。这时候的选择除非是那种火烧眉毛的情况，否则一定应该选择一个迭代速度更快，增长率更好，更代表未来的方案，这个也很好理解。这是人的思维的一个惯性，人总是倾向用线性思维去看待问题，于是对非线性增长的事物往往会习惯性的低估。\n说一个更加震撼的例子，我粗略统计了一下，从 2018 到现在，也就短短一年多时间，整个 TiDB 的 SQL 层这么一个项目发生了 30000 多次提交，有接近 60% 的源码被修改。也就是说，每一年的 TiDB 都和上一年是不一样的，是一个更适应当下的，更加进步的一个 TiDB，而且随着社区的不断壮大，迭代的速度会越来越快。我完全不能想象，如果 TiDB 是一个闭源软件，从第一行代码开始写，到现在短短的 5 年时间，如何能够到达现在这个成熟度，这一切都是得益于开源社区的带来的加速度和反复迭代。\n三，如何挣钱？未来在云端 刚才我们聊了很多产品哲学上的东西，我们接下来聊聊商业，以及在云时代开源软件的位置。让我们回到开篇提到的那个话题：担心用户拿到代码，就不给钱了。这个观点背后的一个暗示是，用户付费买的是代码，如果有代码，用户就没有其他理由付钱。其实这个结论是靠不住的，**客户付费买的是解决问题和创造价值，而不是代码，如果拿到你的代码自己折腾付出的成本大于给你的钱（如果你能如实交付价值的话），用户没有任何理由不付钱。**而且这里的成本包括，比较明显的成本，例如人力成本，机器成本。也包括一些经常被人忽略的成本，例如错失市场机会的沉没成本，业务改造迁移成本，学习成本，线上出问题没人懂修带来的风险成本，这些隐性的成本往往是比显性的成本高得多的。\n上面我的解释中暗示了一点：软件的价值取决于它解决了什么问题，创造了什么价值，而不是开源与否。举个例子：一个分布式关系性数据库，一定比一个分布式缓存更加有商业价值，这是由前者的应用场景，存储的数据以及提供的能力决定的，而不是开源与否。所以这就是为什么我们要做通用数据库的核心原因，因为价值天花板更高。\n还有一点需要强调的，开源并不是一个商业模式，而是一种更好的软件开发和分发模式。另外，我认为商业模式和软件本身一样，也是需要设计的，这个设计取决于产品特性和公司的属性，这就意味着适用于 A 产品的商业模式，不一定适用于 B，甚至同一个产品，不同的公司，可能适合的商业模式都是不一样的。\n● 用我很崇敬的华为公司举个例子，华为是一个很厉害的通信设备制造商，很成功的手机终端厂商，很成功的硬件厂商。卖通信设备，卖手机，卖服务器，大家发现共性了吗？ 华为很会卖硬件和盒子，巨大的商业成功带来了很大的惯性，硬件和通讯设备的市场的特点是：各家产品本身能力差不太多（至少没有代差），比拼的是满足客户其他需求的能力以及低价（例如：服务，更快的响应，充分的定制化）。所以不难理解，华为软件的思路会通过低价甚至软件免费进入客户场景，然后通过硬件获取利润的商业模式。这个模式的问题在于，客户不能多，一旦战线拉得太长，项目的预算和硬件的利润都没有办法的抹平定制化软件的研发成本和支持成本时，这个模式就会出现问题。\n我认为如果想要通过软件创造可规模化的持续利润，需要两个关键点：\n 生态，软件能形成生态或者和现有生态有机整合，由生态补齐单一产品的能力，从而才能进一步能形成解决方案。 渠道，高效的分发渠道和支持渠道，这确保在用户规模化后，作为厂商的销售和售后成本不会随着客户的增长而增长（至少成本增长的斜率需要更缓）。  两者缺一不可。对于第一点，开源软件构建生态是很天然的，开发者和解决方案提供商会很自然的通过不同开源软件的组合做到解决方案的覆盖，这个效率是闭源定制化软件很难跟上的，这点不赘述。\n第二点，其实理想的渠道就是云。云标准化了硬件，标准化了计算力，甚至标准化了计算力的交付方式，尤其是公有云。一切都是标准化的好处就是可以自动化，这个对于软件供应商来说才是真正的价值。\n所以开源 + 云的模式，在开源这端，完成了开发者的心智占领和解决方案的成型，然后在云这端完成极其高效的分发和价值传递。看上去很美不是吗？理论上确实没问题，但是一定会有朋友挑战我说：这个模式里面没有你们开源软件厂商什么事情啊？云为什么不自己提供开源软件服务？这几年沸沸扬扬的 AWS 吸血事件逼得一堆开源公司和项目改协议，就是一个例子呀。\n关于这个问题，我的看法可能和主流观点有点不一样：\nCloud is eating Open-source? No, Open-source is eating the cloud.\n云厂商就像当年的运营商一样，占据着和客户对接的第一位置，当然很自然的在关键路径上放自家的产品。但是移动梦网和飞信的故事后来大家都看到了，拿飞信做一个例子，大家还记得作为移动的飞信，当年是没有办法和联通电信的手机号码互通的，直到后来微信的出现，终于事实上打通了各个运营商，所以市场格局就出现了很明显的分水岭，运营商是谁不重要，只要保证网络通信号好就行。对于云也是一样，AWS 肯定不会为 GCP 提供舒服的迁移和打通方案，反过来也不可能，但是对于客户来说，这个选择就像逼着用户选移动的飞信还是联通的沃友一样（我猜你可能都没听说过沃友吧 :) ），用户肯定说：不好意思，两个都不要，我选微信。从另一方面来说，对于在云上提供开源软件服务这件事情，云厂商本身的投入其实不一定有这个开源项目背后的公司多，一个很好的例子是 Databricks 是 Spark 创始团队的公司，也是一个 100% 在 AWS 上提供 Spark 服务的公司，相比起 AWS 的官方 EMR，Databricks 完全不占下风甚至客户和产品都胜过原生的 EMR。就像飞信的开发团队的质量肯定没有微信高，是一样的。\n由于开源软件的中立性，使得开源软件成为用户在多个云厂商之间保持统一体验和统一服务的几乎唯一选项。因为开源软件和开源服务商的存在，市场我相信会进入一个平衡：云厂商会持续优化它擅长的东西，真正的将云基础能力变成水电煤一样的规模化生意，开源软件厂商基于云的标准基础设施构建服务并交付业务价值，开源软件项目和社区由于厂商的持续持续，不断的蓬勃发展，占领更多用户的心智。三者形成一个价值链的闭环。不要着急，让子弹飞一会儿。\n洋洋洒洒写了几千字，聊了聊开源，最后我想用一段《大教堂与集市》书里我很喜欢的一句话作为结尾：\n「**\u0026hellip;Often, the most striking and innovative solutions come from realizing that your concept of the problem was wrong\u0026hellip;\n\u0026hellip;通常，那些最有突破性和最有创新力的解决方案来自于你认识到你对问题的基本观念是错的\u0026hellip;**」\n","permalink":"http://c4pt0r.github.io/posts/oss-in-china/","summary":"作为一个在中国的数据库软件从业者，最近被不少朋友在微信上询问业内某厂商「团队整合」的新闻，我其实并不想对这个事情发表什么评论。我始终坚信：基础软件，未来只有开源一条路。如果不开源，或者说内核不开源的话，产品的生命力是有限的。所以，在这里想分享一些我个人有关开源与闭源的看法，希望大家看完这篇文章后能够有些自己的思考 :）\n顺便提一下，看到这个标题，熟悉开源运动的朋友肯定会心一笑，没错，作为 ESR 的门徒，我从不掩饰对于《大教堂与集市》这篇著作的喜爱。另外作为从事开源的创业者，这几年的实践让我们对于 ESR 的这本书的理解更加的深入，我会试着在这篇文章总结一些我们经常被问到的问题，最后一部分我斗胆给 ESR 的理论在当今云时代的背景下做一些修订，另外我们讨论的软件范围仅限于基础软件（数据库，编译器，操作系统等）。\n一、代码是核心竞争力吗？ 我和一些闭源软件项目的作者聊过，大多数选择闭源的原因不外乎以下几种：\n 觉得自己的核心算法非常厉害，不希望竞争对手模仿 担心用户拿到代码，就不给钱了 没有找到或者建立自己的护城河 代码太丑，不好意思开源 怕被人找到 Bug  其中以前三种答案居多，我非常能理解，这些回答也都是非常正当的理由，只是这篇文章我们好好的就事论事的挨个分析一下，对于第四第五个理由，其实我不想过多展开，我们聊聊前两种，先看第一种，我在后边会聊聊第二种。\n对于第一种原因，我们再深入思考一下，一般可能有下面两种情况：\n 我的核心代码很短，可能是一个很巧妙的算法，或者一套很巧妙的参数 我的工程上的设计和实现得很优秀，系统架构是领先的  ● 对于第一种情况，我一直以来的观点是：如果在同一个行业里面，除非你达到了彻彻底底的人才垄断，那么在一个充分竞争的环境，如果这个问题是一个高价值问题，那么你能想到的短短的 「核心算法」，别人也同样能想得到。天下没有银弹，计算机科学就是在无数种妥协和不完美中寻找平衡的艺术（当然，图灵奖级别的 idea 或者量子计算机这种现象级的东西另说，但是这种机会是很少见的），即使通过闭源创造出短期的垄断优势，但是这个平衡一定会被另一个竞争对手打破，最终也一定会出现一个优质的开源替代品全部吞掉（这个开源事实标准短期看甚至不一定是更好的）。\n其实多数的产品优势是体现在工程实现上，也就是上面的第二种，一群优秀的工程师，在正确的设计下，构建出优质的软件。对于这种情况，无论开源还是不开源，竞争对手都没有办法很好的模仿，就像一个学霸，考了一个100分的答卷，把这个答卷给一个学渣看，学渣朋友肯定也没法马上变成学霸，因为代码只是结果，是什么样的思考和选择得到了这个结果，这个过程是没法开放的，所谓知其然不知其所以然，当然，就算你也很厉害，也有一批优秀工程师，短时间也做出了一个不错的产品，但是没关系，结局和前面提到那种情况也是一样的：只要你是闭源的，这个问题又足够普遍且高价值，那么长远来看一定会有一个开源的解决方案吞掉一切。这背后的原因其实和代码没有什么关系，因为代码在这里其实并不是核心竞争力。关于前面提到的第三种理由，我认为是和第一种类似，作者可能认识到代码并不一定是核心竞争力，但是没有构建好护城河的情况下，只能选择将代码作为护城河。\n二、代码不是核心竞争力，那什么才是？ 在聊真正的核心竞争力之前，我们来聊聊闭源软件的局限性。\n我们看看一个闭源的软件的一生：立项的动机可能是某个公司或者个人对于一个市场机会的洞见找到了一个高价值的场景，通过开发一个软件能够很好的提高效率或创造价值，甚至可能就是一张来自甲方的合同，总之这个公司招募了一伙程序员，设计师，产品经理，开始项目的开发。一切顺利的情况，顺利的满足了甲方的需求，甲方也很开心的付钱了，然后这个公司发现，好像这个软件改一改（甚至不用改）也就能够在同行业另一个客户那边卖出去，这就太好了，感觉找到了一条致富路。可是好境不长，客户这边的场景和需求在变化，原来的软件可能不一定能够满足新的需求了，但是开发团队就这几杆枪，稍有不慎一个方向判断错误，可能时间和机会窗口就错过了。这就意味着，对于项目领头人的要求就很高，要求持续能够引领行业的方向。还有一种方式是挑选一个相对狭窄或迭代不快的领域，存活时间能够延长一些。对于甲方也很难受，总是感觉需求的满足慢半拍，甚至对于有些有着研发能力的甲方，因为受限于没有源码，就算知道如何改进，也只能干瞪眼。\n其实这个问题的本质在于：闭源软件开发商虽然可能是技术的专家，但是并不一定是业务或者场景的专家，软件进化的速度受限于开发团队和产品经理自己的认知和见识的进化速度，除非开发商强大到能够持续引领整个行业的进化方向，否则无解。\n其实这个问题，教员早就给出了答案：「\u0026hellip;凡属正确的领导，必须是从群众中来，到群众中去。这就是说，将群众的意见（分散的无系统的意见）集中起来（经过研究，化为集中的系统的意见），又到群众中去作宣传解释，化为群众的意见，使群众坚持下去，见之于行动，并在群众行动中考验这些意见是否正确。然后再从群众中集中起来，再到群众中坚持下去，如此无限循环，一次比一次地更正确、更生动、更丰富\u0026hellip;」 \u0026mdash; 《关于领导方法的若干问题》, 1943\n要我说教员放在当代，就算是当个程序员，也能是一个大师级别的。教员的这段话，包含两个关键的点，完美的解释了开源软件的生命力的来源，我下面的详细讲讲。\n第一点，开源软件的生命力来自于场景的垄断，而背后更本质的垄断是人才垄断。\n为什么强调从群众中来？回顾刚才我们闭源软件的那段，其实一个关键的点是，软件的初始动机虽然来自于少数人的洞见，但是持续保持洞见并不是一件容易的事情，这就是为什么很多技术团队或者产品团队容易「自嗨」，一旦脱离用户，极易出现这样的问题。闭源软件厂商触及用户的手段不外乎于传统的商业宣传和销售，用户从感兴趣到使用起来的门槛很高，实施的周期也很长，另外通常销售会站在产品团队和客户中间，通过一些信息不对称来获取超额的利润，其中最大的信息不对称就是封闭的源代码本身或者定制化。这导致的问题是，相比流行的开源软件，闭源软件没有办法高效的获取，吸收和理解更多的场景，这对于一个通用的基础软件产品来说通常是一个致命的问题，如果见过的场景不够多，更没有办法判断产品那些需求该做是普遍需求，哪些是伪需求坚决不做，我认为这就是做产品的「触感」。\n对于一个流行的开源软件，本身不会有上面提到的问题：因为有足够多的用户，那么一定能看到足够多的场景，也能看到足够多的稀奇古怪的用法，这一个个用户的反馈，修过的一个个 bug，提出的一个个建议，会持续的产生类似「复利」的效果，你的软件越强壮，见过的场景越广，会进一步让你接触到更大的用户群，帮助软件变得更强大，如此循环。实际上开源软件本质上是通过放弃一部分通过信息不对称产生的潜在利润，换取了极其高效的传播和场景触及效率，但是有意思的是，实际上牺牲掉的这些潜在利润大概率也不一定真的牺牲掉，一来可能本身付费能力有限，二来可能实际上这些用户通过宣传站台二次传播或者代码贡献等方式回馈了项目本身。\n在上面那个过程中还会产生一个更加厉害的效应：人才的垄断。正所谓「事在人为」，上面提到的场景垄断中种种的技术决策和实践都是人来操作的。一个流行的开源软件在变成事实标准的过程中，一定会培养出大量熟悉这个产品的工程师，用户，摇旗呐喊的粉丝，代码贡献者，甚至挑刺吐槽的人。传统意义上，大家理解的开源社区只是狭义上的开发者社区，只有贡献代码才算参与，但是我认为只要和这个产品发生关联的人，都算是社区的一部分，「人尽其材」才是构建开源社区的终极目标。这个优势是会随着时间的流逝不断累积，这个很好理解，举个例子：A 公司的工程师在 A 公司的工作中学习使用了 TiDB 也很好的解决了问题，然后这个工程师作为数据库专家跳槽到了 B 公司，遇到同样的问题时，你猜他会选什么？ :)\n第二点，迭代，迭代，迭代，只有高速迭代才能立于不败之地\n上面教员的话里面有个关键的点，关于正向循环，也就是迭代。这个道理同样也适用于软件开发，软件从来都不是静止的，随着市场和竞争环境的变化，你今天的竞争优势，很可能明天就不是了。很多人都喜欢用静态的眼光看待问题，热衷于各种方案的横向对比，而忽略了进化速度，在这点上，我可能更看重的是同一个产品的纵向对比，举个例子：目前有 A, B, C三个方案，可能当下看这三个方案差距不大，也许在百分之五十之内。但是如果其中一个开源方案每次和自己半年前比都是在翻倍的提升（背后开源社区推动），但是闭源的方案的进步受限于团队规模和资源。这时候的选择除非是那种火烧眉毛的情况，否则一定应该选择一个迭代速度更快，增长率更好，更代表未来的方案，这个也很好理解。这是人的思维的一个惯性，人总是倾向用线性思维去看待问题，于是对非线性增长的事物往往会习惯性的低估。\n说一个更加震撼的例子，我粗略统计了一下，从 2018 到现在，也就短短一年多时间，整个 TiDB 的 SQL 层这么一个项目发生了 30000 多次提交，有接近 60% 的源码被修改。也就是说，每一年的 TiDB 都和上一年是不一样的，是一个更适应当下的，更加进步的一个 TiDB，而且随着社区的不断壮大，迭代的速度会越来越快。我完全不能想象，如果 TiDB 是一个闭源软件，从第一行代码开始写，到现在短短的 5 年时间，如何能够到达现在这个成熟度，这一切都是得益于开源社区的带来的加速度和反复迭代。","title":"大教堂终将倒下，但集市永存"},{"content":"前些天在与友人喝咖啡的时候，正好聊到关于 PingCAP 和 TiDB 的一些历史以及对于开源软件公司核心竞争力的理解，回顾这几年的创业生涯和 TiDB 社区的生长壮大，就像是一场巨大且正在进行中的社会学实验，原本零散的一些想法随着一条主线变得逐渐清晰，就想着写成文章总结一下关于社区对于开源软件以及开源公司到底意味着什么。\n无处不在的网络效应 两种网络效应\n很多人听说过网络效应（梅特卡夫效应：网络的价值与联网用户的平方数成正比），许多伟大的产品和公司通过网络效应构建起了强大的护城河。提到网络效应，经典例子在通信领域，例如手机，每多一个用户，对于所有用户的价值就越大，虽然大家也无意为他人创造价值，但是一旦开始使用，该行为就会帮助这个网络创造价值。很多我们熟知的 to C公司，尤其是社交网络和IM（即时通信软件） ，通过这个效应构建了极高的壁垒。NfX Venture 在他们的一篇博客(https://www.nfx.com/post/network-effects-manual/）中详细描述了很多种网络效应，在介绍社区之前，我想着重介绍下其中和开源软件相关的两种网络效应。\n 基于从众心理的网络效应  这类网络效应通常是从一些意见领袖开始，可能是行业大咖，可能是社交潮人，常常出现在一个新产品要去进攻一个老产品的市场时。尽管这个新产品相比市场的统治者来说不一定成熟，但它通常会带着一些鲜明的特色或者更加前沿的理念，吸引那些对「主流」不满或者希望突显自身前沿视野的意见领袖的支持，造成一种「很酷的人都在用，你不用你就要被淘汰了」的感觉。\n这种感觉会在新用户纷纷加入时，形成从众心理的网络效应，但是**这类网络效应的持续时间不会太长。**细想一下就能知道：如果早期意见领袖只是因为突显「不同」而加入，那么在这个社区成为主流后，这些意见领袖就没有理由留下，追随这些人的粉丝可能会随之而去。另外，对于这个新产品来说，完善程度通常不如老产品，美誉和差评会在早期同时到来。此时，如果不快速通过网络效应打磨产品，获得更好的迭代速度，那么，这个网络效应是根基不牢的。一个好处在于，该效应在早期是事半功倍的。\n回想 TiDB 早期的社区建设，也是因为几个创始人在 Codis 的工作以及在国内基础软件圈中积累的名声，和一些互联网技术圈中朋友的支持，形成最早的背书。\n 基于信仰的网络效应  **所谓「信仰」，就是基于对一个理念的认可而加入，从而形成网络效应。**这点在软件领域也不少见，自由软件运动和开源运动都是很好的例子。人嘛，总是要相信点什么。**这类网络效应的护城河是极深的，而且对于产品缺陷的容忍度极高。**因为信念是一个长期的念想，对于 TiDB 来说，这个念想形如：相信分布式是未来，相信云时代的业务需要像 TiDB 这样的数据库。但是这个目标又是足够有挑战的，值得长期为之努力。\n基于信仰的网络效应可能在最早期和从众心理网络效应有点类似，其中的关键是社区核心人群对于产品背后的理念是否有坚定信仰。反之，如果只是简单地秀优越感，是不会长久的，随着兴趣衰减，网络效应也会崩塌。\n网络效应对于基础软件的意义\n对于基础软件来说，我一直坚持两个观点：\n 基础软件是被“用”出来的，不是“写”出来的。 迭代和进化速度是这类软件的核心竞争力。  这两点恰恰是网络效应能带来的，虽然价值链条不像IM那样明显，但是，网络效应存在的基础是新用户给老用户带来的额外价值。而基础软件的价值，体现为以下几点：\n 可控的风险（稳定性） 更多的场景适应性（发现新的适用场景和持续提升性能） 良好的易用性  对于风险控制来说，越多人用意味着风险被越多人均摊，其中的一个假设是：我不特别，我遇到的问题别人应该也遇到过，一定有人能比我早发现并修复它。这个假设在一个成熟且活跃的基础软件社区是成立的，因为基础软件的场景边界相对清晰，在适用范围内的路径大致相同，同一条路径走多了，坑自然就少了。只要有一个人踩到坑，反馈回社区，不管最后是谁修好的，这个行为对于其他用户都是受益的。\n同样的逻辑，对于场景适应性来说也成立。个体的认知总是带有局限性，即使是项目的创始团队，也不见得对于某个具体的应用场景有深刻理解。社区用户的创造力是无穷的，一些设计外的使用路径可能会出奇地好用，从而发展出新的优势场景。同样地，只要有一个成功案例，那么对于其他具有相似场景的用户来说，软件的价值就增加了， TiDB 和 Flink 组合成的实时 HTAP 数据处理方案，就是一个很好的例子。\n对于易用性改进的逻辑和稳定性类似，我就不赘述了。利用网络效应带来的飞轮效应改进软件，这个思路我在《大教堂终将倒下，但集市永存》一文中也提到过。\n社区的成熟度曲线和必经阶段 社区的诞生\n在 GitHub 上开放你的源代码，甚至使用公开的 Git 工作流，都不是社区诞生的时刻。一个社区真正诞生，是在你和你的代码之外，开始有第三者介入并产生连接的时刻，可能是收到第一个外部 PR，可能是收到第一个外部 issue，这些才是社区的开端。社区始于连接，也成就于连接。开放源代码并不等同于开源，很多团队和项目在开放源代码方面花费了很多时间，却忽略了代码及背后团队的社区化，这是很可惜的。\n死亡鸿沟和希望之坡\n就像《跨越鸿沟》这本书中提到的，开源软件也有自己的生命周期曲线，这是和社区息息相关的。\n图中断层出现的原因是产品成熟度迟迟没有跟上，用户过来以后发现都是坑，随之而来的各种差评会让早期支持者和创始人疲于奔命甚至而失去兴趣。\n**对于一个开源软件，断层的体现可能是经历早期快速增长后，来到长达 1~2 年的静默期，增长几乎停滞。**对于社区来说，几乎所有的精力都用在给早期用户填坑，期间会有用户自然增长但流失率也非常高。这个阶段对于资源的消耗非常大，社区的核心贡献者也会非常累，如果熬不过去就死了，所以说是“死亡鸿沟”。\n好消息是，这个阶段终将会过去，bug 这种东西嘛，改掉一个就少一个，产品也会在这个阶段逐渐摸索到自己的定位和最佳实践，而在最佳实践这个路径上，产品会变得越来越稳定和聚焦。如果定位是市场刚需，**那么就会迎来一个高速增长阶段（成熟期），而社区的生态也会随着产品的普及开始加速度发展。**这个从上图的 Kubernetes 和 TiDB 的搜索指数里面能看到这个鸿沟的一个侧写。\n社区的终局\n一个好的开源软件社区的终局会是什么样子？对于这个问题，其实我们有很多能参考的例子，例如 GNU Linux、Hadoop、Spark、MySQL 等等。我认为，不管一个开源软件及社区是由商业公司发起还是其他方式发起、壮大，到最后一定会出现独立于某公司之外的中立组织来接管这个社区，这也是最自然合理的方式。\n尤其是公司主导的开源项目，在后期会面临中立性的问题。因为对于公司而言，最重要的是客户成功，对商业化的诉求一定会影响开源软件功能设置和开发优先级。而且优先级往往是会变的（可能更紧急且更具体），变化也许会和社区的开发节奏冲突，但我不认为这两者的矛盾不可调和，我会在下文展开来讲。\n**中后期的开源软件已经支撑着太多用户的场景成功和商业利益，由一个中立的委员会来平衡各方的利益及监督各方的责任是目前看来比较成功的实践，**而且开始有这样的组织，也从侧面说明这个项目已经成熟，已经有良好的生态。还没有到达这个阶段的开源软件大多是由项目背后的公司主导社区，在项目成熟阶段，重点是不断地通过优化客户和场景的成功让整个飞轮转动起来，当主导公司之外有越来越多的成员在思考和实践 governance rule，这就是一个积极的信号。\n社区和商业化如何共存 种地和做菜 \u0026amp; 河与岸上的人\n前文留下一个问题，就是开源与商业化的矛盾，不管我如何解释，本质上开源和传统的软件售卖模式一定是冲突的。\n我举一个比较好理解的例子：如果将开源比作种菜，开源软件源代码相当于种子，业务成功相当于长出来的菜，传统的软件商业模式类似于卖种子，但是种地施肥（hosting）都是客户自己的工作。开源软件的种子是免费的，地是客户的，种地的人也是客户的人，所以开源厂商大概只能提供种地指导服务，尤其在一些种子不是太好种的情况下，指导服务是有意义的。但仔细想想，随着种子不断改良（性能、稳定性、易用性等），随便撒到地里就能开花结果，那么专业的种菜服务就没什么必要性了。于是厂商只好卖一些额外的价值，比如保险服务，万一种子生长遇到极端天气，至少有专家团在背后帮忙解决。但是这种商业模式仍然比较别扭，因为价值链条大部分都在客户自己这边。所以，如果厂商看待社区只停留在潜在客户视角，很难做出好产品，因为没有内在动力去持续优化软件。\n一个更好的视角是往后退一步，我再举个好理解的例子：将社区当成一条河流，不属于任何人，大家共同保持河水的清澈和流动性，谁都不要过度捞鱼，不同的组织和个人都可以在河流周边构建自己的生态，至于岸上的人靠什么挣钱，那是另外一个问题，后文再讲。\n客户成功和用户体验：内在的一致性\n虽然开源软件商业公司的第一目标是客户成功，但这和做好社区并不矛盾。**一个常见的误区是在开源软件公司内部，这两个团队形成对立关系。**商业团队认为社区就是给商业化养鱼的，养肥了就要收割，极端点就动不动要闭源；社区团队认为商业化会减慢生态传播的速度，使用门槛上升，极端做法是产生反商业化的倾向。如果都只在自己的位置上思考问题，当然双方都没错，那到底是哪里有问题呢？\n问题出在了“阶段”和“客户选择”，社区用户和商业用户使用开源软件的生命周期可能完全不同，一般的开源软件公司会有两个漏斗，我称之为社区漏斗和商业漏斗。有些说法认为社区漏斗是商业漏斗的上层，我之前也深以为然，但经过几年的实践，我渐渐发现其实并不是那样。这两者是独立的，如果只是简单地作为一个漏斗，那么就会有很多问题，比如经典问题：不会流到商业漏斗的社区用户，其价值到底是什么？所以，肯定不是一个漏斗，而是有很深的内部联系。\n什么联系？为方便理解，还是用种菜举例说明。开源社区孵化出来的东西，例如用户成功案例、社区贡献对产品的打磨、探索出来的适用场景等，就像一个个生的菜和食材，而客户想要一盘鱼香肉丝，并不关心盘子中的肉和菜是怎么来的，所以看到关键点了吗？商业化团队的角色就像是厨师，社区运营团队就像农民，二者的关注点并不一样，厨师关注点是如何做好菜，农民的关注点是如何种好地，产生更好的食材。从食材到一道菜，还要经历很长的过程，但没有好食材，能力再强的厨师也难做出一盘好菜。\n**对于开源软件公司来说，社区和商业这两个团队的内部一致性是：好产品和制胜场景。**根据我们的实践经验，比较好的做法是，社区团队聚焦于两个关键点：\n 社区用户对于产品的打磨（在制胜场景下）； 发现更多的制胜场景。  这两个关键点会形成闭环，社区团队持续产生食材（制胜场景以及持续进化的产品），商业团队聚焦于制胜场景的进一步加工和客户旅程优化，两个团队互相配合拉动整个公司和项目的大循环。例如TiDB商业用户的场景和解决方案，大多是从社区用户中诞生并打磨成熟，尽管可能两个用户群体完全不一样，但是通过 TiDB 形成了一个大的生态——商业化的循环，而PingCAP 就是中间的桥梁。另外，社区和商业化团队会有一个共同的北极星指标：用户体验。\n可规模化变现的唯一出路：云\n一个好的生意应该是可以规模化的，传统开源软件公司的商业模式，问题在于规模化中需要人的介入，销售/售前/售后交付等等，而基于人的生意是没法规模化的。在云诞生前这个问题是无解的，所以开源软件公司需要寻找一个和开源无关的软件商业模式（听起来有点别扭，但是仔细想想确实如此），而云本质上是一个资源租赁生意。\n还是以种菜的例子来说，过去传统的商业模式中，因为土地和种菜人都是客户自己的，所以开源软件公司的位置就比较尴尬，但是在云上，基础软件商业模式本质上是一个hosting服务，让原来价值链条中最重要的一部分“土地”（ hosting资源和基础设施）掌握在了厂商手上，这对于用户来说也是好的，毕竟管理“土地”也是一件费心费力的事情，而且很难做到按需购买。问题在于用户想要的只是一道好菜而已，注意这和开源（种菜）并没有什么关系，因为不管开不开源，用户支付的都是管理和租赁费用，相当于即使种子和食材免费，顾客去饭店吃饭，也需要为菜品买单，因为顾客购买的是好菜和服务体验。\n另外，**很多人认为开源社区是竞争壁垒，其实并不是，真正的壁垒是生态，而开源社区是构建生态的一种高效方式，如果一个产品不用开源也构建起了生态，那么效果是一样的。**一个很好的例子就是 Snowflake，尽管 Snowflake 没有开源，但是2012年诞生伊始，它在云数据仓库这个市场内几乎没有任何竞争对手，留给 Snowflake 足够的时间通过差异化定位和极佳的用户体验构建自己的生态，依托云的崛起和规模化效应取得了巨大成功。\n如何做好社区 上文形而上地讨论了很多关于哲学的内容，接下来聊聊落地实践。想要做好开源社区其实是有方法论的，但前提是有正确的思考方式和思考角度，否则在实践环节你就会发现有无数事情可以做，却不知道哪件或哪些事情是更重要的，更难受的是你发现没法衡量对与错。以下是我的一些思考角度以及思考时考虑的重点指标，可作为社区运营者的参考。\n你是谁？你解决了什么问题？为什么是你？\n好社区的根基一定是好产品，要回答“你是谁”这个问题，一定是通过回答“你解决了什么问题”而得出的，这点和 to C 产品的运营很不一样。一些社区运营者会将注意力转移到各种活动或者宣传拉新，同时夸大产品能力，导致与现实不符，这是最常见的误区。\n很多做社区运营的朋友经常来找我：我也做了很多活动，写了很多文章，为什么看起来没有效果？通常这个时候我会问他：你能一句话说明白你的产品是做什么的吗？到底解决了什么问题？这个问题是普遍问题吗？非你这个产品不可吗？这个时候他就明白：完美的产品是不存在的，好的产品一定是跟随它的优势场景出现的，比如 Redis 显然不能用来做核心金融交易场景，但谁都不会否认Redis在缓存场景下是当之无愧的事实标准。同样的例子还有很多，例如 Spark、ClickHouse 等等。所以对于运营团队，在做任何动作之前要想清楚上面的四个问题。\n好用决定了漏斗的转化率\n找到制胜场景就够了吗？当然不是，如果把整个用户旅程当成一个漏斗，找到制胜场景充其量是找到正确的入口而已，进入漏斗以后，重要的事情就变成了提升各阶段的转化率，**决定转化率的一个关键指标是产品的易用性，**这点和做 to C 产品很像，很多做 to B 的团队会下意识忽略这一点，通常可能是两种原因：\n 不太重视社区用户 Self-service ，项目官方甚至鼓励用户联系官方团队，因为早期知道有人在用这个信息是很重要的，而商业客户基本服务和支持都是官方的，客户无感，对公司而言没有动力优化。 很多产品在诞生初期是救命型的产品，用户没有别的选择。例如早期的 TiDB ，在 MySQL 扩展需求迫在眉睫的时候，用户更关心如何立即把问题解决掉，内核能力更重要，其他的可以先缓缓，忍着就好。  这两种原因导致的结果就是，对易用性和用户体验关注不足，这个错误在市场竞争初期是很隐蔽的。一方面因为流进漏斗的 leads 数量不够大，人肉支持尚可，且市场的竞争还不激烈，用户没有其他选择。试想一下，当这个市场终有一天变得成熟，大量客户被充分教育后流入漏斗，团队的支持带宽肯定是不足的；另一方面，因为市场已经被教育成熟，一定会有竞争对手能做类似的事情，这时，当你不是市场中唯一的救命选择，用户一定会选择用着顺手且省心的一方，这不难理解。这就是为什么在开源软件竞争的中后期，易用性和用户体验要放在至高位置的原因。对于“用着省心”，假设已经通过成熟的生态和案例背书解决了，而在“用着顺手”这一点上，中国诞生的开源软件团队相比世界先进水平而言，差距很大，毕竟海外的开源软件竞争比国内更加激烈，因为国外开源市场诞生时间长，而且业务场景对于基础软件的需求也没有国内极端，通常好几个产品都能搞定同一个场景，那么这时当然就要比拼易用性（省心）和生态（放心）。\n有几个问题，作为开源项目的产品负责人可以问问自己，在你的产品领域里，如何定义好用？最佳实践是什么？世界上最好用的同类水平是怎么样的？我相信思考这些问题对产品发展会有帮助。一个反映易用性的好视角是：用户能够 Self-servicing 的程度，其指标体系较多：比如在云上自助完整整个产品生命周期的比例，在开源社区从接触到使用过程中不用提问的比例，开源社区活跃贡献者数量等等。\n二次传播是达成网络效应的关键\n上文提到过，网络效应产生的前提是，任何一个新用户的使用对于老用户是有价值加成的，所以试想：如果一个社区用户默默地使用了软件，默默地看了文档和最佳实践文章，甚至出了 bug 自己默默地修好（不贡献回来），这对这个社区和产品是有价值的吗？\n我认为是没有的。\n尽管我知道一定会有这样的用户存在，就像沉默的大多数人一样。对于社区运营者来说，**最关键的任务不是让沉默者更多或更深度地使用，而是让他们和网络中的其他用户建立更多的连接，**例如分享经验（写案例文章）、培养贡献者、积极向社区反馈使用中的问题等等，而且一定要将这些内容传递到网络的其他节点，确保产生价值。例如：一个用户的使用场景帮到了另一个用户选型，一个用户反馈帮助产品发现了一个 bug 并修复，这些都是产生价值的例子。切忌让用户变成一个个孤岛，社区运营者如果看不清这个关键点，可能会陷入为了数字（使用量）而追求数字的情况，做了很多工作，但从全局看不到进步。\n网络效应的转移\n社区运营的最高境界是将网络效应从使用者的网络效应转移到基于信仰的网络效应，将社区中心从开源公司内部转移到外部以获得更大的势能。这两者都不容易，对于前者可能更多的是抽象和总结提炼理念以及持续保持长远而正确的 insight（洞察），加之寻找合适的布道者群体，这点并不容易。对于后者来说，只要在以公司为中心的阶段积累足够多的成功案例和优势场景，并且投入资源教育市场，剩下的交给时间就好，这个阶段关注的指标是品牌力。开源软件社区运营是一个指数曲线的游戏，要抱着长期主义的心态去耕耘。\n最后作为结尾，我想谈谈，一个伟大的开源基础软件产品应该是什么样的？\n我眼中一个伟大的基础软件产品不仅仅是解决眼下的具体问题，而是开启一片新的天地，一个新的视角，创造新的可能性。就像智能手机的发明，它作为平台催生出了微信这样的伟大应用，开启了一个全新的世界。就像云、S3 和 EBS 的发明，给开发者提供了新的设计方式，催生出了Snowflake这类的新物种，彻底改变了人们使用分析数据的方式。而开源社区正是这类伟大基础软件诞生的最合适的土壤，就像鱼和水一样。\n我不知道社区会带来什么，我也不敢高估自己能力，毕竟在群体智慧面前，个人的力量永远是渺小的。\n","permalink":"http://c4pt0r.github.io/posts/in-community-we-trust/","summary":"前些天在与友人喝咖啡的时候，正好聊到关于 PingCAP 和 TiDB 的一些历史以及对于开源软件公司核心竞争力的理解，回顾这几年的创业生涯和 TiDB 社区的生长壮大，就像是一场巨大且正在进行中的社会学实验，原本零散的一些想法随着一条主线变得逐渐清晰，就想着写成文章总结一下关于社区对于开源软件以及开源公司到底意味着什么。\n无处不在的网络效应 两种网络效应\n很多人听说过网络效应（梅特卡夫效应：网络的价值与联网用户的平方数成正比），许多伟大的产品和公司通过网络效应构建起了强大的护城河。提到网络效应，经典例子在通信领域，例如手机，每多一个用户，对于所有用户的价值就越大，虽然大家也无意为他人创造价值，但是一旦开始使用，该行为就会帮助这个网络创造价值。很多我们熟知的 to C公司，尤其是社交网络和IM（即时通信软件） ，通过这个效应构建了极高的壁垒。NfX Venture 在他们的一篇博客(https://www.nfx.com/post/network-effects-manual/）中详细描述了很多种网络效应，在介绍社区之前，我想着重介绍下其中和开源软件相关的两种网络效应。\n 基于从众心理的网络效应  这类网络效应通常是从一些意见领袖开始，可能是行业大咖，可能是社交潮人，常常出现在一个新产品要去进攻一个老产品的市场时。尽管这个新产品相比市场的统治者来说不一定成熟，但它通常会带着一些鲜明的特色或者更加前沿的理念，吸引那些对「主流」不满或者希望突显自身前沿视野的意见领袖的支持，造成一种「很酷的人都在用，你不用你就要被淘汰了」的感觉。\n这种感觉会在新用户纷纷加入时，形成从众心理的网络效应，但是**这类网络效应的持续时间不会太长。**细想一下就能知道：如果早期意见领袖只是因为突显「不同」而加入，那么在这个社区成为主流后，这些意见领袖就没有理由留下，追随这些人的粉丝可能会随之而去。另外，对于这个新产品来说，完善程度通常不如老产品，美誉和差评会在早期同时到来。此时，如果不快速通过网络效应打磨产品，获得更好的迭代速度，那么，这个网络效应是根基不牢的。一个好处在于，该效应在早期是事半功倍的。\n回想 TiDB 早期的社区建设，也是因为几个创始人在 Codis 的工作以及在国内基础软件圈中积累的名声，和一些互联网技术圈中朋友的支持，形成最早的背书。\n 基于信仰的网络效应  **所谓「信仰」，就是基于对一个理念的认可而加入，从而形成网络效应。**这点在软件领域也不少见，自由软件运动和开源运动都是很好的例子。人嘛，总是要相信点什么。**这类网络效应的护城河是极深的，而且对于产品缺陷的容忍度极高。**因为信念是一个长期的念想，对于 TiDB 来说，这个念想形如：相信分布式是未来，相信云时代的业务需要像 TiDB 这样的数据库。但是这个目标又是足够有挑战的，值得长期为之努力。\n基于信仰的网络效应可能在最早期和从众心理网络效应有点类似，其中的关键是社区核心人群对于产品背后的理念是否有坚定信仰。反之，如果只是简单地秀优越感，是不会长久的，随着兴趣衰减，网络效应也会崩塌。\n网络效应对于基础软件的意义\n对于基础软件来说，我一直坚持两个观点：\n 基础软件是被“用”出来的，不是“写”出来的。 迭代和进化速度是这类软件的核心竞争力。  这两点恰恰是网络效应能带来的，虽然价值链条不像IM那样明显，但是，网络效应存在的基础是新用户给老用户带来的额外价值。而基础软件的价值，体现为以下几点：\n 可控的风险（稳定性） 更多的场景适应性（发现新的适用场景和持续提升性能） 良好的易用性  对于风险控制来说，越多人用意味着风险被越多人均摊，其中的一个假设是：我不特别，我遇到的问题别人应该也遇到过，一定有人能比我早发现并修复它。这个假设在一个成熟且活跃的基础软件社区是成立的，因为基础软件的场景边界相对清晰，在适用范围内的路径大致相同，同一条路径走多了，坑自然就少了。只要有一个人踩到坑，反馈回社区，不管最后是谁修好的，这个行为对于其他用户都是受益的。\n同样的逻辑，对于场景适应性来说也成立。个体的认知总是带有局限性，即使是项目的创始团队，也不见得对于某个具体的应用场景有深刻理解。社区用户的创造力是无穷的，一些设计外的使用路径可能会出奇地好用，从而发展出新的优势场景。同样地，只要有一个成功案例，那么对于其他具有相似场景的用户来说，软件的价值就增加了， TiDB 和 Flink 组合成的实时 HTAP 数据处理方案，就是一个很好的例子。\n对于易用性改进的逻辑和稳定性类似，我就不赘述了。利用网络效应带来的飞轮效应改进软件，这个思路我在《大教堂终将倒下，但集市永存》一文中也提到过。\n社区的成熟度曲线和必经阶段 社区的诞生\n在 GitHub 上开放你的源代码，甚至使用公开的 Git 工作流，都不是社区诞生的时刻。一个社区真正诞生，是在你和你的代码之外，开始有第三者介入并产生连接的时刻，可能是收到第一个外部 PR，可能是收到第一个外部 issue，这些才是社区的开端。社区始于连接，也成就于连接。开放源代码并不等同于开源，很多团队和项目在开放源代码方面花费了很多时间，却忽略了代码及背后团队的社区化，这是很可惜的。\n死亡鸿沟和希望之坡\n就像《跨越鸿沟》这本书中提到的，开源软件也有自己的生命周期曲线，这是和社区息息相关的。\n图中断层出现的原因是产品成熟度迟迟没有跟上，用户过来以后发现都是坑，随之而来的各种差评会让早期支持者和创始人疲于奔命甚至而失去兴趣。\n**对于一个开源软件，断层的体现可能是经历早期快速增长后，来到长达 1~2 年的静默期，增长几乎停滞。**对于社区来说，几乎所有的精力都用在给早期用户填坑，期间会有用户自然增长但流失率也非常高。这个阶段对于资源的消耗非常大，社区的核心贡献者也会非常累，如果熬不过去就死了，所以说是“死亡鸿沟”。","title":"In Community We Trust"}]