[{"content":"‘不立文字，直指人心’ \u0026mdash; 六祖慧能\n昨天正好在飞机上把原研哉的又一本关于设计的书看完了，书名就不提了，大概仍然是原研哉老师用他那种特有的平静的口吻描述关于设计的思考和社会的观察，引起了我对于软件设计审美的一些思考。熟悉我的朋友大概知道我一向对艺术和哲学有着偏爱，尤其是东亚的古典美学，看似离所从事的计算机行业很远，但是我一直认为在代码深处存在着相同的审美趣味。正好试着总结一下作为第二篇关于系统设计品味的文章，上次如果说是一篇关于‘术’的文章，这篇可能会更有‘道’的味道 :)。不过关于审美的事情通常是带着强烈的个人偏好，而且就像任何其他艺术形态一样，审美也是有流派的，如果对本文描述的东西不认同也实属正常，一笑了之就好。\n东方美学的内核 在聊软件之前，我们先聊一下美学。仔细想想也蛮有意思的，长期以来我们都认为计算机科学是更加偏向工程学的范畴，也就是所谓的软件工程，但看看接近的学科，例如建筑，我们很自然的能够将泥瓦匠和建筑设计师看作是两种不同的职业，但是对于程序员和软件设计师很多时候是一体，于是对于系统设计品味的讨论通常会和工程学乃至管理学混在一起，即使有对于美学的讨论，也只是在一些 Geek 和 Hacker 的亚文化中，隐藏在一个个看似戏谑但是充满禅意的 Puns 和 Wordplay 里面，例如在 ESR 的《How To Become A Hacker》一文中关于 Hacker 生活方式中对禅宗和禅修的推崇可见一斑，我其实还蛮庆幸在我刚接触编程的年代（90年代中后期）赶上了黄金年代的尾巴，得以一窥，现在的年轻 Geek 们只能在计算机考古学中体验了 :)。\n为了避免牵扯太多其他的内容，大概的范围会限定在禅宗和道家的审美，而且只会从‘表’上分析，内在的哲学和宗教的内容不会过多涉及。说到这个话题，大家不妨在脑子里想象一下典型的东方审美的例子：寥寥几笔加上大片留白的水墨画，雾气缭绕的山脉，日式枯山水庭院，Wabi-sabi，离日常生活近一点的，例如优衣库，无印良品，苹果（乔布斯时代）\u0026hellip;如果总结几个关键字就是：崇尚简洁，没有攻击性，平静含蓄的表达，以小见大（通过小的细节隐喻出更大的意境）\u0026hellip;值得注意的是，这并不是回避世界的复杂性，而是强调隐藏在复杂性的表面背后的根源是极简要素加上自洽的规则。\n其实有这种审美倾向丝毫不意外，禅宗的内核中有很浓的存在主义和本体论色彩，例如铃木大拙（当代最有名的禅学大师之一，在西方尤其受到推崇）关于意识以及一切可能性的根源，也就是他口中的 Cosmic Unconscious 概念，又如道家的老子在道德经中关于‘道’的描述：\u0026lsquo;有物混成，先天地生\u0026hellip;道生一，一生二，二生三，三生万物\u0026hellip;'，都是关于这个审美内核精彩诠释，当然严格来说，道家和禅宗在审美上还是有一定区别的，道家更加崇尚与自然的融合，顺其自然，用当下流行的话就是‘躺平了’，是一种出世的美学，但是禅宗更加严肃，只为了达到心物合一的顿悟。但在表面上，这类东方的古典审美其实倒是暗合了当代西方的包豪斯设计的一些理念：简单并不意味着简陋，而是舍弃掉一切无用的装饰，直指本源。只是对于包豪斯来说，本源大致是从实用主义角度出发，东方这边的含义更深且丰富而已。\n复杂系统的简洁之美 回到计算机的世界，复杂总是不可回避的，人类总是会在不停尝试创造超出自己理解边界的事物，正所谓创新。而且无穷的复杂性用有穷的代码来表示，本身就是一件非常充满禅学审美的事情。就像我经常举的一个例子：大家有没有想过，TiDB 核心大概百来万行代码，运行在 3 台机器上和运行在 3000 台机器上一样，都是这百来万行代码，但是 3 台机器的复杂性和 3000 台机器复杂性确是千差万别，人肉管理 3 台机器很轻松，但是管理好 3000 台机器，让它们高效稳定的协作这件事情，肯定超出了人作为个体的能力范围，等一下后面我会再聊到 TiDB 的例子。 同样的例子还有很多，例如大家比较熟悉的 Unix 哲学，已经有无数人阐述过，我也不追溯，后边我会用几个比较新鲜的例子，用来阐述复杂系统的简单之美，来让大家体会一下其中妙处。\n元胞自动机 第一个例子，我想聊聊元胞自动机（Cellular Automata），元胞自动机大概是 50 年代由冯诺依曼提出的一个自动机模型，听名字很高级，但事实上非常非常简单，简单到小学生都能马上理解：想象一个 n 维度的无限网格（最好理解的是 2 维，大概就是类似棋盘的样子），每个格子会处于有限的状态，t 作为离散的时间概念，每一个 t 时刻的网格中每一个格子的状态是由 t - 1 时刻这个的格子的邻居格子（ 2 维里面就是上下左右的几个）的状态决定，注意所有的格子都是平等的，受到同一种规则的支配。实现这么一个自动机，也就是百来行代码，最有名的实现是 Conway 的 Game of Life，生命游戏是一个二维的 CA 实现，想象每个格子是一个细胞，规则很简单（来自 Wikipedia）：\n  每个细胞有两种状态 - 存活或死亡，每个细胞与以自身为中心的周围八个格子的细胞产生互动\n  当前细胞为存活状态时，当周围的存活细胞低于2个时（不包含2个），该细胞变成死亡状态。（模拟生命数量稀少）\n  当前细胞为存活状态时，当周围有2个或3个存活细胞时，该细胞保持原样。\n  当前细胞为存活状态时，当周围有超过3个存活细胞时，该细胞变成死亡状态。（模拟生命数量过多）\n  当前细胞为死亡状态时，当周围有3个存活细胞时，该细胞变成存活状态。（模拟繁殖）\n  可能你会问：就这么一个看上去如此弱智的游戏，能玩出什么花样来？\n那我接下来要说的可能会让你大吃一惊，已经被证明，生命游戏中可以构造出通用图灵机，也就是说，通过这个游戏，你可以实现在计算机上能够实现的一切，只要你愿意，你甚至可以用生命游戏模拟出一台计算机，在这个表格上实现一个操作系统和文本编辑器，然后构造出我写这篇文字需要的一切软件，或者实现一个深度学习系统，例如 实现一个 AlphaGo 在围棋上胜过人类最强的棋手，没错就是在这么一个二维的表格上加上 5 条规则。\n注意，生命游戏的广度并不局限于实现图灵机，是否蕴含更多关于计算模型的可能性？没有答案。只是如此深邃复杂的宇宙就是由如此简单的规则构成，本身就是一件很美的事情，对吧？（另外关于在生命游戏的一个 Fun Fact 是，在游戏中构造逻辑门的生成模式叫做：滑翔机，这个图案也常被作为 Hacker 的 Logo，https://www.bilibili.com/video/BV1T541157s7/?spm_id_from=333.788.recommend_more_video.2）。\nλ-Calculus 和 Y-Combinator 第二个例子仍然是一个关于计算理论的例子： λ 演算。这个被作为计算之美的一个具体的体现，虽然它和图灵机是等价的，但是在爱好者圈子里通常对它的美学价值更加的推崇（我感觉？），我猜背后的原因大概是图灵机的抽象充满了一股机械主义的气息，而 λ 演算从名字就看得出来就带着纯理论那种的高级感吧 😂（当然图灵机的抽象也很简洁）。λ 演算大概就是数学中的函数换个写法再加几个规则, 例如 f(x) = x , 这么一个函数，通过 λ 演算的书写方式，就是 λx.x。λ 演算的核心规则就两条（注：可能有朋友会问 η 归约哪去了？其实 η 归约在完备性上不是必要的）分别叫：α 转换和 β 归约，听起来很高级，但是实际是简单的吓人：所谓 α 转换就是一个函数的自变量名字叫做 x 还是 y 还是 z 无所谓；所谓 β 归约，就是函数的变量可以带入一个值进行计算，相当于 Apply 函数的过程，表达方式是一个括号。具体 λ 演算能做什么我就不赘述了，和上面一样，图灵机能做的都能做。 提到美，在 λ 演算中经常被拉出来溜溜的大概就是 Y-Combinator（下面简称 YC），没错，就是 YC 的那个 YC，因为这个东西过于优雅，以至于 Paul Graham 搞基金的时候直接拿过去当名字了。\n下面我试一下尽可能用人话把 YC 讲明白（不想看的跳过这段也没有任何问题）：我们已经知道大概 λ 演算是和我们在数学里面的函数接近的例如 f(x) = x, 但是注意到：λ 演算的定义都是匿名函数（如：λx.x）并没有一个叫做 f 的名字，如果我们希望实现递归函数怎么办呢？也就是自己调用自己？这里插播介绍一个概念：不动点，也很简单，所有满足 f(x) = x 的 x 都叫做 f 的不动点。想象一下，如果 x 作为一个函数带入，输出一个函数，这个函数和传入的 x 是等价的函数，我们不就可以把自己给‘算’出来了吗？所以把 YC 想象成就是一个传入参数是 f 返回 f 的不动点函数的函数（有点绕）。当然看不懂也没关系，静静的观赏一下 YC 吧：\n一切这些优雅的东西都是构建在上面几条简单演算规则之上。\nActor 模式 说了两个纯理论的例子，其实这样纯粹的抽象带来的美学在更软件工程的味道的领域也不少见，让我们看看分布式系统里面的一个常用的设计模式：Actor 模式。Actor 模式大约在上世纪 70 年代由 Carl Hewitt 等人作为研究并行计算理论的工具被提出，后来在 Erlang OTP 和 Scala Akka 被发扬光大。我之前的一篇文章提到可观测性的时候略微提及了周期的概念，程序的逻辑其实就是一个又一个的‘循环’嵌套起来，Actor 模式就是利用了这一点：万物皆是 Actor，每一个 Actor 都是一个无限的循环，这个循环对不同的事件的到来，可以做出以下几种反馈：\n 向其他（有限个）Actor 发送事件（包括自己） 产生（有限个）新 Actor 根据收到事件，决定下一条事件的内容  不管多么复杂的业务逻辑，都能归约到 Actor 上，篇幅有限举一个特别简单的例子，由 Actor 模型构建的 Web Service 服务（假设需要访问数据库），大概分为 2 类 Actor：处理 HTTP 请求的 Actor，以及处理 DAO（Data Access Object）访问数据库的 Actor。对于第一类 Actor 来说是一个不停接收客户端请求事件，持久化请求，当收到连接可读写的事件后读取并对 HTTP 请求的内容进行处理，如果是需要访问数据库的事件，发送给负责数据库处理的 Actor，当收到数据库处理的 Actor 的回应事件后，返回客户端；对于 DAO Actor，收到的数据库访问请求的时候访问数据库，然后向请求的 Actor 返回包含结果的消息事件。与 Actor 类似的思想还有 Tony Hoare 的 CSP (communicating sequential processes) 模型，甚至在 Go 语言中 Goroutine / Channel 的模式也是一点 Actor 和 CSP 的影子。\nActor 模型优雅的地方不仅仅在于通过一套简单统一的范式来表达复杂的逻辑，更重要的是从消除了单机和集群的区别，大家仔细想，Actor 并没有规定与其通信的其他的 Actor 在哪，与之对应的 Mutex 和信号量通常带着单机色彩（Spinlock 本质上是通过控制锁对象的所有权实现互斥），Actor 就没有这个问题，而且很天然的对负载均衡友好，不过上面的第三条原则实际上暗示了 Actor 要处理自身状态持久化的问题，虽然实际的工程中，完全纯粹的 Actor 模型的系统也不多见，也经常被人诟病性能问题和 Actor 的拆分粒度问题（太细了冗余增加通信的复杂度，太粗了形成单点则失去了 Actor 的意义），但是作为一种思考分布式系统的角度，Actor 是受启发于现实的物理世界，我们和世界发生交互的方式正是通过语言（消息）和异步的，从某种程度上来说 Actor 是对我们自己的建模。\nThe Zen of TiKV 刚才提到了的 Actor 的时候为状态留下了一个伏笔，每个 Actor 需要关注自己的状态，但是状态一向是优雅系统的大敌，尤其是叠加上分布式/Failover/一致性之类的要求之后，这里每一个要求都不简单，叠加在一起就变成了复杂性爆炸的状态，TiKV 作为 TiDB 的存储层的核心，就是为了解决这个问题。就像前面提到的，东方审美的精髓是用简单对抗复杂。TiKV 是一个支持跨行事务的分布式的 Key-Value Database，这个世界上的 KV 数据库已经那么多了，Why another？如果说从设计的优雅程度来说，TiKV 一定是在不错的那一批，所以这个数据库的优雅在哪？在分析之前，我先放一首当时自己写的诗（为了致敬 Python 的 import this）TiKV 是构建在下面这 10 条规则：\n 《The Zen of TiKV》\nEverything is KV pair\nEvery KV pair belongs to a Region, but a Region contains multiple KV pairs\nEvery Region belongs to a Host, but a Host contains multiple Regions\nRegion comes from nothingness, only specifying the beginning and the end of a KV range\nInitial Region is (-∞, +∞)\nWhen Region is too big, it splits\nWhen Regions are too small, they merge\nRegion can copy itself (to other hosts)\nRegion can also destroy itself\nRegions live and prosper\n 如果读者读完后，脑中能联想到细胞的分裂和繁殖，那就对了，TiKV 诞生在一个大的假设上：系统应该能调整自己去适应环境的变化，这个过程人和业务的领域知识只是在给系统指引方向，让系统朝着这个方向演进，而并不是反过来，为了一个具体特定的场景定制。 我经常开玩笑说，从技术的角度来说，TiDB 是我们努力让 TiKV 长成了一个关系型数据库的样子，事实上因为这种类似‘细胞’的设计，让 TiKV 能长出来的东西很多，例如 TiFlash 就是一个绝佳的例子，TiFlash 是 TiDB 的列式存储加速拓展，是之所以用拓展（Extension）这个词是因为 TiFlash 的原理就是 TiKV 这些一个个存储数据的‘细胞’上，根据上面那首小诗的第八行，创建出来的一批列式存储副本，这些副本除了是列式存储格式之外，和普通的‘细胞’别无二致，于是就很平滑的继承了整个系统的灵活性。试想一下，TiFlash 只是这个能力的一个应用，未来还能发展出多少可能性？另外这个设计带来的一个好处是，对于一致性和 Failover 之类的比较‘脏’的问题，被限定在了 Region 的单位上，也就是我只需要保证 Region 在复制/销毁/分裂/合并的正确性以及可用性，就很自然能在一个更大的集群上大致保证整体的正确性，更详细的一些介绍，我在 2016 年的一篇 Blog 里有阐述（https://pingcap.com/zh/blog/building-distributed-db-with-raft）。\nPlan9 最后一个例子来自我特别喜欢的一个操作系统：Plan9。\n这一小节我想了很久，竟然不知道该如何下笔，因为 Plan9 的设计实在超前时代太多，这种感觉就像看到一个非常震撼的艺术品，你的第一反应其实会是愣住，有千言万语没法说出来，不过拖了好几个礼拜觉得总这么拖着也不好，就硬着头皮写一下。\nPlan9 大概要从它的历史说起，Plan9 脱胎于贝尔实验室，没错 ，就是那个诞生了 UNIX 和 C 语言的地方，而且 Plan9 的设计团队的领导者正是 Rob Pike 和 Ken Thompson，诞生的定位就是一个\u0026rsquo;更好的\u0026rsquo; UNIX。主要是为了解决 UNIX 的一个问题，其哲学里面虽然有：一切皆是文件，但是随着时间的发展，新的模块不停的加入，对这条原则开始没有那么的坚守，一个例子：TCP/IP 协议栈和 BSD-Style Socket，回想当初学网络编程的时候，学习到 socket 的时候就觉得有点别扭，socket 的 API 长得有点像 UNIX 的文件系列的 API，但是名字和行为却有点不一样，而且 socket 很显然不是一个文件，我相信很多开发者有过同样的困惑。其实 Plan9 就是希望将这条哲学带回来并严格的贯彻，例如刚才网络的例子，我们看看 Plan9 是如何处理的：\n(在 Plan9 中完全用 shell 操作模拟 HTTP 的过程，全程都是用文件操作的命令)\nPlan9 另外一个超前的设计是：这是一个面向纯分布式环境设计的操作系统，我一直觉得分布式应该是一个和操作系统抽象无关的特性，一个很好的例子就是 plan9 的文件系统：9pfs。9pfs 的设计是可以作为一个分布式文件系统，也就是你可以 mount 一块远程的文件夹，分布式存储细节全部也隐藏在了文件系统的抽象之下；更绝的是，我们现在经常提到的「计算存储分离」，在 plan9 中已经都落地了（90年代初），plan9 把机器分成几种类型：cpu servers（计算密集型），file servers（IO 密集），terminal servers (终端)；通过 rcpu 在本机里面会启动一个新的 term，类似 ssh，然后将本地的文件系统挂载给远端的 cpu server 上，相当于给本地的机器换了个 CPU，这是我见过最简洁和最完整的计算存储分离。\n其实 Plan9 从某种意义上来说间接影响了我们现代的分布式系统设计，原因是其实这帮大牛作者（Rob Pike，Ken 等人）从贝尔实验室离开后加入了 Google 搞 Infra，其实仔细看看 Borg / GFS(Colossus)，以及 Google 内部很多服务都是一股浓浓的 plan9 的味道：通过文件系统作为抽象屏蔽掉分布式的细节。Google 的这些系统通过一篇篇论文影响着整个行业，从这个角度看，plan9 也算成功了。\n写在最后 一个优秀的软件，在日常使用或者阅读源码或者学习它的设计的时候，总是能隐约感受到其设计者清晰的主线，或者说是‘世界观’或者‘道’，不分大小，大的如同 Plan9 ‘一切皆是文件’ 的宣言，小的如同 Lua 中的 table （用过 Lua 的朋友一定知道我在说什么）。一个好的主线应该是清晰，简洁，优雅的，你可能看不见它，但又感觉无处不在。在这个焦虑作为底色的时代，一切都变化得太快，我们因为自身如何适应这个不断变化的世界而焦虑，我们以及我们所造的系统都在不停的追求迭代和进化，而进化密码可能是隐藏在这些亘古不变的古老智慧里面。懂得欣赏这些‘不变’的美，会让我们更清晰的了解自己，了解自己应该做出什么样子的软件，也可以更从容的面对这个不停变化的世界。\n其实本来写到这里就应该结束了，我写完上一句愣了一下，因为事实上，这个世界并不是美的总是最后的胜利者，美学角度的优雅只是一个优秀软件的很多优秀方面中的一小部分（甚至不是最重要的），所以最后也是想提醒一下各位，美的东西通常会让人沉迷，这在某种程度上会让人看不到的全局。所以按照惯例，我想分享一段话，作为这篇文章的结尾和大家共勉，这篇文章是 Eric Raymond 在一篇 Blog 中总结 Plan9 的失败时写道的 ：\n Compared to Plan 9, Unix creaks and clanks and has obvious rust spots, but it gets the job done well enough to hold its position. There is a lesson here for ambitious system architects: the most dangerous enemy of a better solution is an existing codebase that is just good enough.\n ","permalink":"http://c4pt0r.github.io/posts/zen-and-the-art-of-programming/","summary":"‘不立文字，直指人心’ \u0026mdash; 六祖慧能\n昨天正好在飞机上把原研哉的又一本关于设计的书看完了，书名就不提了，大概仍然是原研哉老师用他那种特有的平静的口吻描述关于设计的思考和社会的观察，引起了我对于软件设计审美的一些思考。熟悉我的朋友大概知道我一向对艺术和哲学有着偏爱，尤其是东亚的古典美学，看似离所从事的计算机行业很远，但是我一直认为在代码深处存在着相同的审美趣味。正好试着总结一下作为第二篇关于系统设计品味的文章，上次如果说是一篇关于‘术’的文章，这篇可能会更有‘道’的味道 :)。不过关于审美的事情通常是带着强烈的个人偏好，而且就像任何其他艺术形态一样，审美也是有流派的，如果对本文描述的东西不认同也实属正常，一笑了之就好。\n东方美学的内核 在聊软件之前，我们先聊一下美学。仔细想想也蛮有意思的，长期以来我们都认为计算机科学是更加偏向工程学的范畴，也就是所谓的软件工程，但看看接近的学科，例如建筑，我们很自然的能够将泥瓦匠和建筑设计师看作是两种不同的职业，但是对于程序员和软件设计师很多时候是一体，于是对于系统设计品味的讨论通常会和工程学乃至管理学混在一起，即使有对于美学的讨论，也只是在一些 Geek 和 Hacker 的亚文化中，隐藏在一个个看似戏谑但是充满禅意的 Puns 和 Wordplay 里面，例如在 ESR 的《How To Become A Hacker》一文中关于 Hacker 生活方式中对禅宗和禅修的推崇可见一斑，我其实还蛮庆幸在我刚接触编程的年代（90年代中后期）赶上了黄金年代的尾巴，得以一窥，现在的年轻 Geek 们只能在计算机考古学中体验了 :)。\n为了避免牵扯太多其他的内容，大概的范围会限定在禅宗和道家的审美，而且只会从‘表’上分析，内在的哲学和宗教的内容不会过多涉及。说到这个话题，大家不妨在脑子里想象一下典型的东方审美的例子：寥寥几笔加上大片留白的水墨画，雾气缭绕的山脉，日式枯山水庭院，Wabi-sabi，离日常生活近一点的，例如优衣库，无印良品，苹果（乔布斯时代）\u0026hellip;如果总结几个关键字就是：崇尚简洁，没有攻击性，平静含蓄的表达，以小见大（通过小的细节隐喻出更大的意境）\u0026hellip;值得注意的是，这并不是回避世界的复杂性，而是强调隐藏在复杂性的表面背后的根源是极简要素加上自洽的规则。\n其实有这种审美倾向丝毫不意外，禅宗的内核中有很浓的存在主义和本体论色彩，例如铃木大拙（当代最有名的禅学大师之一，在西方尤其受到推崇）关于意识以及一切可能性的根源，也就是他口中的 Cosmic Unconscious 概念，又如道家的老子在道德经中关于‘道’的描述：\u0026lsquo;有物混成，先天地生\u0026hellip;道生一，一生二，二生三，三生万物\u0026hellip;'，都是关于这个审美内核精彩诠释，当然严格来说，道家和禅宗在审美上还是有一定区别的，道家更加崇尚与自然的融合，顺其自然，用当下流行的话就是‘躺平了’，是一种出世的美学，但是禅宗更加严肃，只为了达到心物合一的顿悟。但在表面上，这类东方的古典审美其实倒是暗合了当代西方的包豪斯设计的一些理念：简单并不意味着简陋，而是舍弃掉一切无用的装饰，直指本源。只是对于包豪斯来说，本源大致是从实用主义角度出发，东方这边的含义更深且丰富而已。\n复杂系统的简洁之美 回到计算机的世界，复杂总是不可回避的，人类总是会在不停尝试创造超出自己理解边界的事物，正所谓创新。而且无穷的复杂性用有穷的代码来表示，本身就是一件非常充满禅学审美的事情。就像我经常举的一个例子：大家有没有想过，TiDB 核心大概百来万行代码，运行在 3 台机器上和运行在 3000 台机器上一样，都是这百来万行代码，但是 3 台机器的复杂性和 3000 台机器复杂性确是千差万别，人肉管理 3 台机器很轻松，但是管理好 3000 台机器，让它们高效稳定的协作这件事情，肯定超出了人作为个体的能力范围，等一下后面我会再聊到 TiDB 的例子。 同样的例子还有很多，例如大家比较熟悉的 Unix 哲学，已经有无数人阐述过，我也不追溯，后边我会用几个比较新鲜的例子，用来阐述复杂系统的简单之美，来让大家体会一下其中妙处。\n元胞自动机 第一个例子，我想聊聊元胞自动机（Cellular Automata），元胞自动机大概是 50 年代由冯诺依曼提出的一个自动机模型，听名字很高级，但事实上非常非常简单，简单到小学生都能马上理解：想象一个 n 维度的无限网格（最好理解的是 2 维，大概就是类似棋盘的样子），每个格子会处于有限的状态，t 作为离散的时间概念，每一个 t 时刻的网格中每一个格子的状态是由 t - 1 时刻这个的格子的邻居格子（ 2 维里面就是上下左右的几个）的状态决定，注意所有的格子都是平等的，受到同一种规则的支配。实现这么一个自动机，也就是百来行代码，最有名的实现是 Conway 的 Game of Life，生命游戏是一个二维的 CA 实现，想象每个格子是一个细胞，规则很简单（来自 Wikipedia）：","title":"东方美学与软件设计"},{"content":"最近有一件事情让我印象特别深刻，作为引子和大家唠一唠：我们在内部做一些极端的流量回归仿真实验时，在 TiKV（TiDB 的分布式存储组件）上观测到了异常的 CPU 使用率，但是从我们的 Grafana Metrics、日志输出里面并没有看到异常，因此也一度困惑了好几天，最后靠一位老司机盲猜并结合 profiling 才找到真凶，真凶出现在谁都没有想到的地方：Debug 用的日志模块（澄清一下：目前这个 Bug 已经修复了，而且这个 Bug 的触发是在非常极端压力的场景下+日志级别全开才会出现，请各位用户放心）。\n这篇文章并不是做 Bug 分析，我觉得更重要的是，找问题过程中我们使用的工具、老司机的思考过程。作为一个观察者，我看到年轻的同事看着老司机熟练地操作 perf 和在各种各样工具和界面中切换那种仰慕的眼神，我隐约觉得事情有点不对：这意味着这门手艺不能复制。\n事后，我做了一些关于基础软件用户体验的调研，发现该领域的理论和资料确实挺少（大多数是 ToC 产品的研究，系统软件相关的大概只有 UNIX 哲学流派），而且缺乏系统化，依赖于作者个人「品味」，但是软件体验的好和坏显然存在，例如一个有经验的工程师看到一个命令行工具，敲几下就知道是否好用，是不是一个有「品味」的工具。\n很多时候「品味」之所以被称为「品味」，就是因为说不清道不明，这固然是软件开发艺术性的一种体现，但是这也意味着它不可复制，不易被习得。我觉得这也不好，今天这篇以及可能接下来的几篇文章（虽然后几篇我还不知道写啥，但是先立个 Flag）会试着总结一下好的基础软件体验到底从哪里来。\n作为第一篇，本文将围绕可观测性和可交互性两个比较重要的话题来谈。至于为什么把这两点放在一起聊，我先卖个关子，最后说。\n可观测性 可观测性是什么？这可从我两年前发表的 《我眼中的分布式系统可观测性》 [1]一文中可见一斑，相同的内容我在这里就不赘述。随着在 TiDB 中对可观测性实践的深入，对这个话题有了更深的理解，为了更好的理解，我们首先先明确一个问题：当我们在聊可观测的时候，到底是谁在观测？\n是谁在观测？ 很多朋友可能会一愣，心想：这还用说，肯定是人，总不能是机器。没错，的确是人在观测，但就是这么一个浅显的道理往往会被软件设计者忽略，所以这两者的区别到底是什么？为什么强调人这个主体很重要？\n要回答这个问题，需要清楚一个现实：人的短期工作记忆是很有限的。大量的心理学研究表明，人类工作记忆的容量大致只有 4，即在短期同时关注 4 项信息 [2]，再多的信息就要靠分模块的方式记忆，如我们快速记忆电话号码的方式，以 13800001111 为例，我们通常不是一个个数字背，而是形如：138-0000-1111 进行分组。\n在了解人的心智模型的一些基础假设和带宽后，我想很多系统软件开发者大概不再会炫耀：我的软件有 1000 多个监控项！这不仅不是好事，反而让更多的信息破坏了短期记忆的形成，引入了更多的噪音，让使用者在信息的海洋里花很多时间找关键信息，以及不自觉的分类（我相信大脑的一个不自觉的后台任务就是对信息建索引和分类，注意这同样是消耗带宽的），所以第一个结论：软件应用一屏的界面里面最好只有 4 个关键信息。那么，接下来的一个问题是：哪些是关键信息？什么是噪音？\n区分关键信息和噪音 这个问题没有标准答案。对于系统软件来说，我的经验是：跟着关键资源走。软件其实很简单，本质就是对硬件资源的使用和分配，讲究平衡的艺术。关键的硬件资源无非也就下面几个，对于下面每一个关键资源在某个采样时间段（单点没有太多意义），都可以通过一些简单的问题的询问，得到对系统运行状态的大致图景：\n CPU：哪些线程在工作？这些线程都在干嘛？这些线程各自消耗了多少 CPU Time？ 内存：当前内存中存储了哪些东西？这些东西的命中率情况？（通常我们更关注业务缓存）？ 网络 I/O：QPS/TPS 有异常吗？当前主要的网络 I/O 是由什么请求发起的？带宽还够吗？请求延迟？长链接还是短链接（衡量 syscall 的开销）？ 磁盘 I/O：磁盘在读写文件吗？读写哪些文件？大多数的读写是什么 Pattern？吞吐多大？一次 I/O 延迟多大？ 关键日志：不是所有日志都有用，只有包含特定关键字的日志，人们才会关心。所以，有没有特定关键字的日志出现？  通过以上标准问题的灵魂拷问，必定可以对系统运行状态有一定的了解。\n 更进一步的关键是，这些系统的指标一定要和业务上下文联系在一起才能好用，举例说明，对于一个支持事务的数据库来说，假设我们看到 CPU 线程和 call stack，发现大量的 CPU 时间花在了 wait / sleep / idle 之类的事情上，同时也没有其他 I/O 资源瓶颈，此时，如果只看这些的数字可能会一脸懵，但是结合事务的冲突率来看可能柳岸花明，甚至能直接给出这些 lock 的等待时间都花在了哪些事务，甚至哪些行的冲突上，这对观测者是更有用的信息。  也并不是说其他的信息就没用，而是相当多的信息的价值是后验的，例如：绝大多数的 debug 日志，或者那些为了证实猜想的辅助信息，其实在解决未知问题时候几乎没有帮助，而且还需要观察者有大量的背景知识，这类信息最好的呈现方式还是折叠起来，眼不见为净的好。\n如果打开 TiDB 的内部 Grafana 就会看到大量这样的指标，如 stall-conditions-changed-of-each-cf（虽然我知道这个指标的含义，但是我猜 TiDB 的用户里 99% 的人不知道），而且从名字里面我看到了写下这个名字的工程师内心的挣扎，他一定很想让其他人（或者自己）看懂这个名字指的是什么，但是比较遗憾，至少在我这里没有成功。\n观察的下一步是什么？作出行动。\n在做出行动之前想想，有行动的前提是什么？我们处理问题的行动大致会遵循下面模式（我自己总结的，但任何一本认知心理学的书都会有类似的概念）：观察—\u0026gt;发现动机—\u0026gt;猜想—\u0026gt;验证猜想—\u0026gt;形成计划—\u0026gt;行动，然后再回到观察，反复循环。\n这个里面人（或者是老司机的经验）体现比较重要地方是在从观察到猜想这个环节，至于观察的动机而言无非有两种：\n 解决眼前的故障； 规避潜在的风险（避免未来的故障）。  假设系统没有问题，也不太需要做出改变。 我觉得这两步之所以重要，是因为基本上其他环节都可以用自动化，唯独这两步很难，因为需要用到：人的知识/经验和直觉。\n对于一个拥有好的可观测性的系统，通常都是能很好利用人直觉的高手，举个小的例子：当打开一个系统后台界面时，我们试着不去关注具体的文字信息，如果界面中的红色黄色的色块比较多，我们的直觉会告诉自己这个系统可能处于不太健康的状态，更进一步如果红色和黄色大致都聚集在屏幕的某个具体位置上，我们的注意力一定会聚焦到这个位置；如果一个界面上全是绿色，那应该是比较健康的状态。\n怎么最大化利用人的直觉？或者说要引导到什么地方？我认为最好的点是：风险的预判。\n人的直觉用在哪？风险的预判 此处需要利用一些先验知识。在聊这个话题之前，我想分享一个我之前听过的小故事，当年福特工厂里有个电机坏了，然后找了个老师傅，他听了听声音，看了看机器运转情况，最后用粉笔在电机上画了一条线，说这个地方的线圈多绕了多少多少圈，将信将疑的工人们照做，果然问题解决了，然后老师傅开了个 1 万美元的维修费（当时算是天价），福特的老板问他凭啥画一条线就收那么多钱，老师傅开了个账单：画线 1 美元，知道在哪画这条线 9999 美元。\n故事的真假暂且不聊，假设是真的，我们可以看到直觉和经验，真的是能产生很多的价值，我当时听到这个故事的第一反应是，这个老师傅肯定这种情况见的多了（废话），而且这个问题一定是常见问题。\n其实解决问题最难部分是通过观察（尤其是一些特征点）排除掉绝大多数不靠谱的方向，另外要相信常见故障的原因是会收敛的。这时一个具有良好可观测性系统的第一步就是能给使用者的直觉指引方向，这个方向就需要前人的知识来给出可能性最大的故障点以及相关的指标（例如 CPU 使用率等）；第二步就是通过一些心理学小技巧把它展现出来。\n下面以 TiDB 中即将会引入的一个小功能 TopSQL 加以佐证。这个功能说起来也很简单，我们发现很多用户故障都和少量的 SQL 相关，这类的 SQL 的特征是拥有和别的 SQL 有明显不同的 CPU footprint，但是每一条 SQL 的 footprint 独立看起来还挺正常的，所以 TopSQL 的功能就是回答：CPU 到底消耗了多少？在哪些 SQL 上？我试着不去解读下面这个截图，我猜聪明的你马上就能知道怎么用：\n你的直觉会告诉你，后半段那段密集的绿色占比好像和其他有什么不一样，将整体的 CPU 使用率推高了，感觉有问题的样子，没错，这大概就是正确的方向，好的可视化能够利用人的直觉快速定位主要矛盾。\n什么叫做“一个操作”？识别操作的真正的生命周期 刚才写第一点的时候想到还有一个经常被人忽略的关键资源：时间。本来想把时间放到关键资源那节里面，但是想了想放在这里可能更加合适。\n稍微形而上一点来看，我们现在的计算机都是图灵机的实现，我小学就知道图灵完备语言的最小功能集合：读/写变量，分支，循环。用文学一点的说法是：所谓程序就是无数个轮回，大轮回嵌套着小轮回（循环），每个轮回中根据现状（变量）不断的做出选择（分支）。\n我说到这里可能聪明的读者会猜到我想说什么：如果我们讨论可观测性脱离了周期，就毫无意义。而周期的定义又是灵活的，对于人而言，大周期显然是一辈子，小周期可以是一年一日，甚至周期可以不用时间跨度作为单位，比如一份工作的周期…\n对于一个数据库软件而言，什么是一个合理的周期？是一条 SQL 的执行周期？还是一个事务从 Begin 到 Commit ？这里没有标准答案，但是我个人建议，周期越贴近终端用户的使用场景越实用。\n譬如，在数据库中，选择单条 SQL 的执行作为周期不如选择事务的周期，事务周期不如应用程序一个请求全链路的周期。其实 TiDB 在很早就引入了 OpenTracing 来追踪一个 SQL 的执行周期内到底调用了哪些函数，花费多少时间，但最早只应用在了 TiDB 的 SQL 层内部（熟悉我们的朋友应该知道我们的 SQL 和存储是分离的），没有在存储层 TiKV 实现，所以就会出现一条 SQL 语句的执行过程往下追到 TiKV 就到了一个断头路。\n后来我们实现了把 TraceID 和 SpanID 传到了 TiKV 内部这个功能才算初步可用，至少把一个周期的图景变得更加完整了，本来我们打算就止步于此，但是后来发生了一个小事情，某天一个客户说：为什么我的应用访问 TiDB 那么慢？然后我一看 TiDB 的监控，没有啊，SQL 到数据库这边基本都是毫秒就返回了，但是客户说：你看我这个请求也没干别的呀，两边怎么对不上？后来我们把 Tracer 加进来以后才知道客户这边的网络出了点问题。\n这个案例提醒了我，如果能做到全链路的 Tracing，这里的全链路应该是从业务端请求开始计算，去看待生命周期才有意义。所以在此之后我们在 TiDB 里面通过拓展 Session Variable，能够支持用户将 OpenTracing 协议的 Tracer 信息通过 Session Varible 传入到 TiDB 的体系中，打通业务层和数据库层，能够真正实现的一个全生命周期的跟踪，这个功能也会在很近的未来的版本中和大家见面。\n说了这么多，总结几点：\n 时间也是重要资源。 抓 Sample 也好，做 Trace 也好，选对周期很重要。 周期越贴近业务的周期越有用。  可观测性能救命的时刻：事后观测 我相信没有人会没事天天看着监控界面，其实仔细想想，当我们需要可观测性的时候，多数是已经出现了可感知的故障或者很明确的风险。此时的系统可能已经“病入膏肓”，或者在火烧眉毛的时候还不知道啥原因导致，其中的根因或是之前某个时间的一些不太显然的异常变化，这时候发现之前除了正常的 Metrics 外并没有更多的信息，我们当然不会永远开着 CPU Profiler，通常 Profiler 都是手动触发，但是如果是在事后复盘原因的时候，能够有事发之前的 CPU Profile 记录，对于问题的解决和归因会有巨大的帮助，所以一个比较好的方案是：在一个相对短的时间间隔下（比如分钟级）自动的开启 Profiler，自动把诊断结果保存下来，就像定期做一个深度体检记录一样，老的记录定期删除就好了，万一出事，可以快速往前回溯，救命的效率会更高。\n另外相信我，做 Profile 其实也不会有什么明显的性能损耗（何况还是间歇性的），这个功能我们叫做：Continuous Profiling，这个功能很实用，也会很快和大家见面。\n根据我们的经验，结合上面一节，有了完善的 Tracing 系统，大部分的 Debug 过程在 Tracing + Log 就能找到问题的根因。\n最好的可观测性是能够指导用户：“我接下来该做什么？” 上文中提到了行动，我在观察老师傅处理问题的时候发现一个特别有意思的现象：有经验的开发者总是能够很快通过观测，决定自己接下来该做什么，不需要查阅资料什么或者等着别人指导，完全处于一个心流的状态（例如在 TiDB 里面看到数据在集群内部分布不均或者有热点，就知道去修改调度策略或者手工 split region），但是新人在这一步总是会卡着，要么去 Google 要么去翻文档，内心OS：「我看到问题了，然后怎么办？」，如果这个时候，系统能够给一些接下来应该观测哪些指标，或者行动建议，会更加友好，目前能做到这一点的系统不多，如果能做到这一点，相信你的系统已经在可观测性上做得很棒了。把这个点放在可观测性的最后其实是想借着这个话题引出可交互性。\n可交互性 在聊基础软件的可交互性之前，我想先和大家回顾一下计算机的历史，在我看来计算机历史的一个侧写就是人机交互的进化史：从第一张图，看着一堆线我也不知道怎么操作，到现在我从来没看过 iPhone 的说明书就能够熟练使用，这个背后其实是多个学科的进步（包括不限于心理学、认知科学神经科学、哲学、计算机科学）。\n回到我们这个领域，基础软件这个领域因为离大众确实有点远，过去很多设计是由工程师完成的，我们这类人，普遍有点缺乏对人性的理解（no offense ），一个很典型的逻辑是：“我自己是人，所以我了解人。我的设计自己能理解，因为我是人，所以别的人也能理解。如果别人不会用，就去看看文档就好了（此时还有一个嫌弃脸）”。\n当我们复盘一些故障时，经常会得出「使用者操作不当」的结论，但是这真的是根因吗？我在之前的公司曾经历过一个事故给我留下了深刻的印象：当时内部有一个自己做的分布式文件系统，就像所有的文件系统一样，它有一个 shell，可以支持一些 UNIX Style 的命令操作。\n有一次，一个工程师执行了一行命令：rm -rf /usr /local/\u0026hellip;（注意 /usr 后边的空格），然后系统很听话的开始删除自己\u0026hellip;最后这件事情的复盘并没有责怪这个操作者，而是惩罚了这个系统的设计者（当时那个公司的老板），因为这是个坏的交互设计，哪怕在删除重要文件夹前确认一下或者通过权限系统保护一下都不至于发生这个事情，机器确实在按照逻辑工作，这个地方也没有 Bug（甚至这个删除还很高效，毕竟分布式系统 LOL）。\n在后来作为工程师漫长的岁月中，我渐渐理解到一个道理：最好的工程师能在逻辑和感性中间找到一个平衡，良好的设计源于对技术和心理的理解，毕竟我们是在为人写程序。\n作为软件的使用者，我们与其说是在使用，不如说我们是在和软件「对话」。那既然是对话，那么就意味着这是一个交互的过程，什么是一个好的交互体验呢？我试着总结一些写给软件设计者的原则，试着第一次干这事，不排除以后会补充。\n没人读文档：一条命令启动和探索式学习 承认吧，没有人会看说明书。我们拿到一部新的 iPhone 时候，第一反应一定是开机（很神奇吧，我们似乎下意识就知道开机键在哪）肯定不是看说明书找开机按钮，开机就开始通过手指来探索新的世界，很浅显的道理，为什么在系统软件领域就要先熟读文档才能上岗呢？\n我经常教育我们年轻的产品经理：“你的用户充其量会在你的 GitHub 首页或者文档的 Quick Start 部分上停留 10 秒，甚至连看完这个文档的耐心都没有，他们的潜意识会寻找「深色背景的字」（shell 命令），然后把里面东西复制到自己的终端里看会发生什么，除此之外啥都不会做，如果这第一条命令失败了，不会再有后面什么事了，所以记住你只有一次机会”。\n一个小例子就是当时在做 TiUP（TiDB 的安装部署工具）的时候，我反复告诫 TiUP 的产品经理，首页里不要废话，就一句命令，贴进去就能用：\nTiUP 的首页（tiup.io）截图\n其实这个例子可以更延展一点，我记得疫情之前有一年我在布鲁塞尔参加 FOSDEM，晚上在会场附近的酒吧和一位来自英国的 DevOps 聊天，可能也是喝多了，他说：“不能用一个 apt-get install 就安装成功的系统软件不是一个好软件”，话糙理不糙。\n那你可能要问，如果确实有一些信息或者概念需要传递给用户，如果用认知心理学里面的概念，可称之为构建 Mental Model（心智模型），最好的方式是什么呢？我自己的经验是：探索式的学习。支持这种认知构建模式的系统通常需要有 Self-Explanatory 的能力，即告诉用户第一步（例如 iPhone 的开机）之后用户的每一步都能够利用上一步行为的输出，决定下一步的行为完成学习。\n举个例子：MySQL 的系统表想必 MySQL 的用户都不会陌生，你只要用一个交互式的 mysql-client 链接到一个实例上，也不用等着系统告知 INFORMATION_SCHEMA 里面有什么，只需要用户 SHOW TABLES 一下就知道了，然后再使用 SELECT * FROM 语句就可以一步步探索 INFORMATION_SCHEMA 里面具体表的内容。这就是一个 Self-Explanatory 的绝佳例子（这个例子里面有个前提就是 SQL 作为统一的交互语言）。\n另一个特别好的例子是 Telegram 的 Botfather，我相信给 Telegram 写过机器人的朋友一定会对 Botfather 的好用程度印象深刻，我放一张图你就懂了：\n用 Telegram 的 botfather 创建聊天机器人的过程\nTelegram 是一个聊天软件，Botfather 巧妙的利用了 IM 的交互模式应用到了一个相对枯燥的 bot 开发流程里面，而不是冷冰冰的丢给用户一个 URL https://core.telegram.org/bots/api ，让用户自己研究去。\n这一节最后一句话想送给大家，有一个无从考究的都市传说是这么说的：鱼的记忆时间只有 7s，我想说，人也一样。祝你做出一个“鱼”都能用好的软件。\n帮用户多想一步，告诉用户半步，让用户自己走半步 我很喜欢看科幻小说，很多科幻小说探索的一个终极哲学话题：我们是否真的有自我意识？尽管我们认为我们有，但是在软件输出 Unknown Error 的时候，你肯定希望有一个声音告诉你接下来该怎么办，对吧？ 一个优秀的基础软件，在输出负向反馈的时候，最好的做法就是建议开发者接下来该干嘛。我举一个很经典的例子，所有的 Rust 开发者都有过被编译器调教的日子，但是这个过程严格来说其实并不痛苦，比如，看下面的截图：\nPlain Text error[E0596]: cannot borrow immutable borrowed content `*some_string` as mutable --\u0026gt; error.rs:8:5 | 7 | fn change(some_string: \u0026amp;String) { | ------- use `\u0026amp;mut String` here to make mutable 8 | some_string.push_str(\u0026quot;, world\u0026quot;); | ^^^^^^^^^^^ cannot borrow as mutable 之所以不痛苦是因为编译器明确告诉了你哪里有问题、原因，以及下一步应该干嘛，普通编译器可能打印一个 cannot borrow as mutable 就仁至义尽了，但是一个好体验的编译器会多帮你想一步。\n回到自我意识的问题，我之前听过一个段子：一个测试工程师走进一家酒吧，要了 NaN 杯 Null，一个测试工程师化装成老板走进一家酒吧，要了500杯啤酒并且不付钱，一万个测试工程师在酒吧门外呼啸而过，一个测试工程师走进一家酒吧，要了一杯啤酒'；DROP TABLE，最后测试工程师们满意地离开了酒吧，然后一名顾客点了一份炒饭，酒吧炸了 LOL。\n这个故事告诉我们，作为软件设计者，你永远没有办法穷举使用者的想法，与其让用户放飞想象力，不如你自己设计好故事线，一步步让用户跟着你的思路走。但是为什么还要留半步？我的答案：\n 「参与感」会带来幸福感，人有时候挺矛盾的，一边希望机器自动干完所有的事，一边还期待自己有主动权。有时候即软件已经知道下一步一定是做某些事情，但是留下临门一脚让操作者完成相当于把成就感都赋予了操作者。 选择的权利交给操作者，尤其在面对一些单向门的决定时，go or no-go 还是应该交给人。  对于这点，我还有几个小建议：\n 对于一些操作可能会引发多个连续操作的模式（例如 terraform 的部署脚本，或者集群变更之类的功能），提供一个 Dry Run 模式是必要的，只输出操作，不执行操作。 对于上面这种批处理型的操作，尽可能设计 save point，不用每次都重新来（类似断点续传），体验会好很多。 遇到真的 Unknown Error 要输出各种帮助 Debug 的上下文信息，最后在错误日志里提示用户到哪个链接提 Github Issue，然后最好在 URL Link 里帮用户把 Issue Title 填好（让用户自己决定是不是发 Issue）。  统一语言：控制器和控制对象 我访谈过很多系统工程师，我有个必问的问题：你心中最好用的（数据库） cli 工具是哪个？绝大多数几乎下意识的回答 redis-cli。其实我自己也会给出同样的答案，后来我想这是为什么呢？\n「控制器」-「被控制对象」是一个在基础软件中非常常见的模式，就像我们在操作电视机的时候，绝大多数时间是通过遥控器一样，所以可以认为用户对电视机的第一和大多数触点其实是遥控器，所以类比到基础软件中，对于控制器的设计其实非常关键，做好控制器，我觉得关键点是：\n 构建统一的交互语言 自洽且简洁的概念模型  我稍微用 redis-cli 作为例子解读一下。使用过 redis-cli 的朋友都知道，所有的操作都遵循 [CMD] [ARG1] [ARG2] \u0026hellip; 的模式，在 redis-cli 没有例外，不管是操作数据，还是修改配置，所有的一切都在一个统一的交互语言下，而且这个语言一目了然，而且这个语言里面有一些很自然的约定，例如命令（CMD）永远是几个不包含符号的字母组成。\nBash redis 127.0.0.1:6379\u0026gt; SET k v OK redis 127.0.0.1:6379\u0026gt; DEL k (integer) 1 redis 127.0.0.1:6379\u0026gt; CONFIG SET loglevel \u0026quot;notice\u0026quot; OK redis 127.0.0.1:6379\u0026gt; CONFIG GET loglevel 1) \u0026quot;loglevel\u0026quot; 2) \u0026quot;notice\u0026quot; redis-cli 的交互例子\n其实这点在刚才提到探索式学习那节 MySQL 的例子也是一样的，SQL 本身就是一个统一的交互语言，只是没有 Redis 这么直观。\n第二点是概念模型，Redis 的优势在于它是一个 Key-Value 数据库，所以概念很简单：一切都是 Key-Value，观察它的 cli 工具，你仔细品一品就知道，作者在尝试将所有的功能和交互都往这个 Key-Value 的模型上映射，这个是很自然的，因为我们之所以会使用 redis-cli，首先是我们接受了 Redis 是一个 KV 数据库的现实，所以在使用 redis-cli 的时候的一个自动就成立心智假设就是 Key-Value 模式，这在使用 cli 的时候一切的操作都会变得很自然。这一点在很多优秀的数据库软件里面应用的很多，例如 Oracle，理论上可以依赖 SQL 来对软件本身做所有操作，因为用户只要在使用 Oracle 就默认应该是知道关系模型和 SQL。\n说了正面的例子，我们聊个反例：大家知道 TiDB 主项目（不包括其他工具，例如 cdc、binlog）至少有 3 个 Controller 工具：tidb-ctl /tikv-ctl / pd-ctl，虽然 TiDB 确实是一个由多个组件组成的分布式系统，但是对于用户来说，多数时候使用对象其实是 TiDB 作为一个整体（数据库软件），但几个 ctl 的使用方式都不太一样，比如说 pd-ctl 是一个可交互式的控制器，而且影响的范围大概是 pd 本身和 tikv，tikv-ctl 的功能上也有一些交集，但是只是针对单个 tikv 实例使用，这点太令人费解了，tikv 明明是一个分布式系统，但是 tikv-ctl 却是一个针对单点的控制器？那么控制 tikv 到底应该用的哪个 ctl 呢？答案：多数时候用 pd-ctl（惊不惊喜，意不意外？）。\n就像你有一个电视机，但是需要用三个遥控器来控制，而且真正控制电视的那个遥控器叫做：机顶盒，这种问题在日常生活中大家都认为是一个理所应当的设计问题，但是在基础软件领域大家的容忍度怎么似乎突然就变高了？\nNo Surprise: 不怕麻烦，就怕惊喜（惊吓） 我不知道是否是一个普遍现象，基础软件的用户在面对错误（尤其是因为坏交互造成的），通常会先自责和内疚，认为是自己的问题，很少会归因于软件。尤其是当能够比较熟练的操作一些复杂又分裂的软件的时候，很多人会觉得这是一种「技能」，毕竟没有人愿意别人看着自己的笨拙操作。\n这背后其实有着很深层次原因（Hacker Culture 里面多少有点崇尚复杂的倾向），但是我想说：这就是的软件的问题！就像我从不避讳说我就不会用 gdb，不是因为我智商不行而是因为这个东西真是太难用了。\n但是我见过很多人真的是以熟练使用命令行 gdb 作为炫耀的资本，回到前面提到的那个反例，我在一个 TiDB 的深度用户那边观察他们的操作员做日常的运维，这个操作员非常熟练的在各种 ctl 之间切换和操作，他不觉得有啥问题，甚至觉得有点厉害，后来我想了下，人的适应性还是很强的，真正让人困扰的事其实并不是麻烦，而是当你在对系统做出一个操作的时候，通常会带着一个下意识的假设，例如一个功能的名字叫「xx开关」的时候，用户在打开开关的时候的预期应该是有一个正反馈，但是如果结果并不是这样的话，用户会非常有挫败感。这里有个真实的故事，我们在 TiDB 5.0 里面引入了一个新功能，叫做 MPP (Massively Parallel Processing)，即大规模并行处理，我们有个开关配置叫做：tidb_allow_mpp\n不知道大家有没有注意到问题：作为一个开关型的配置，当设置成 OFF 的时候，是一个 100% 的负反馈，这没有问题，但是问题在设置成 ON 的时候，这个功能是否启用会依赖优化器的判断，也就是有一定概率 MPP 功能不会生效，这就像一个房间里有个控制灯的开关，当你关的时候，灯一定不会亮，当你开开关的时候，灯不一定亮（灯觉得房间内的光线足够，没必要亮\u0026hellip;），你一定不会觉得这个灯智能，你一定会觉得灯坏了。上面这个配置的一个更好的写法应该是:\ntidb_mpp_mode = ON | OFF | AUTO 这个写法我都不用解释，你也不用看文档，是不是一眼就明白怎么用？好配置应该是自解释的。通常来说，配置项是破坏用户体验的重灾区，后边讲反馈的时候展开讲讲。\nUNIX 哲学里面有一条「安静原则」，说的是如果程序没什么特别事情要表达，应该保持安静。具体的一个表现就是鼓励命令行程序如果成功执行，不需要输出东西的话，就直接以 0 作为 return code 退出就好了，其实对于这一点我是持保留意见的，用户的行为如果是符合预期的结果，应该用一个明确的正向反馈作为奖励（例如打印一个 Success 都好），不要忘了人性大师巴普洛夫。\n反馈：暴露进展，不要暴露内部细节 刚才正好提到了反馈，我觉得将反馈称为好体验中最重要的一环都不为过。学过控制论的朋友的都知道反馈是非常重要的概念，前面提到的 Self-Explanatory 之所以是个好体验就是因为反馈的及时性。\n但是我惊讶的是，很多基础软件在交互反馈部分设计得糟糕得令人发指，举一个我熟悉的例子，某些数据库软件在接收到一个复杂查询的时候，当敲下回车，通常就 Hang 在那里了，可能确实数据库程序在后边辛苦的检索和扫描数据，然后隔了几分钟直接返回一个结果（或者挂了），过程中并没有反馈扫描了多少数据和预期要扫描多少数据，其实这个体验是很差的，因为这个信息就是进展（这点上 ClickHouse 做得很好）。反馈是需要精心设计的，我的几个经验是：\n1.反馈一定要即时，最好是敲完回车后 200ms 内一定要有反馈（人的生理反应时间，超过这个时间反馈人就会有卡顿感），顺滑的感觉是靠反馈创造的。\n2.反馈进展，不要反馈细节，不要反馈需要上下文才能读懂的细节（除非是 Debug Mode），这里给出一个我们自己的反例（ https://asktug.com/t/topic/2017 ）：\nBash MySQL [test]\u0026gt; SELECT COUNT(1) AS count, SUM(account_balance) AS amount, trade_desc AS type FROM b_test WHERE member_id = 「22792279001」 AND detail_create_date \u0026gt;= 「2019-11-19 17:00:00」 AND detail_create_date \u0026lt; 「2019-11-28 17:00:00」 group by trade_desc; ERROR 9005 (HY000): Region is unavailable 这个 Case 坏在哪里呢？很显然，对用户来说，Region 是一个 TiDB 内部概念，一个很自然的问题是：什么是 Region（我在前面埋了个伏笔，不知道你注意到没有）？为什么 Select 数据和 Region 相关？为什么 Region is unavailable？我该怎么解决这个问题？暴露给用户这个信息是无用的，反而给用户创造了噪音。这个 Case 的原因是 TiKV 太忙，无法返回需要的数据，一个更好反馈应该是：具体的哪台 TiKV 因为哪些数据（用用户能理解的形式，如：哪张表，哪些行）读取不出来是因为 TiKV 太忙，最好还能告诉用户为什么忙，怎么解决，实在解决不了至少贴个 FAQ 的链接（我见过有软件直接贴 StackOverflow 的 Search URL 的 LOL）。\n3.对正反馈设置一些 milestone，例如一个服务器程序开始正常对外提供服务的时候，打印一个 Ascii Art，不同日志级别用一些带颜色 Label，这是给用户一个明确信号，这点 redis-server 做得很好。\n通常对于可交互命令行程序的反馈还是容易设计的，一个非常麻烦的事情是，基础软件通常非常依赖配置文件，配置的问题就是修改配置到确认生效的反馈周期通常很长，一个经常的场景是：修改配置 - 重启 - 观察效果，而且通常配置是存储在配置文件里面，这也造成修改文件操作的反馈感是极差的，因为用户也不知道到底这个操作有没有生效，尤其是一些配置的生效并不是太明显，一些比较好的实践如：程序在启动的时候打印一下读取了哪个配置文件以及这个配置文件的内容是什么；设计一个类似 print-default-config 之类的命令行功能，直接输出模板配置，省得用户自己 Google。\n另外对于分布式系统来说，配置的问题更加复杂，因为存在并不是本地配置和全局配置的区别，以及更新后的配置分发的问题，包括滚动重启的问题（重启进程才能让配置生效本身就不是一个好设计），老实说目前我还没有特别好的方案，可能的思路是是使用类似 etcd 这样的分布式全局配置中心或者（对于数据库来说）通过一些全局的配置表来实现。但是总体的原则是：集中比分散好；即时生效比重启生效好；统一交互（修改和读取配置的方式）比多种方式交互好。\n写在最后 终于写得差不多了，但是这篇文章我觉得仅仅是抛砖引玉，一定还有很多好的实践没有总结出来，也希望有想法朋友找我一起探讨，我揭晓一下最开篇留下的一个悬念，为什么要在第一篇文章中将可观测性和可交互性放在一起写，其实这个是来自经典的认知心理学中的人行动的模型[3]：\n当用户使用软件时，需要面对的两个鸿沟：一个是执行的鸿沟，在这里，用户要弄清楚如何操作，与软件「对话」；另一个是评估的鸿沟，用户要弄清楚操作的结果。我们作为设计师的使命就是帮助用户消除这两个鸿沟，正是对应到文章中的可观测性和可交互性。\n设计出使用起来令人愉悦的软件是一门艺术，也不见的比设计出一个精妙的算法或者健壮的程序简单，从某种意义上来说更加难，因为这要求设计者真的要有对人和软件两者都有深入的理解以及倾注感情，最后送给大家一段来自 Steve Jobs 的话共勉：\nThe design is not just what it looks like and feels like. The design is how it works.\n","permalink":"http://c4pt0r.github.io/posts/dx-in-system-software-1/","summary":"最近有一件事情让我印象特别深刻，作为引子和大家唠一唠：我们在内部做一些极端的流量回归仿真实验时，在 TiKV（TiDB 的分布式存储组件）上观测到了异常的 CPU 使用率，但是从我们的 Grafana Metrics、日志输出里面并没有看到异常，因此也一度困惑了好几天，最后靠一位老司机盲猜并结合 profiling 才找到真凶，真凶出现在谁都没有想到的地方：Debug 用的日志模块（澄清一下：目前这个 Bug 已经修复了，而且这个 Bug 的触发是在非常极端压力的场景下+日志级别全开才会出现，请各位用户放心）。\n这篇文章并不是做 Bug 分析，我觉得更重要的是，找问题过程中我们使用的工具、老司机的思考过程。作为一个观察者，我看到年轻的同事看着老司机熟练地操作 perf 和在各种各样工具和界面中切换那种仰慕的眼神，我隐约觉得事情有点不对：这意味着这门手艺不能复制。\n事后，我做了一些关于基础软件用户体验的调研，发现该领域的理论和资料确实挺少（大多数是 ToC 产品的研究，系统软件相关的大概只有 UNIX 哲学流派），而且缺乏系统化，依赖于作者个人「品味」，但是软件体验的好和坏显然存在，例如一个有经验的工程师看到一个命令行工具，敲几下就知道是否好用，是不是一个有「品味」的工具。\n很多时候「品味」之所以被称为「品味」，就是因为说不清道不明，这固然是软件开发艺术性的一种体现，但是这也意味着它不可复制，不易被习得。我觉得这也不好，今天这篇以及可能接下来的几篇文章（虽然后几篇我还不知道写啥，但是先立个 Flag）会试着总结一下好的基础软件体验到底从哪里来。\n作为第一篇，本文将围绕可观测性和可交互性两个比较重要的话题来谈。至于为什么把这两点放在一起聊，我先卖个关子，最后说。\n可观测性 可观测性是什么？这可从我两年前发表的 《我眼中的分布式系统可观测性》 [1]一文中可见一斑，相同的内容我在这里就不赘述。随着在 TiDB 中对可观测性实践的深入，对这个话题有了更深的理解，为了更好的理解，我们首先先明确一个问题：当我们在聊可观测的时候，到底是谁在观测？\n是谁在观测？ 很多朋友可能会一愣，心想：这还用说，肯定是人，总不能是机器。没错，的确是人在观测，但就是这么一个浅显的道理往往会被软件设计者忽略，所以这两者的区别到底是什么？为什么强调人这个主体很重要？\n要回答这个问题，需要清楚一个现实：人的短期工作记忆是很有限的。大量的心理学研究表明，人类工作记忆的容量大致只有 4，即在短期同时关注 4 项信息 [2]，再多的信息就要靠分模块的方式记忆，如我们快速记忆电话号码的方式，以 13800001111 为例，我们通常不是一个个数字背，而是形如：138-0000-1111 进行分组。\n在了解人的心智模型的一些基础假设和带宽后，我想很多系统软件开发者大概不再会炫耀：我的软件有 1000 多个监控项！这不仅不是好事，反而让更多的信息破坏了短期记忆的形成，引入了更多的噪音，让使用者在信息的海洋里花很多时间找关键信息，以及不自觉的分类（我相信大脑的一个不自觉的后台任务就是对信息建索引和分类，注意这同样是消耗带宽的），所以第一个结论：软件应用一屏的界面里面最好只有 4 个关键信息。那么，接下来的一个问题是：哪些是关键信息？什么是噪音？\n区分关键信息和噪音 这个问题没有标准答案。对于系统软件来说，我的经验是：跟着关键资源走。软件其实很简单，本质就是对硬件资源的使用和分配，讲究平衡的艺术。关键的硬件资源无非也就下面几个，对于下面每一个关键资源在某个采样时间段（单点没有太多意义），都可以通过一些简单的问题的询问，得到对系统运行状态的大致图景：\n CPU：哪些线程在工作？这些线程都在干嘛？这些线程各自消耗了多少 CPU Time？ 内存：当前内存中存储了哪些东西？这些东西的命中率情况？（通常我们更关注业务缓存）？ 网络 I/O：QPS/TPS 有异常吗？当前主要的网络 I/O 是由什么请求发起的？带宽还够吗？请求延迟？长链接还是短链接（衡量 syscall 的开销）？ 磁盘 I/O：磁盘在读写文件吗？读写哪些文件？大多数的读写是什么 Pattern？吞吐多大？一次 I/O 延迟多大？ 关键日志：不是所有日志都有用，只有包含特定关键字的日志，人们才会关心。所以，有没有特定关键字的日志出现？  通过以上标准问题的灵魂拷问，必定可以对系统运行状态有一定的了解。","title":"做出让人爱不释手的基础软件：可观测性和可交互性"},{"content":"我觉得面对测试的态度是区分一个普通程序员和优秀程序员的重要标准。现如今我们的程序和服务越来越庞大，光是单元测试 TDD 之类的就已经很难保证质量，不过这些都是 baseline，所以今天聊点新的话题。\n说测试之前，我们先问下自己，为什么要测试？当然是为了找 Bug。看起来这是句废话，但是仔细想想，如果我们能写出 Bug-free 的程序不就好了吗？何必那么麻烦。不过 100% 的 Bug-free 肯定是不行的，那么我们有没有办法能够尽可能地提升我们程序的质量？举个例子，我想到一个 Raft 的优化算法，与其等实现之后再测试，能不能在写代码前就知道这个算法理论上有没有问题？办法其实是有的，那就是形式化证明技术，比较常用的是 TLA+。\nTLA+ TLA+ 背后的思想很简单，TLA+ 会通过一套自己的 DSL（符号很接近数学语言）描述程序的初始状态以及后续状态之间的转换关系，同时根据你的业务逻辑来定义在这些状态切换中的不变量，然后 TLA+ 的 TLC model checker 对状态机的所有可达状态进行穷举，在穷举过程中不断检验不变量约束是否被破坏。\n举个简单的例子，分布式事务最简单的两阶段提交算法，对于 TLA+ Spec 来说，需要你定义好初始状态（例如事务要操作的 keys、有几个并发客户端等），然后定义状态间跳转的操作（ Begin / Write / Read / Commit 等），最后定义不变量（例如任何处于 Committed 状态的 write ops 一定是按照 commit timestamp 排序的，或者 Read 的操作一定不会读到脏数据之类的），写完以后放到 TLC Checker 里面运行，等待结果就好。\n但是，我们活在一个不完美的世界，即使你写出了完美的证明，也很难保证你就是对的。第一， Simulator 并没有办法模拟出无限多的 paticipants 和并发度， 一般也就是三五个；第二，聪明的你可能也看出来了，一般 TLA+ 的推广文章也不会告诉你 Spec 的关键是定义不变量，如果不变量定义不完备，或者定义出错，那么证明就是无效的。因此，我认为形式化验证的意义在于让工程师在写代码之前提高信心，在写证明的过程中也能更加深对算法的理解，此外，如果在 TLC Checker 里就跑出异常，那就更好了。\n目前 PingCAP 应该是国内唯一一个使用 TLA+ 证明关键算法，并且将证明的 Spec 开源出来的公司，大家可以参考 pingcap/tla-plus 这个 Repo，以及我们的首席架构师唐刘的这篇 博客 了解更多。\nChaos Engineering 如果完美的证明不存在，那么 Deterministic 的测试存在吗？我记得大概 2015 年在 PingCAP 成立前，我看到了一个 FoundationDB 关于他们的 Deterministic 测试的 演讲 。简单来说他们用自己的 IO 处理和多任务处理框架 Flow 将代码逻辑和操作系统的线程以及 IO 操作解耦，并通过 集群模拟器 做到了百分之百重现 Bug 出现时的事件顺序，同时可以在模拟器中精确模拟各种异常，确实很完美。但是考虑到现实的情况，我们当时选择使用的编程语言主要是 Go，很难或者没有必要做类似 Flow 的事情 。所以我们选择了从另一个方向解决这个问题，提升分布式环境下 Bug 的复现率，能方便复现的 Bug 就能好解决，这个思路也是最近几年很火的 Chaos Engineering。 做 Chaos Engineering 的几个关键点：\n 定义稳态，记录正常环境下的 workload 以及关注的重要指标。 定义系统稳态后，我们分为实验组和对照组进行实验，确认在理想的硬件情况下，无论如何操作实验组，最后都会回归稳态。 开始对底层的操作系统和网络进行破坏，再重复实验，观察实验组会不会回归稳态。  道理大家都懂，但是实际做起来最大的问题在于如何将整个流程自动化。原因在于：一是靠手动的效率很低；二是正统的 Chaos Engineering 强调的是在生产环境中操作，如何控制爆炸半径，这也是个比较重要的问题。\n先说第一个问题，PingCAP 在实践 Chaos Engineering 的初期，都是在物理机上通过脚本启停服务，所有实验都需要手动完成，耗时且非常低效，在资源利用上也十分不合理。这个问题我们觉得正好是 K8s 非常擅长的，于是我们开发了一个基于 K8s 的，内部称为 Schrodinger 的自动化测试平台，将 TiDB 集群的启停镜像化，另外将 TiDB 本身的 CI/CD，自动化测试用例的管理、Fault Injection 都统一了起来。这个项目还催生出一个好玩的子项目 Chaos Operator：我们通过 CRD 来描述 Chaos 的类型，然后在不同的物理节点上启动一个 DaemonSets，这个 DaemonSets 就负责干扰 Pod，往对应的 Pod 里面注入一个 Sidecar，Sidecar 帮我们进行注入错误（例如使用 Fuse 来模拟 IO 异常，修改 iptable 制造网络隔离等），破坏 Pod。近期我们也有计划将 Chaos Operator 开源。\n第二个问题，其实在我看来，有 Chaos Engineering 仍然还是不够的，我们在长时间的对测试和质量的研究中发现提升测试质量的关键是如何发现更多的测试 workload。在早期我们大量依赖了 MySQL 和相关社区的集成测试，数量大概千万级别，这个决定让我们在快速迭代的同时保证质量，但是即使这样还是不够的，我们也在从学术界寻求答案.例如引入并通过官方的 Jepsen Test ，再例如通过 SQLfuzz 自动生成合法 SQL 的语句加入到测试集中，这个思路在最近我们的一次 Hackathon 项目中有一个很完美的落地，可以看看这篇介绍这个项目的文章 《你呼呼大睡，机器人却在找 bug？》 。\n总之，比起写业务逻辑，在分布式环境下写测试 + 写测试框架花费的精力可能一点都不少，甚至可能多很多（如果就从代码量来说，TiDB 的测试相关的代码行数可能比内核代码行数多一个数量级），而且这是一个非常值得研究和投资的领域。另外一个问题是如何通过测试发现性能回退。我们的测试平台中每天运行着一个名为 benchbot 的机器人，每天的回归测试都会自动跑性能测试，对比每日的结果。这样一来我们的工程师就能很快知道哪些变更导致了性能下降，以及得到一个长期性能变化趋势。\neBPF 说完测试，另外一个相关的话题是 profiling 和分布式 tracing。tracing 看看 Google 的 Dapper 和开源实现 OpenTracing 就大概能理解，所以，我重点聊聊 profiling。最近这几年我关注的比较多的是 eBPF（extended BPF）技术。想象下，过去我们如果要开发一个 TCP filter，要么就自己写一个内核驱动，要么就用 libpcap 之类的基于传统 BPF 的库，而传统 BPF 只是针对包过滤这个场景设计的虚拟机，很难定制和扩展。\n图 1 BPF 工作原理\n图 2 eBPF 架构图\n在这个背景下，eBPF 应运而生，eBPF 引入了 JIT 和寄存器，将 BPF 的功能进一步扩充，这背后的意义是，我们在内核中有一个安全的、高性能的、基于事件的、支持 JIT 的字节码的虚拟机！这其实极大地降低了拓展内核能力的门槛，我们可以不用担心在驱动中写个异常把内核搞崩，我们也可以将给 llvm 用的 clang 直接编译成 eBPF 对象，社区还有类似 bcc 这样的基于 Python 的实用工具集……\n过去其实大家是从系统状态监控、防火墙这个角度认识 eBPF 的。没错，性能监控以及防火墙确实是目前 eBPF 的王牌场景，但是我大胆地预测未来不止于此，就像最近 Brendan Gregg 在他的 blog 里喊出的口号：BPF is a new type of software。可能在不久的未来，eBPF 社区能诞生出更多好玩的东西，例如我们能不能用 eBPF 来做个超高性能的 web server？能不能做个 CDN 加速器？能不能用 BPF 来重定义操作系统的进程调度？我喜欢 eBPF 的另一个重要原因是，第一次内核应用开发者可以无视内核的类型和版本，只要内核能够运行 eBPF bytecode 就可以了，真正做到了一次编译，各个内核运行。所以有一种说法是 BPF is eating Linux，也不是没有道理 。\nPingCAP 也已经默默地在 BPF 社区投入了很长时间，我们也将自己做的一些 bcc 工具开源了，详情可以参考 pingcap/kdt 这个 repo。其中值得一提的是，我们的 bcc 工具之一 drsnoop 被 Brendan Gregg 的新书收录了，也算是为社区做出了一点微小的贡献。\n上面聊的很多东西都是具体的技术，技术的落地离不开部署和运维，分布式系统的特性决定了维护的复杂度比单机系统大得多。在这个背景之下，我认为解法可能是：不可变基础设施。\n云和容器的普及让 infrastructure as code 的理念得以变成现实，通过描述式的语言来创建可重复的部署体验，这样可重用的描述其实很方便在开源社区共享，而且由于这些描述几乎是和具体的云的实现无关，对于跨云部署和混合数据中心部署的场景很适合。有些部署工具甚至诞生出自己的生态系统，例如 Terraform / Chef / Ansible。有一种说法戏称现在的运维工程师都是 yaml 语言工程师，其实很有道理的：人总是会出错，且传统的基于 shell 脚本的运维部署受环境影响太大，shell 天然也不是一个非常严谨的语言。描述意图，让机器去干事情，才是能 scale 的正道。\n","permalink":"http://c4pt0r.github.io/posts/distributed-system-in-2010s-4/","summary":"我觉得面对测试的态度是区分一个普通程序员和优秀程序员的重要标准。现如今我们的程序和服务越来越庞大，光是单元测试 TDD 之类的就已经很难保证质量，不过这些都是 baseline，所以今天聊点新的话题。\n说测试之前，我们先问下自己，为什么要测试？当然是为了找 Bug。看起来这是句废话，但是仔细想想，如果我们能写出 Bug-free 的程序不就好了吗？何必那么麻烦。不过 100% 的 Bug-free 肯定是不行的，那么我们有没有办法能够尽可能地提升我们程序的质量？举个例子，我想到一个 Raft 的优化算法，与其等实现之后再测试，能不能在写代码前就知道这个算法理论上有没有问题？办法其实是有的，那就是形式化证明技术，比较常用的是 TLA+。\nTLA+ TLA+ 背后的思想很简单，TLA+ 会通过一套自己的 DSL（符号很接近数学语言）描述程序的初始状态以及后续状态之间的转换关系，同时根据你的业务逻辑来定义在这些状态切换中的不变量，然后 TLA+ 的 TLC model checker 对状态机的所有可达状态进行穷举，在穷举过程中不断检验不变量约束是否被破坏。\n举个简单的例子，分布式事务最简单的两阶段提交算法，对于 TLA+ Spec 来说，需要你定义好初始状态（例如事务要操作的 keys、有几个并发客户端等），然后定义状态间跳转的操作（ Begin / Write / Read / Commit 等），最后定义不变量（例如任何处于 Committed 状态的 write ops 一定是按照 commit timestamp 排序的，或者 Read 的操作一定不会读到脏数据之类的），写完以后放到 TLC Checker 里面运行，等待结果就好。\n但是，我们活在一个不完美的世界，即使你写出了完美的证明，也很难保证你就是对的。第一， Simulator 并没有办法模拟出无限多的 paticipants 和并发度， 一般也就是三五个；第二，聪明的你可能也看出来了，一般 TLA+ 的推广文章也不会告诉你 Spec 的关键是定义不变量，如果不变量定义不完备，或者定义出错，那么证明就是无效的。因此，我认为形式化验证的意义在于让工程师在写代码之前提高信心，在写证明的过程中也能更加深对算法的理解，此外，如果在 TLC Checker 里就跑出异常，那就更好了。\n目前 PingCAP 应该是国内唯一一个使用 TLA+ 证明关键算法，并且将证明的 Spec 开源出来的公司，大家可以参考 pingcap/tla-plus 这个 Repo，以及我们的首席架构师唐刘的这篇 博客 了解更多。","title":"分布式系统 in 2010s ：测试和运维"},{"content":"上篇 我们聊了软件构建方式和演化，今天我们来聊聊硬件吧！\nSSD 普及的深远影响 如果说云的出现是一种商业模式的变化的话，驱动这个商业革命的推手就是最近十年硬件的快速更新。比起 CPU，存储和网络设备的进化速度更加迅速。最近五年，SSD 的价格 (包括 PCIe 接口) 的成本持续下降，批量采购的话已经几乎达到和 HDD 接近的价格。\n图 1 近 5 年 SSD 成本曲线\nSSD 的普及，对于存储软件厂商的影响是深远的。\n其一，是极大地缓解了 IO 瓶颈。对于数据库厂商来说，可以将更多的精力花在其他事情，而不是优化存储引擎上。最近两年发生了一些更大的变化，NVMe 正在成为主流，我们很早就在 Intel Optane 进行实验和投资，类似这样的非易失内存的技术，正在模糊内存和存储的界限，但是同时对开发者带来挑战也是存在的。举一个简单的例子，对于 Optane 这类的非易失内存，如果你希望能够完全利用它的性能优势，最好使用类似 PMDK 这类基于 Page cache Bypass 的 SDK 针对你的程序进行开发，这类 SDK 的核心思想是将 NVM 设备真正地当做内存使用。如果仅仅将 Optane 挂载成本地磁盘使用，其实很大程度上的瓶颈不一定出现在硬件本身的 IO 上。\n下面这张图很有意思，来自 Intel 对于 Optane 的测试，我们可以看见在中间那一列，Storage with Optane SSD，随机读取的硬件延迟已经接近操作系统和文件系统带来的延迟，甚至 Linux VFS 本身会变成 CPU 瓶颈。其实背后的原因也很简单，过去由于 VFS 本身在 CPU 上的开销（比如锁）相比过去的 IO 来说太小了，但是现在这些新硬件本身的 IO 延迟已经低到让文件系统本身开销的比例不容忽视了。\n图 2 Intel 对于 Optane 的测试\n其二，这个变化影响了操作系统和文件系统本身。例如针对 Persistent Memory 设计新的文件系统，其中来自 UCSD 的 NVSL 实验室 (名字很厉害， Non-Volatile Systems Laboratory) 的 NovaFS 就是一个很好的例子。简单来说是大量使用了无锁数据结构，减低 CPU 开销，NovaFS 的代码量很小很好读，有兴趣可以看看。另外 Intel 对 Persistent Memory 编程模型有很好的一篇 文章 ，感兴趣的话可以从这里开始了解这些新变化。\n内核开销的挑战 说完了存储设备，我们聊聊网络设备。我还记得我第一份工作的数据中心里甚至还有百兆的网卡，但现在，1GbE 已经都快淘汰光了，主流的数据中心基本上开始提供 10GbE 甚至 25GbE 的网络。为什么会变成这样？我们做一个简单的算术题就知道了。根据 Cisco 的 文档介绍 ， 一块千兆网卡的吞吐大概是: [1,000,000,000 b/s / (84 B * 8 b/B)] == 1,488,096 f/s (maximum rate)。\n那么万兆网卡的吞吐大概是它的十倍，也就是差不多每秒 1488 万帧，处理一个包的时间在百纳秒的级别，基本相当于一个 L2 Cache Miss 的时间。所以如何减小内核协议栈处理带来的内核-用户态频繁内存拷贝的开销，成为一个很重要的课题，这就是为什么现在很多高性能网络程序开始基于 DPDK 进行开发。\n对于不了解 DPDK 的朋友，在这里 简单科普一下 :\n图 3 DPDK Flow Bifurcation\n从上图可以看到，数据包直接从网卡到了 DPDK，绕过了操作系统的内核驱动、协议栈和 Socket Library。DPDK 内部维护了一个叫做 UIO Framework 的用户态驱动 (PMD)，通过 ring queue 等技术实现内核到用户态的 zero-copy 数据交换，避免了 Syscall 和内核切换带来的 cache miss，而且在多核架构上通过多线程和绑核，极大提升了报文处理效率。如果你确定你的网络程序瓶颈在包处理效率上，不妨关注一下 DPDK。\n另外 RDMA 对未来体系结构的影响也会很大，它会让一个分布式集群向一个超级 NUMA 的架构演进（它的通信延时/带宽已经跟现在 NUMA 架构中连接不同 socket node 的 QPI 的延时/带宽在一个量级），但是目前受限于成本和开发模型的变化，可能还需要等很长一段时间才能普及。\n其实不管是 DPDK，SPDK，PMDK ，背后的主线都是 Bypass kernel，Linux 内核本身带来的开销已经很难适应现代硬件的发展，但是生态和兼容性依然是大的挑战，我对于一言不合就搞个 Bypass Kernel SDK 的做法其实是不太赞同的。大量的基础软件需要适配，甚至整个开发模型都要变化。\n我认为有关内核的问题，内核社区从长期来看一定会解决。一个值得关注的技术是 Linux 5.1 内核中引入的 io_uring 系列的新系统调用，io_uring 的原理简单来说就是通过两个内核/用户态共享的 ring buffer 来实现 IO 事件的提交以及收割，避免了 syscall 及内核\u0026lt;-\u0026gt;用户态的内存拷贝，同时提供了 poll 的模式， 不用等待硬件中断，而是不断轮询硬件，这极大降低了 IO 延迟，提升了整体吞吐。 我认为 io_uring 的出现也代表了内核社区在各种 Bypass Kernel 技术涌现的当下，正在奋起直追。\n","permalink":"http://c4pt0r.github.io/posts/distributed-system-in-2010s-3/","summary":"上篇 我们聊了软件构建方式和演化，今天我们来聊聊硬件吧！\nSSD 普及的深远影响 如果说云的出现是一种商业模式的变化的话，驱动这个商业革命的推手就是最近十年硬件的快速更新。比起 CPU，存储和网络设备的进化速度更加迅速。最近五年，SSD 的价格 (包括 PCIe 接口) 的成本持续下降，批量采购的话已经几乎达到和 HDD 接近的价格。\n图 1 近 5 年 SSD 成本曲线\nSSD 的普及，对于存储软件厂商的影响是深远的。\n其一，是极大地缓解了 IO 瓶颈。对于数据库厂商来说，可以将更多的精力花在其他事情，而不是优化存储引擎上。最近两年发生了一些更大的变化，NVMe 正在成为主流，我们很早就在 Intel Optane 进行实验和投资，类似这样的非易失内存的技术，正在模糊内存和存储的界限，但是同时对开发者带来挑战也是存在的。举一个简单的例子，对于 Optane 这类的非易失内存，如果你希望能够完全利用它的性能优势，最好使用类似 PMDK 这类基于 Page cache Bypass 的 SDK 针对你的程序进行开发，这类 SDK 的核心思想是将 NVM 设备真正地当做内存使用。如果仅仅将 Optane 挂载成本地磁盘使用，其实很大程度上的瓶颈不一定出现在硬件本身的 IO 上。\n下面这张图很有意思，来自 Intel 对于 Optane 的测试，我们可以看见在中间那一列，Storage with Optane SSD，随机读取的硬件延迟已经接近操作系统和文件系统带来的延迟，甚至 Linux VFS 本身会变成 CPU 瓶颈。其实背后的原因也很简单，过去由于 VFS 本身在 CPU 上的开销（比如锁）相比过去的 IO 来说太小了，但是现在这些新硬件本身的 IO 延迟已经低到让文件系统本身开销的比例不容忽视了。\n图 2 Intel 对于 Optane 的测试","title":"分布式系统 in 2010s ：硬件的进化"},{"content":"我上大学的时候专业是软件工程，当时的软件工程是 CMM、瀑布模型之类。十几年过去了，看看现在我们的软件开发模式，尤其是在互联网行业，敏捷已经成为主流，很多时候老板说业务下周上线，那基本就是怎么快怎么来，所以现代架构师对于可复用性和弹性会有更多的关注。我所知道业界对 SOA 的关注是从 Amazon 的大规模 SOA 化开始， 2002 年 Bezos 要求 Amazon 的工程团队将所有的业务 API 和服务化， 几条原则 放在今天仍然非常适用：\n  All teams will henceforth expose their data and functionality through service interfaces. Teams must communicate with each other through these interfaces. There will be no other form of inter-process communication allowed: no direct linking, no direct reads of another team’s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network. It doesn’t matter what technology they use. All service interfaces, without exception, must be designed from the ground up to be externalizable. That is to say, the team must plan and design to be able to expose the interface to developers in the outside world. No exceptions.   尤其最后一条，我个人认为对于后来的 AWS 的诞生有直接的影响，另外这条也间接地对工程团队的软件质量和 API 质量提出了更高的要求。亚马逊在 SOA 上的实践是组件化在分布式环境中的延伸，尽可能地将业务打散成最细粒度的可复用单元（Services），新的业务通过组合的方式构建。这样的原则一直发展到今天，我们提到的微服务、甚至 Serverless，都是这个思想的延伸。\nSOA 只是一个方法论 很多人在思考 SOA 和微服务的区别时，经常有一些观点类似：「拆的粗就是 SOA，拆的细就是微服务 」，「使用 RESTful API 就是微服务，用 RPC 是 SOA」，「使用 XXX（可以是任何流行的开源框架） 的是微服务，使用 YYY 的是 SOA」\u0026hellip; 这些观点我其实并不认可，我理解的 SOA 或者微服务只是一个方法论，核心在于有效地拆分应用，实现敏捷构建和部署，至于使用什么技术或者框架其实无所谓，甚至 SOA 本身就是反对绑定在某项技术上的。\n对于架构师来说， 微服务化也并不是灵丹妙药，有一些核心问题，在微服务化的实践中经常会遇到：\n  服务的拆分粒度到底多细？\n  大的单体服务如何避免成为单点，如何支持快速的弹性水平扩展？\n  如何进行流控和降级？防止调用者 DDoS？\n  海量服务背景下的 CI/CD (测试，版本控制，依赖管理)，运维（包括 tracing，分布式 metric 收集，问题排查）\n… …\n  上面几个问题都很大。熟悉多线程编程的朋友可能比较熟悉 Actor 模型，我认为 Actor 的思想和微服务还是很接近的，同样的最佳实践也可以在分布式场景下适用，事实上 Erlang OTP 和 Scala 的 Akka Framework 都尝试直接将 Actor 模型在大规模分布式系统中应用。其实在软件工程上这个也不是新的东西，Actor 和 CSP 的概念几乎在软件诞生之初就存在了，现在服务化的兴起我认为是架构复杂到一定程度后很自然的选择，就像当年 CSP 和 Actor 简化并发编程一样。\n服务化和云 从服务化的大方向和基础设施方面来说，我们这几年经历了：本地单体服务 + 私有 API （自建数据中心，自己运维管理） -\u0026gt; 云 IaaS + 本地服务 + 云提供的 Managed Service (例如 EC2 + RDS) -\u0026gt; Serverless 的转变。其本质在于云的出现让开发者对于硬件控制力越来越低，算力和服务越来越变成标准化的东西。而容器的诞生，使得资源复用的粒度进一步的降低（物理机 -\u0026gt; VM -\u0026gt; Container），这无疑是云厂商非常希望看到的。对公有云厂商来说，资源分配的粒度越细越轻量，就越能精准地分配，以提升整体的硬件资源利用率，实现效益最大化。\n这里暗含着一个我的观点：公有云和私有云在价值主张和商业模式上是不一样的：对公有云来说，只有不断地规模化，通过不断提升系统资源的利用率，获取收益（比如主流的公有云几乎对小型实例都会超卖）。而私有云的模式可以概括成降低运维成本（标准化服务 + 自动化运维），对于自己拥有数据中心的企业来说，通过云技术提升硬件资源的利用率是好事，只是这个收益并没有公有云的规模化收益来得明显。\n在服务化的大背景下，也产生了另外一个趋势，就是基础软件的垂直化和碎片化，当然这也是和现在的 workload 变得越来越大，单一的数据库软件或者开发框架很难满足多变且极端的需求有关。数据库、对象存储、RPC、缓存、监控这几个大类，几乎每位架构师都熟悉多个备选方案，根据不同需求排列组合，一个 Oracle 包打天下的时代已经过去了。\n这样带来的结果是数据或状态在不同系统之间的同步和传递成为一个新的普遍需求，这就是为什么以 Kafka，Pulsar 为代表的分布式的消息队列越来越流行。但是在异构数据源之间的同步，暗含了异步和不一致（如果需要一致性，那么就需要对消费者实现幂等的语义），在一些对一致性有极端需求的场景，仍然需要交给数据库处理。\n在这种背景下，容器的出现将计算资源分配的粒度进一步的降低且更加标准化，硬件对于开发者来说越来越透明，而且随着 workload 的规模越来越大，就带来的一个新的挑战：海量的计算单元如何管理，以及如何进行服务编排。既然有编排这里面还隐含了另外一个问题：服务的生命周期管理。\nKubernetes 时代开始了 其实在 Kubernetes 诞生之前，很多产品也做过此类尝试，例如 Mesos。Mesos 早期甚至并不支持容器，主要设计的目标也是短任务（后通过 Marathon Framework 支持长服务），更像一个分布式的工作流和任务管理（或者是分布式进程管理）系统，但是已经体现了 Workload 和硬件资源分离的思想。\n在前 Kubernetes 时代，Mesos 的设计更像是传统的系统工程师对分布式任务调度的思考和实践，而 K8s 的野心更大，从设计之初就是要在硬件层之上去抽象所有类型的 workload，构建自己的生态系统。如果说 Mesos 还是个工具的话，那么 K8s 的目标其实是奔着做一个分布式操作系统去的。简单做个类比：整个集群的计算资源统一管控起来就像一个单机的物理计算资源，容器就像一个个进程，Overlay network 就像进程通信，镜像就像一个个可执行文件，Controller 就像 Systemd，Kubectl 就像 Shell……同样相似的类比还有很多。\n从另一方面看，Kubernetes 为各种 IaaS 层提供了一套标准的抽象，不管你底层是自己的数据中心的物理机，还是某个公有云的 VM，只要你的服务是构建在 K8s 之上，那么就获得了无缝迁移的能力。K8s 就是一个更加中立的云，在我的设想中，未来不管是公有云还是私有云都会提供标准 K8s 能力。对于业务来说，基础架构的上云，最安全的路径就是上 K8s，目前从几个主流的公有云厂商的动作上来看（GCP 的 GKE，AWS 的 EKS，Azure 的 AKS），这个假设是成立的。\n不选择 K8s 的人很多时候会从性能角度来攻击 K8s，理由是：多一层抽象一定会损害性能。对于这个我是不太同意的。从网络方面说，大家可能有个误解，认为 Overlay Network 的性能一定不好，其实这不一定是事实。下面这张图来自 ITNEXT 的工程师对几个流行的 CNI 实现的 评测 ：\nKubernetses CNI benchmark\n我们其实可以看到，除了 WaveNet Encrypted 因为需要额外的加密导致性能不佳以外，其它的 CNI 实现几乎已经和 Bare metal 的 host network 性能接近，出现异常的网络延迟大多问题是出现在 iptable NAT 或者 Ingress 的错误配置上面。\n所以软件的未来在哪里？我个人的意见是硬件和操作系统对开发者会更加的透明，也就是现在概念刚开始普及起来的 Serverless。我经常用的一个比喻是：如果自己维护数据中心，采购服务器的话，相当于买房；使用云 IaaS 相当于租房；而 Serverless，相当于住酒店。长远来看，这三种方案都有各自适用的范围，并不是谁取代谁的关系。目前看来 Serverless 因为出现时间最短，所以发展的潜力也是最大的。\n从服务治理上来说，微服务的碎片化必然导致了管理成本上升，所以近年 Service Mesh （服务网格）的概念才兴起。 服务网格虽然名字很酷，但是其实可以想象成就是一个高级的负载均衡器或服务路由。比较新鲜的是 Sidecar 的模式，将业务逻辑和通信解耦。我其实一直相信未来在七层之上，会有一层以 Service Mesh 和服务为基础的「八层网络」，不过目前并没有一个事实标准出现。Istio 的整体架构过于臃肿，相比之下我更加喜欢单纯使用 Envoy 或者 Kong 这样更加轻量的 API Proxy。 不过我认为目前在 Service Mesh 领域还没有出现有统治地位的解决方案，还需要时间。\n","permalink":"http://c4pt0r.github.io/posts/distributed-system-in-2010s-2/","summary":"我上大学的时候专业是软件工程，当时的软件工程是 CMM、瀑布模型之类。十几年过去了，看看现在我们的软件开发模式，尤其是在互联网行业，敏捷已经成为主流，很多时候老板说业务下周上线，那基本就是怎么快怎么来，所以现代架构师对于可复用性和弹性会有更多的关注。我所知道业界对 SOA 的关注是从 Amazon 的大规模 SOA 化开始， 2002 年 Bezos 要求 Amazon 的工程团队将所有的业务 API 和服务化， 几条原则 放在今天仍然非常适用：\n  All teams will henceforth expose their data and functionality through service interfaces. Teams must communicate with each other through these interfaces. There will be no other form of inter-process communication allowed: no direct linking, no direct reads of another team’s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network.","title":"分布式系统 in 2010s ：软件构建方式和演化"},{"content":"回看这几年，分布式系统领域出现了很多新东西，特别是云和 AI 的崛起，让这个过去其实不太 sexy 的领域一下到了风口浪尖，在这期间诞生了很多新技术、新思想，让这个古老的领域重新焕发生机。站在 2010s 的尾巴上，我想跟大家一起聊聊分布式系统令人振奋的进化路程，以及谈一些对 2020s 的大胆猜想。\n无论哪个时代，存储都是一个重要的话题，今天先聊聊数据库。在过去的几年，数据库技术上出现了几个很明显的趋势。\n存储和计算进一步分离 我印象中最早的存储-计算分离的尝试是 Snowflake，Snowflake 团队在 2016 年发表的论文 《The Snowflake Elastic Data Warehouse》 是近几年我读过的最好的大数据相关论文之一，尤其推荐阅读。Snowflake 的架构关键点是在无状态的计算节点 + 中间的缓存层 + S3 上存储数据，计算并不强耦合缓存层，非常符合云的思想。从最近 AWS 推出的 RedShift 冷热分离架构来看，AWS 也承认 Snowflake 这个搞法是先进生产力的发展方向。另外这几年关注数据库的朋友不可能不注意到 Aurora。不同于 Snowflake，Aurora 应该是第一个将存储-计算分离的思想用在 OLTP 数据库中的产品，并大放异彩。Aurora 的成功在于将数据复制的粒度从 Binlog降低到 Redo Log ，极大地减少复制链路上的 IO 放大。而且前端复用了 MySQL，基本做到了 100% 的应用层 MySQL 语法兼容，并且托管了运维，同时让传统的 MySQL 适用范围进一步拓展，这在中小型数据量的场景下是一个很省心的方案。\n虽然 Aurora 获得了商业上的成功，但是从技术上，我并不觉得有很大的创新。熟悉 Oracle 的朋友第一次见 Aurora 的架构可能会觉得和 RAC 似曾相识。Oracle 大概在十几年前就用了类似的方案，甚至很完美的解决了 Cache Coherence 的问题。另外，Aurora 的 Multi-Master 还有很长的路要走，从最近在 ReInvent 上的说法来看，目前 Aurora 的 Multi-Master 的主要场景还是作为 Single Writer 的高可用方案，本质的原因应该是目前 Multi-Writer 采用乐观冲突检测，冲突检测的粒度是 Page，在冲突率高的场合会带来很大的性能下降。\n我认为 Aurora 是一个很好的迎合 90% 的公有云互联网用户的方案：100% MySQL 兼容，对一致性不太关心，读远大于写，全托管。但同时，Aurora 的架构决定了它放弃了 10% 有极端需求的用户，如全局的 ACID 事务+ 强一致，Hyper Scale（百 T 以上，并且业务不方便拆库），需要实时的复杂 OLAP。这类方案我觉得类似 TiDB 的以 Shared-nothing 为主的设计才是唯一的出路。作为一个分布式系统工程师，我对任何不能水平扩展的架构都会觉得不太优雅。\n分布式 SQL 数据库登上舞台，ACID 全面回归 回想几年前 NoSQL 最风光的时候，大家恨不得将一切系统都使用 NoSQL 改造，虽然易用性、扩展性和性能都不错，但是多数 NoSQL 系统抛弃掉数据库最重要的一些东西，例如 ACID 约束，SQL 等等。NoSQL 的主要推手是互联网公司，对于互联网公司的简单业务加上超强的工程师团队来说当然能用这些简单工具搞定。\n但最近几年大家渐渐发现低垂的果实基本上没有了，剩下的都是硬骨头。\n最好的例子就是作为 NoSQL 的开山鼻祖，Google 第一个搞了 NewSQL （Spanner 和 F1）。在后移动时代，业务变得越来越复杂，要求越来越实时，同时对于数据的需求也越来越强。尤其对于一些金融机构来说，一方面产品面临着互联网化，一方面不管是出于监管的要求还是业务本身的需求，ACID 是很难绕开的。更现实的是，大多数传统公司并没有像顶级互联网公司的人才供给，大量历史系统基于 SQL 开发，完全迁移到 NoSQL 上肯定不现实。\n在这个背景下，分布式关系型数据库，我认为这是我们这一代人，在开源数据库这个市场上最后一个 missing part，终于慢慢流行起来。这背后的很多细节由于篇幅的原因我就不介绍，推荐阅读 PingCAP TiFlash 技术负责人 maxiaoyu 的一篇文章《 从大数据到数据库 》，对这个话题有很精彩的阐述。\n云基础设施和数据库的进一步整合 在过去的几十年，数据库开发者都像是在单打独斗，就好像操作系统以下的就完全是黑盒了，这个假设也没错，毕竟软件开发者大多也没有硬件背景。另外如果一个方案过于绑定硬件和底层基础设施，必然很难成为事实标准，而且硬件非常不利于调试和更新，成本过高，这也是我一直对定制一体机不是太感兴趣的原因。但是云的出现，将 IaaS 的基础能力变成了软件可复用的单元，我可以在云上按需地租用算力和服务，这会给数据库开发者在设计系统的时候带来更多的可能性，举几个例子：\n Spanner 原生的 TrueTime API 依赖原子钟和 GPS 时钟，如果纯软件实现的话，需要牺牲的东西很多（例如 CockroachDB 的 HLC 和 TiDB 的改进版 Percolator 模型，都是基于软件时钟的事务模型）。但是长期来看，不管是 AWS 还是 GCP 都会提供类似 TrueTime 的高精度时钟服务，这样一来我们就能更好的实现低延迟长距离分布式事务。 可以借助 Fargate + EKS 这种轻量级容器 + Managed K8s 的服务，让我们的数据库在面临突发热点小表读的场景（这个场景几乎是 Shared-Nothing 架构的老大难问题），比如在 TiDB 中通过 Raft Learner 的方式，配合云的 Auto Scaler 快速在新的容器中创建只读副本，而不是仅仅通过 3 副本提供服务；比如动态起 10 个 pod，给热点数据创建 Raft 副本（这是我们将 TiKV 的数据分片设计得那么小的一个重要原因），处理完突发的读流量后再销毁这些容器，变成 3 副本。 冷热数据分离，这个很好理解，将不常用的数据分片，分析型的副本，数据备份放到 S3 上，极大地降低成本。 RDMA/CPU/超算 as a Service，任何云上的硬件层面的改进，只要暴露 API，都是可以给软件开发者带来新的好处。  例子还有很多，我就不一一列举了。总之我的观点是云服务 API 的能力会像过去的代码标准库一样，是大家可以依赖的东西，虽然现在公有云的 SLA 仍然不够理想，但是长远上看，一定是会越来越完善的。\n所以，数据库的未来在哪里？是更加的垂直化还是走向统一？对于这个问题，我同意这个世界不存在银弹，但是我也并不像我的偶像，AWS 的 CTO，Vogels 博士那么悲观，相信未来是一个割裂的世界（AWS 恨不得为了每个细分的场景设计一个数据库）。过度地细分会加大数据在不同系统中流动的成本。解决这个问题有两个关键：\n 数据产品应该切分到什么粒度？ 用户可不可以不用知道背后发生了什么？  第一个问题并没有一个明确的答案，但是我觉得肯定不是越细越好的，而且这个和 Workload 有关，比如如果没有那么大量的数据，直接在 MySQL 或者 PostgreSQL 上跑分析查询其实一点问题也没有，没有必要非去用 Redshift。虽然没有直接的答案，但是我隐约觉得第一个问题和第二个问题是息息相关的，毕竟没有银弹，就像 OLAP 跑在列存储引擎上一定比行存引擎快，但是对用户来说其实可以都是 SQL 的接口。\nSQL 是一个非常棒的语言，它只描述了用户的意图，而且完全与实现无关，对于数据库来说，其实可以在 SQL 层的后面来进行切分，在 TiDB 中，我们引入 TiFlash 就是一个很好的例子。动机很简单：\n 用户其实并不是数据库专家，你不能指望用户能 100% 在恰当的时间使用恰当的数据库，并且用对。 数据之间的同步在一个系统之下才能尽量保持更多的信息，例如，TiFlash 能保持 TiDB 中事务的 MVCC 版本，TiFlash 的数据同步粒度可以小到 Raft Log 的级别。  另外一些新的功能仍然可以以 SQL 的接口对外提供，例如全文检索，用 SQL 其实也可以简洁的表达。这里我就不一一展开了。\n我其实坚信系统一定是朝着更智能、更易用的方向发展的，现在都 21 世纪了，你是希望每天拿着一个 Nokia 再背着一个相机，还是直接一部手机搞定？\n","permalink":"http://c4pt0r.github.io/posts/distributed-system-in-2010s-1/","summary":"回看这几年，分布式系统领域出现了很多新东西，特别是云和 AI 的崛起，让这个过去其实不太 sexy 的领域一下到了风口浪尖，在这期间诞生了很多新技术、新思想，让这个古老的领域重新焕发生机。站在 2010s 的尾巴上，我想跟大家一起聊聊分布式系统令人振奋的进化路程，以及谈一些对 2020s 的大胆猜想。\n无论哪个时代，存储都是一个重要的话题，今天先聊聊数据库。在过去的几年，数据库技术上出现了几个很明显的趋势。\n存储和计算进一步分离 我印象中最早的存储-计算分离的尝试是 Snowflake，Snowflake 团队在 2016 年发表的论文 《The Snowflake Elastic Data Warehouse》 是近几年我读过的最好的大数据相关论文之一，尤其推荐阅读。Snowflake 的架构关键点是在无状态的计算节点 + 中间的缓存层 + S3 上存储数据，计算并不强耦合缓存层，非常符合云的思想。从最近 AWS 推出的 RedShift 冷热分离架构来看，AWS 也承认 Snowflake 这个搞法是先进生产力的发展方向。另外这几年关注数据库的朋友不可能不注意到 Aurora。不同于 Snowflake，Aurora 应该是第一个将存储-计算分离的思想用在 OLTP 数据库中的产品，并大放异彩。Aurora 的成功在于将数据复制的粒度从 Binlog降低到 Redo Log ，极大地减少复制链路上的 IO 放大。而且前端复用了 MySQL，基本做到了 100% 的应用层 MySQL 语法兼容，并且托管了运维，同时让传统的 MySQL 适用范围进一步拓展，这在中小型数据量的场景下是一个很省心的方案。\n虽然 Aurora 获得了商业上的成功，但是从技术上，我并不觉得有很大的创新。熟悉 Oracle 的朋友第一次见 Aurora 的架构可能会觉得和 RAC 似曾相识。Oracle 大概在十几年前就用了类似的方案，甚至很完美的解决了 Cache Coherence 的问题。另外，Aurora 的 Multi-Master 还有很长的路要走，从最近在 ReInvent 上的说法来看，目前 Aurora 的 Multi-Master 的主要场景还是作为 Single Writer 的高可用方案，本质的原因应该是目前 Multi-Writer 采用乐观冲突检测，冲突检测的粒度是 Page，在冲突率高的场合会带来很大的性能下降。","title":"分布式系统 in 2010s ：存储之数据库篇"},{"content":"这次我分享的主题和 2019 年还是一样的——《The Future of Database》，如果你是 PingCAP 的老朋友，参加过之前几次 DevCon 就会知道，这是我的一个保留节目。如果要说我哪里有一些与众不同的气质，我觉得除了发型之外，还有一个是对技术的信仰和执著。这个保留节目我们还是聊聊技术。\n过去两年，**TiDB 在技术上发生的最大变化是什么？**可能有很多同学觉得性能变得越来越好，功能变得越来越多，生态功能越来越大，其实不是。\n从一个程序员角度看，在过去两年中 TiDB 其实完成了一个很重要的转变，那就是开发模式的转变。上图中左边是一个工程师对着屏幕在写代码，这是我们早年在第一个办公室里面开始写 TiDB 第一行代码的状态。旁边放了一瓶可乐和披萨，想到什么写什么。现在 TiDB 整个研发流程越来越像右边这张图，一个小工厂流水线化做月饼。虽然现在离中秋节还稍微有点距离，还是很可爱。\nTiDB 这两年最重要的一件事情，是研发流程以一个全新的发版模型去做软件工程，我们称它为“火车发版”模型。这个模型的特点，是我们会把很多大的 feature 以小的迭代进行逐步增量发布，意味着更易于管理发布周期。\n很多人可能会说“关我什么事？”，这件事情非常重要的意义在于，TiDB 从一个纯粹社区的开源软件开始慢慢变成面向企业级的数据库产品。说得再接地气一点，用户真实场景里面需要的 feature 最快两个月就能合并到 TiDB 的主干，并交付给用户。\n两年前，我的演讲题目也是《The Future of Database》，上图是两年前演讲的截图。向量化，当时这是一个挑战，现在已经完成了；TiFlash ，当时只是在草图上设计的一个架构，在 5.0 引入 MPP 后让它变成了一个真正的 Real-time HTAP 的数据库；IPC /异步提交，5.0 的性能和稳定性都得到了稳步提升；TiDB DBaaS，现在 TiDB Cloud 已经是服务千家万户，服务全球各个地方的真实产品；本地事务异地多活，两年时间也做完了。\n两年前的五大构想，今天都变成了现实。\n从 2019 年到现在的两年时间中，在**这些 feature 背后我们经历了什么？**是两年时间超过三万个 PR 的合并。人总是有成长的，两年前的我和现在的我区别是什么？发型没有变，T 恤也是一样的，变化的是 TiDB 合并了三万多个 PR。回头看我两年前的 PPT，我在思考一个问题，TiDB 的竞争力或核心优势是什么？很多数据库都说自己的核心优势是性能好、功能多。那么，TiDB 的优势是什么？\n两年前我的 PPT 里面有一页叫 Everything is Pluggable，我觉得特别有味道，**TiDB****的真正优势在于技术开放性。**架构开放就意味着能够产生更多的连接，更多连接意味着更快的迭代速度、更多的可能性。\n为什么 TiDB 的系统核心优势是开放性？大家可以花几秒钟时间去思考一下，这一个思考的角度，让我这两年慢慢开始变成一个哲学家。这个角度是：单机数据库和分布式数据库最本质的区别是什么？做分布式数据库的工程师的这些痛苦和幸福的根源在哪里？我们真正的敌人是什么？我们要解决什么样的问题？我们怎么解决这些问题？\n作为一个系统的设计者，在思考系统的时候，**我觉得我们真正的敌人是复杂性。**TiDB 这么一个几百万行代码的软件，跑在 3 台机器上，跑在 30 台、300 台、3 万台的服务器上还是这一套代码。大家想象一下， 3 台机器的复杂性和 3 万台机器的复杂性是一样的吗？\n我们生活中见过最复杂的系统是什么？就是活生生的生命，生命是最复杂的系统。包括每个人每天在和这个世界发生各种各样的交互，我们没有办法预料明天。我们去看生命这么一个复杂的系统，我们往里看人的生命最开始就是一个受精卵，细胞不停分裂，很简单。再往下看 DNA，排列组合，所以我觉得从生命和自身的角度看，才能真正找到解决对抗复杂性的办法，这就简单了。\n这里有肖邦老师的一句话，真正难的事情是把系统做简单，简单意味着美。TiDB 在这方面的设计理念和很多的常规做法还是有点不一样的，刚才我提到一句话，我们幸福和痛苦的根源在哪？刚才也提到我们是一个不一样的公司，技术上往深去思考我们到底和其他的数据库区别是什么？最根源的区别我觉得在于核心的设计理念，当理解了 TiDB 核心设计理念再去看 TiDB 的技术架构设计，有很多具体技术问题大家自然就能够想通了，也能想到为什么我们会这么做。\n左边这是一个惯常思维，1） 我要做一个数据库，2） 做一个分布式数据库会怎么做，3） 我试着把这些数据库上面的表给做分片，分区表，不同的分区放在不同的服务器上就是分布式了。\n我们过去从来没有做过数据库，但是我们有一个疯狂的想法，这个想法就是我们要做一个分布式数据库，我们开始是去定义数据最小的流转单元，像刚才看到的那张动图里面的细胞一样，我们去定义这些细胞的分裂、合并、移动，复制，繁殖。把这些规则用最极简，正交，自洽的规则赋予这些细胞生命，让这些细胞长成一个数据库，是 TiDB 最核心的理念。单机数据库和分布式数据库本质区别在什么，分布式数据库在一台台机器上是可以生长的。\n左边这张图解释了一下，常规是这样去设计，几乎所有的数据库都是从上往下设计的，TiDB 是一个 bottom-up 的设计，先定义底层细胞，在让它长成一个数据库的样子。\n下一个问题，让大家思考几秒钟，给大家铺垫一下，左边的名词，两地三中心，异地多活，跨地域数据分布能力，本地事务，动态热点打散，实时在线捞数，只读表。这些功能的共同点是什么？\n问：如果我要去实现这些功能该怎么去实现？这些功能背后的共同点是什么？有没有一个关键的点，解决了这个点所有能力都能马上拥有，有没有这样的东西？\n答案揭晓，刚才所有这些技术的名词和所有的这些刚才提到的用户看到的东西，背后都依赖一个能力就是“调度”，刚才我提到了那个问题，一个单机数据库，一个单机系统和分布式系统最本质的区别到底是什么？我给出答案是可调度能力，这是区别于单机系统最主要的能力。可调度能力是开放的基础，开放架构不能让这个数据库以不变应万变，这个万变就像把自己重塑成更适合用户的场景的数据库，如果没有这样的能力分布式系统就变得没有意义，就不能说自己是一个开放的系统。\n所以，这个其实是 TiDB 在技术架构上最核心最闪光的价值。今天聊技术，我们在可调度性上做了哪些事情，这是一盘大棋，不是一个 feature，这是一个理念，我们看这个理念过去现在和未来会长成什么样子。熟悉 Raft Proxy 技术的朋友，底层架构上，刚才我提到的细胞是基于 Raft 复制协议的复制组，这其实是我们整个调度最细粒度的单元，我们在这些一个个数据复制组上赋予它自我繁殖、分裂、合并、移动的能力。右边这张图有一个 Learner，用户会心一笑，选择这样的单元作为细胞是很合适的，每一个细胞的行为都是一样的，它是同构的。\n我们再放飞一下，原来 Learner 这个技术的第一次引用我们想给它找一个应用场景，这个应用场景就是 TiFlash，本来只是我们脑中一个小实验，我能不能在这个细胞上让它多复制一小块，让它干点别的事情? 当时，我们觉得 AP 能力不太强，需要底层数据存储列存的数据结构，我们把这个架构在副本上让它支持列存，于是 TiDB 就有了 HTAP 的能力，在这个基础上不到两年时间一个小团队把整个 Real-Time HTAP 这个系统就做出来了。\n为什么这么快做出来？TiFlash 是可调度性的理念绝佳的一个例子，而且我脑子里还有很多很奇怪的想法，Real-Time HTAP，TiFlash 只是开始。\n最细粒度的调度能力，可调度上的调度能力，我们再进一步往上看，有一些朋友熟悉 Foreign Data Wrapper（FDW），现在 TiDB 还不支持 Foreign Data Wrapper。这个功能比较好理解的一个说法，让 TiDB 把其他的数据源当作它内部一张表来进行查询，比如说当这个功能支持了以后，我可以把 Redis 作为 TiDB 中的一张外表，把 MySQL 数据作为一张外表，可以一起关联分析 HBase 这些数据。\n但是，FDW 意义仅仅停留在\u0026quot;联邦查询\u0026quot;吗？我在思考这个 feature 是为什么？因为我在看这个 feature 的时候联想到关于数据库的本质，数据库这种软件的本质是什么？**当你抛开所有的数据结构，存储的能力，抛开所有功能，数据库里面到底存了什么东西？**数据库把所有刚才我说的概念都剥离开，它只干两件事情，一是存储真实的数据，另外一部分是叫做索引，数据库无非就是数据和索引，怎么在这两种概念中辗转腾挪。按照刚才的思路把整个数据库当成数据和索引的容器，索引这个概念其实就是一种特殊映射的表关系，索引也是一张表，你要索引的内容对应到数据上的映射关系。\n那我们就跟着这个思路重新思考 FDW。右边是我的灵魂画风，有点难以看懂，今天整个数据库行业的趋势，其中一个趋势是各种各样的细分领域的数据库诞生，图数据库，向量搜索数据库，全文检索数据库，TiDB 能不能把这些数据库的能力变成它的索引能力？比如说我有一张表这里面存储着用户的关系，用户的信息，大家知道在一个关系上的搜索、查询用图的模型更好，如果是用传统的比如说我用索引的数据结构查询得很慢，用图模型可以极大加速这个性能。如果从这个角度去思考，TiDB 的索引能够接入其他的这些数据库，让其他的数据库作为 TiDB 的索引，同时以一个统一的接口给用户提供服务，是不是打开了新世纪大门的感觉？\n今天大会的主题是开放×连接×预见。\n我觉得特别有意思就是这个“×”号，我也不知道这些东西加进去以后能对 TiDB 的生态带来多大的可能性，任何人试图去预估它的价值都是傲慢的，我们能做的就是把这些基础给开发者打好，这是索引的部分。\n我们再把目光往下看，数据库的本质一个是数据，一个是索引，现在我们看数据，关于数据大家第一个联想就是存储引擎，数据的存储是最关键的一个话题。熟悉 TiDB 整体系统架构的同学肯定对左边这张灵魂画风的图不会陌生，刚才我提到 TiDB 在内部其实是把数据已经拆分成了无数个小小的细胞，每个细胞是一个复制组，分裂，合并，移动。但是在物理层面上存储我们现在是使用基于 Database 的 Real-time HTAP。TiKV 底层用的是 Rocks DB ，TiFlash 用的存储引擎我们命名叫 Delta tree，两种引擎。\n还能不能有更多？\n在存储上去体现开放性和可调度性的能力，有一个基础的前提就是对存储引擎进行抽象，熟悉 TiDB 的代码的同学如果去看它的代码仓库，发现有一个很有意思的文件夹叫Engine API，这件事情特别有意思，我直接把代码放上了，意思就是我们试图去对存储本身的能力进行抽象，这个抽象是一个基础。\n这个抽象的意义在哪？我们为什么做这件事情？我对未来的一个判断，为什么一般来说数据库技术负责人总会谈到性能、功能，为什么今天我们来讨论哲学？因为我觉得从更长的一个维度来看，当你的软件在保持高速迭代能力的时候，它是一个动态的进化过程，进化的终局是什么？\n先来看性能，在 TiDB 发展过程中，每一个版本都保持着 100% 性能提升的速度往前走，可以保持到 6.0，7.0 每次都是百分之百增长，未来优化是无止境的。我个人认为，不会说发明了一种新的硬件和算法解决了全世界所有应用场景的性能问题，粒度会变得越来越细，有一些优化用于某些具体场景，比如用来存用户的关联和关系就是图的模型最好。但是有一点，我觉得用户不用去关心他在使用什么样的数据库的结构，哪一块数据在使用哪一种数据结构，这些都不重要。\n右边的图透露了 TiDB 在做的巨大的一个事情，信息量非常大，我们做的事情，刚才 Engine API 的抽象让我们能做一件事情，熟悉 TiDB 的朋友都知道，我们在一台存储节点上是共享一个存储引擎，现在我们慢慢对每一块数据分片，每一个细胞让它能够自己拥有自己的存储引擎，这个事情在我们实验室里已经做完了，效果非常棒，当时都震惊了。\n下一步发展，当我把数据的细胞存储拆分了以后，下一步到底是不是 Delta tree 这件事情不重要了，比如我有一部分数据在业务场景里面一年只访问一次，但是不能丢，我又不希望用 SSD 来存，我能不能用云上 S3 的存储，甚至在一张表里面的一个数据特别热，对一致性要求没有那么高，是不是能在内存中对这一块数据的形态做一个变换。而且更有意思的是，这些所有的变换都是动态的，对业务都是透明的，回想刚才我说的可调度性和细胞这几个概念。\n我刚才说所有这些技术都是为了一件事情，都需要构建在一个基础上，刚才我说了分布式系统的终局，分布式系统可调度是它的核心优势，**这个基础我相信各位大概能够猜出是什么，我需要有一个近乎无限的弹性资源池，就是云。**关于云的重要性我觉得现在整个行业还在低估，现在天天说云，但是我觉得云其实是构建未来新一代软件的最重要的一个基石。\n我觉得对于云有一个很好的说法，我作为一个软件工程师看待云就像什么？我用了无限的资源，就像一堆积木我怎么去拼，手上有多少钱能拼成什么样子。右边这张图是 Flink 的架构，Flink 是一个很有意思的产品，它上市有各种各样的新闻，但是我最早注意到它是在 2016 年，它发表第一篇论文的时候，我看那篇论文，是我这几年最喜欢的论文之一，那篇论文更大意义在于它开创了一种新的软件设计的思路，开创了新的物种，基于云的服务去构建的基础软件，它是第一个，但绝对不是最后一个，TiDB 在这个领域是走在最前面的软件之一。\nTiDB 的核心思想，开放性体现在可插拔，存储和计算可插拔、可调度，借用今天主题“ × ”号，乘以调度能力，可插拔以后还能调度，细粒度，粗粒度调度，乘以云上几乎无限的资源它又等于什么。\n回顾一下我今天的题目，The Future Database，终极的 Future 是什么，这张图是我理想中的数据库的样子：底层各种各样的资源池，各种各样的云，公有云、私有云，混合云；上面中间逻辑这一层是数据平台，用户不同的业务不同数据，对数据库有不同要求，数据库会根据用户的需要自动去重塑自己；在不同的颗粒度上，从副本分布我们去做全球跨数据中心部署，这种能力对于 TiDB 来说工程代价并不是太高，刚我说调度能力，索引，我们通过 FDW 未来可以引入各种各样多种形态的索引。开了一个小小脑洞，图的数据库作为 TiDB 的索引，根据用户需求变换自己的形态。\n所以，大胆预测一下，刚才那个公式“可插拔性 × 调度能力 × 云上几乎无限的资源 = ？”，数据库作为一个独立的软件形态我认为会被颠覆，同时意味着整个数据库的“数据服务平台化”会崛起，我们下一代很多在场的各位为人父母，下一代的小朋友可能到他们写程序的年纪，可能不知道什么是 CPU，什么是内存，什么是磁盘，什么是操作系统，可能看到的就是一个个云服务，比如要用数据库的时候好象有一个 TiDB 的东西，我把信用卡绑上去之后就可以直接用一个 SQL 的接口里操作就完了，不需要知道什么叫索引， 什么叫 Delta tree。\n我们回头看一下今天我们大会三个关键字，开放，连接，预见，只有开放的架构才能有更多连接，更多的连接才能让我们有更好未来，这是今天我关于 TiDB 的技术和设计理念的分享。\n","permalink":"http://c4pt0r.github.io/posts/the-future-of-db-2021/","summary":"这次我分享的主题和 2019 年还是一样的——《The Future of Database》，如果你是 PingCAP 的老朋友，参加过之前几次 DevCon 就会知道，这是我的一个保留节目。如果要说我哪里有一些与众不同的气质，我觉得除了发型之外，还有一个是对技术的信仰和执著。这个保留节目我们还是聊聊技术。\n过去两年，**TiDB 在技术上发生的最大变化是什么？**可能有很多同学觉得性能变得越来越好，功能变得越来越多，生态功能越来越大，其实不是。\n从一个程序员角度看，在过去两年中 TiDB 其实完成了一个很重要的转变，那就是开发模式的转变。上图中左边是一个工程师对着屏幕在写代码，这是我们早年在第一个办公室里面开始写 TiDB 第一行代码的状态。旁边放了一瓶可乐和披萨，想到什么写什么。现在 TiDB 整个研发流程越来越像右边这张图，一个小工厂流水线化做月饼。虽然现在离中秋节还稍微有点距离，还是很可爱。\nTiDB 这两年最重要的一件事情，是研发流程以一个全新的发版模型去做软件工程，我们称它为“火车发版”模型。这个模型的特点，是我们会把很多大的 feature 以小的迭代进行逐步增量发布，意味着更易于管理发布周期。\n很多人可能会说“关我什么事？”，这件事情非常重要的意义在于，TiDB 从一个纯粹社区的开源软件开始慢慢变成面向企业级的数据库产品。说得再接地气一点，用户真实场景里面需要的 feature 最快两个月就能合并到 TiDB 的主干，并交付给用户。\n两年前，我的演讲题目也是《The Future of Database》，上图是两年前演讲的截图。向量化，当时这是一个挑战，现在已经完成了；TiFlash ，当时只是在草图上设计的一个架构，在 5.0 引入 MPP 后让它变成了一个真正的 Real-time HTAP 的数据库；IPC /异步提交，5.0 的性能和稳定性都得到了稳步提升；TiDB DBaaS，现在 TiDB Cloud 已经是服务千家万户，服务全球各个地方的真实产品；本地事务异地多活，两年时间也做完了。\n两年前的五大构想，今天都变成了现实。\n从 2019 年到现在的两年时间中，在**这些 feature 背后我们经历了什么？**是两年时间超过三万个 PR 的合并。人总是有成长的，两年前的我和现在的我区别是什么？发型没有变，T 恤也是一样的，变化的是 TiDB 合并了三万多个 PR。回头看我两年前的 PPT，我在思考一个问题，TiDB 的竞争力或核心优势是什么？很多数据库都说自己的核心优势是性能好、功能多。那么，TiDB 的优势是什么？\n两年前我的 PPT 里面有一页叫 Everything is Pluggable，我觉得特别有味道，**TiDB****的真正优势在于技术开放性。**架构开放就意味着能够产生更多的连接，更多连接意味着更快的迭代速度、更多的可能性。\n为什么 TiDB 的系统核心优势是开放性？大家可以花几秒钟时间去思考一下，这一个思考的角度，让我这两年慢慢开始变成一个哲学家。这个角度是：单机数据库和分布式数据库最本质的区别是什么？做分布式数据库的工程师的这些痛苦和幸福的根源在哪里？我们真正的敌人是什么？我们要解决什么样的问题？我们怎么解决这些问题？","title":"[演讲] The Future of Database 2021"},{"content":"今天的文章我想从这张模糊的照片说起，相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次「看到」了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓「一图胜千言」很多时候一张图传达的信息超过千言万语。 关于黑洞我不想展开太多，今天我们聊聊「望远镜」。\n前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此，在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」，过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。\n举几个直观的小例子，你知道 TPC-C 测试「长」什么样子吗？请看下图：\n图中横轴是时间，纵轴是数据的分布，左半部分有零星的亮点，是数据导入的过程，，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的局部访问热点（最亮的那条线）。 第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面:\n左边比较密集的明亮黄块是导入数据阶段，右半段明暗相间的部分是进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。 如果你看懂了上面两个小例子，下面是一个小作业，这是我们模拟的一个实际用户的生产环境的照片，这个用户的系统遇到了一些瓶颈，你能看出问题吗？\n上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。\n顾名思义，分布式数据库，数据一定是分散在不同机器上的，对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。\n和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。\n现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。 然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？ 过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但是很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的，再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。有经验一些的 DBA 可能能从多个指标里通过自己的经验，模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维，老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。现代医学有 CT 有 B 超有核磁共振，这些现代化的手段极大的促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断，在计算机的世界道理也是相通的，最好通过某些工具让人更清晰的看到系统运行的健康状态、帮助诊断“病灶”，从而降低经验门槛和不确定性。 过去经常有朋友问我：「你说我这个业务适不适合使用 TiDB？」这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。有些信息可能是敏感的，也不方便共享。所以“预判 TiDB 到底适不适合某类业务”就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统都或多或少有类似的问题。 在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：\n这个坐标描述了一个我们对系统的理解程度和可收集信息的关系，在 X 轴的右侧（Known Knows 和 Known Unknowns）这些称为确定性的已知和未知，图中也给出了相对应的例子，这些信息通常是最基础的普适的事实，也就是在系统上线之前我们一定就能想到，一定能够监控起来的（CPU Load，内存，TPS，QPS之类的），我们过去已有的大多数运维监控都是围绕这些确定的东西。 但是有一些情况是这些基础信息很难描述和衡量的，例如这个坐标的左上角：Unknown Knowns，用通俗的话来说，叫做「假设」。举个数据库的例子：有经验的架构师在设计一个基于分布式数据库的应用时，通常不会将表的主键设成自增主键，会尽可能的用 UUID 或者其他方式打散数据，这样在即使有突发写入压力的时候，系统也能很好的扩展。 注意在这个例子中，其实假设的事情（写入压力突然增大）并没有发生，如果在日常压力不大，数据量不多的情况下，即使使用自增主键，从已有的基础监控中，可能也很难看出任何问题。但是到出事的时候，这个设计失误就会变成 Unknown Unkowns（意外），这是任何人都不想看到的。有经验的架构师能通过种种的蛛丝马迹证实自己的推测，也从无数次翻车的 Post-mortem 中将 Unknown Unknowns 的范围变小。但是更合理的做法是通过技术手段描绘系统更全面的状态，在 Cloud Native 和微服务的世界里，最近几年一个行业的大趋势是将系统的可观测性放在一个更高的位置（监控只是可观测性的一个子集），这是有道理的。\n回到数据库的世界，TiDB KeyViz 的意义在于，就像上面提到的，这个工具不仅仅是一个监控工具，而且它能以一个非常低门槛且形象的方式让架构师具象化的看到自己对于业务的「假设」是否符合预期，这些「假设」不一定是能够通过监控反映的，以获得对业务更深刻的 Insight。 还是说回上面那个主键的小例子，对于两种不同的主键设计，KeyViz 这边是怎么表现的呢？看看下面两张图，是不是非常一目了然。\n所以现在如果有朋友问我，这个业务适不适合 TiDB？我只需要通过录制线上流量，或者搭建一个从集群，只需要把 KeyViz 的图给我看一眼，我甚至都不需要压力测试就能判断这个业务是否适合，而且即使不适合，我也能准确的给出修改建议，因为 KeyViz 的图对我的「假设」的可解释性有了很强的支持。 不妨从这个方向我们再放飞一下想象力，为什么人类能够一眼就从这图片中理解这些信息，这说明这些图形背后有模式，有模式我们就可以识别，想象一下，如果所有的 TiDB 用户，都使用 KeyViz 将自己的系统具象化后分享出来（其实这些图片已经高度抽象，已经不具有任何的业务机密信息），我们是不是可以通过机器学习，挖掘背后更深层次的价值？AI 能不能通过这种形式更加理解我们的业务？\n最后，我想以我最喜欢的科幻小说《三体：黑暗森林》中的一段话结束这篇文章，大致是面壁人希恩斯在冬眠后被妻子唤醒后的一个场景： 「\u0026hellip;与此同时，希恩斯感觉到围绕着他们的白雾发生了变化，雾被粗化了，显然是对某一局部进行了放大。他这时发现所谓的雾其实是由无数发光的小微粒组成的，那月光般的光亮是由这些小微粒自身发出的，而不是对外界光源的散射。放大在继续，小微粒都变成了闪亮的星星。希恩斯所看到的，并不是地球上的那种星空，他仿佛置身于银河系的核心，星星密密麻麻，几乎没有给黑夜留出空隙。　“每一颗星星就是一个神经元。”山杉惠子说，一千亿颗星星构成的星海给他们的身躯镀上了银边。」\n","permalink":"http://c4pt0r.github.io/posts/observability-keyviz/","summary":"今天的文章我想从这张模糊的照片说起，相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次「看到」了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓「一图胜千言」很多时候一张图传达的信息超过千言万语。 关于黑洞我不想展开太多，今天我们聊聊「望远镜」。\n前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此，在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」，过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。\n举几个直观的小例子，你知道 TPC-C 测试「长」什么样子吗？请看下图：\n图中横轴是时间，纵轴是数据的分布，左半部分有零星的亮点，是数据导入的过程，，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的局部访问热点（最亮的那条线）。 第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面:\n左边比较密集的明亮黄块是导入数据阶段，右半段明暗相间的部分是进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。 如果你看懂了上面两个小例子，下面是一个小作业，这是我们模拟的一个实际用户的生产环境的照片，这个用户的系统遇到了一些瓶颈，你能看出问题吗？\n上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。\n顾名思义，分布式数据库，数据一定是分散在不同机器上的，对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。\n和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。\n现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。 然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？ 过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但是很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的，再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。有经验一些的 DBA 可能能从多个指标里通过自己的经验，模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维，老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。现代医学有 CT 有 B 超有核磁共振，这些现代化的手段极大的促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断，在计算机的世界道理也是相通的，最好通过某些工具让人更清晰的看到系统运行的健康状态、帮助诊断“病灶”，从而降低经验门槛和不确定性。 过去经常有朋友问我：「你说我这个业务适不适合使用 TiDB？」这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。有些信息可能是敏感的，也不方便共享。所以“预判 TiDB 到底适不适合某类业务”就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统都或多或少有类似的问题。 在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：","title":"我眼中的分布式系统可观测性"},{"content":"作为一个在中国的数据库软件从业者，最近被不少朋友在微信上询问业内某厂商「团队整合」的新闻，我其实并不想对这个事情发表什么评论。我始终坚信：基础软件，未来只有开源一条路。如果不开源，或者说内核不开源的话，产品的生命力是有限的。所以，在这里想分享一些我个人有关开源与闭源的看法，希望大家看完这篇文章后能够有些自己的思考 :）\n顺便提一下，看到这个标题，熟悉开源运动的朋友肯定会心一笑，没错，作为 ESR 的门徒，我从不掩饰对于《大教堂与集市》这篇著作的喜爱。另外作为从事开源的创业者，这几年的实践让我们对于 ESR 的这本书的理解更加的深入，我会试着在这篇文章总结一些我们经常被问到的问题，最后一部分我斗胆给 ESR 的理论在当今云时代的背景下做一些修订，另外我们讨论的软件范围仅限于基础软件（数据库，编译器，操作系统等）。\n一、代码是核心竞争力吗？ 我和一些闭源软件项目的作者聊过，大多数选择闭源的原因不外乎以下几种：\n 觉得自己的核心算法非常厉害，不希望竞争对手模仿 担心用户拿到代码，就不给钱了 没有找到或者建立自己的护城河 代码太丑，不好意思开源 怕被人找到 Bug  其中以前三种答案居多，我非常能理解，这些回答也都是非常正当的理由，只是这篇文章我们好好的就事论事的挨个分析一下，对于第四第五个理由，其实我不想过多展开，我们聊聊前两种，先看第一种，我在后边会聊聊第二种。\n对于第一种原因，我们再深入思考一下，一般可能有下面两种情况：\n 我的核心代码很短，可能是一个很巧妙的算法，或者一套很巧妙的参数 我的工程上的设计和实现得很优秀，系统架构是领先的  ● 对于第一种情况，我一直以来的观点是：如果在同一个行业里面，除非你达到了彻彻底底的人才垄断，那么在一个充分竞争的环境，如果这个问题是一个高价值问题，那么你能想到的短短的 「核心算法」，别人也同样能想得到。天下没有银弹，计算机科学就是在无数种妥协和不完美中寻找平衡的艺术（当然，图灵奖级别的 idea 或者量子计算机这种现象级的东西另说，但是这种机会是很少见的），即使通过闭源创造出短期的垄断优势，但是这个平衡一定会被另一个竞争对手打破，最终也一定会出现一个优质的开源替代品全部吞掉（这个开源事实标准短期看甚至不一定是更好的）。\n其实多数的产品优势是体现在工程实现上，也就是上面的第二种，一群优秀的工程师，在正确的设计下，构建出优质的软件。对于这种情况，无论开源还是不开源，竞争对手都没有办法很好的模仿，就像一个学霸，考了一个100分的答卷，把这个答卷给一个学渣看，学渣朋友肯定也没法马上变成学霸，因为代码只是结果，是什么样的思考和选择得到了这个结果，这个过程是没法开放的，所谓知其然不知其所以然，当然，就算你也很厉害，也有一批优秀工程师，短时间也做出了一个不错的产品，但是没关系，结局和前面提到那种情况也是一样的：只要你是闭源的，这个问题又足够普遍且高价值，那么长远来看一定会有一个开源的解决方案吞掉一切。这背后的原因其实和代码没有什么关系，因为代码在这里其实并不是核心竞争力。关于前面提到的第三种理由，我认为是和第一种类似，作者可能认识到代码并不一定是核心竞争力，但是没有构建好护城河的情况下，只能选择将代码作为护城河。\n二、代码不是核心竞争力，那什么才是？ 在聊真正的核心竞争力之前，我们来聊聊闭源软件的局限性。\n我们看看一个闭源的软件的一生：立项的动机可能是某个公司或者个人对于一个市场机会的洞见找到了一个高价值的场景，通过开发一个软件能够很好的提高效率或创造价值，甚至可能就是一张来自甲方的合同，总之这个公司招募了一伙程序员，设计师，产品经理，开始项目的开发。一切顺利的情况，顺利的满足了甲方的需求，甲方也很开心的付钱了，然后这个公司发现，好像这个软件改一改（甚至不用改）也就能够在同行业另一个客户那边卖出去，这就太好了，感觉找到了一条致富路。可是好境不长，客户这边的场景和需求在变化，原来的软件可能不一定能够满足新的需求了，但是开发团队就这几杆枪，稍有不慎一个方向判断错误，可能时间和机会窗口就错过了。这就意味着，对于项目领头人的要求就很高，要求持续能够引领行业的方向。还有一种方式是挑选一个相对狭窄或迭代不快的领域，存活时间能够延长一些。对于甲方也很难受，总是感觉需求的满足慢半拍，甚至对于有些有着研发能力的甲方，因为受限于没有源码，就算知道如何改进，也只能干瞪眼。\n其实这个问题的本质在于：闭源软件开发商虽然可能是技术的专家，但是并不一定是业务或者场景的专家，软件进化的速度受限于开发团队和产品经理自己的认知和见识的进化速度，除非开发商强大到能够持续引领整个行业的进化方向，否则无解。\n其实这个问题，教员早就给出了答案：「\u0026hellip;凡属正确的领导，必须是从群众中来，到群众中去。这就是说，将群众的意见（分散的无系统的意见）集中起来（经过研究，化为集中的系统的意见），又到群众中去作宣传解释，化为群众的意见，使群众坚持下去，见之于行动，并在群众行动中考验这些意见是否正确。然后再从群众中集中起来，再到群众中坚持下去，如此无限循环，一次比一次地更正确、更生动、更丰富\u0026hellip;」 \u0026mdash; 《关于领导方法的若干问题》, 1943\n要我说教员放在当代，就算是当个程序员，也能是一个大师级别的。教员的这段话，包含两个关键的点，完美的解释了开源软件的生命力的来源，我下面的详细讲讲。\n第一点，开源软件的生命力来自于场景的垄断，而背后更本质的垄断是人才垄断。\n为什么强调从群众中来？回顾刚才我们闭源软件的那段，其实一个关键的点是，软件的初始动机虽然来自于少数人的洞见，但是持续保持洞见并不是一件容易的事情，这就是为什么很多技术团队或者产品团队容易「自嗨」，一旦脱离用户，极易出现这样的问题。闭源软件厂商触及用户的手段不外乎于传统的商业宣传和销售，用户从感兴趣到使用起来的门槛很高，实施的周期也很长，另外通常销售会站在产品团队和客户中间，通过一些信息不对称来获取超额的利润，其中最大的信息不对称就是封闭的源代码本身或者定制化。这导致的问题是，相比流行的开源软件，闭源软件没有办法高效的获取，吸收和理解更多的场景，这对于一个通用的基础软件产品来说通常是一个致命的问题，如果见过的场景不够多，更没有办法判断产品那些需求该做是普遍需求，哪些是伪需求坚决不做，我认为这就是做产品的「触感」。\n对于一个流行的开源软件，本身不会有上面提到的问题：因为有足够多的用户，那么一定能看到足够多的场景，也能看到足够多的稀奇古怪的用法，这一个个用户的反馈，修过的一个个 bug，提出的一个个建议，会持续的产生类似「复利」的效果，你的软件越强壮，见过的场景越广，会进一步让你接触到更大的用户群，帮助软件变得更强大，如此循环。实际上开源软件本质上是通过放弃一部分通过信息不对称产生的潜在利润，换取了极其高效的传播和场景触及效率，但是有意思的是，实际上牺牲掉的这些潜在利润大概率也不一定真的牺牲掉，一来可能本身付费能力有限，二来可能实际上这些用户通过宣传站台二次传播或者代码贡献等方式回馈了项目本身。\n在上面那个过程中还会产生一个更加厉害的效应：人才的垄断。正所谓「事在人为」，上面提到的场景垄断中种种的技术决策和实践都是人来操作的。一个流行的开源软件在变成事实标准的过程中，一定会培养出大量熟悉这个产品的工程师，用户，摇旗呐喊的粉丝，代码贡献者，甚至挑刺吐槽的人。传统意义上，大家理解的开源社区只是狭义上的开发者社区，只有贡献代码才算参与，但是我认为只要和这个产品发生关联的人，都算是社区的一部分，「人尽其材」才是构建开源社区的终极目标。这个优势是会随着时间的流逝不断累积，这个很好理解，举个例子：A 公司的工程师在 A 公司的工作中学习使用了 TiDB 也很好的解决了问题，然后这个工程师作为数据库专家跳槽到了 B 公司，遇到同样的问题时，你猜他会选什么？ :)\n第二点，迭代，迭代，迭代，只有高速迭代才能立于不败之地\n上面教员的话里面有个关键的点，关于正向循环，也就是迭代。这个道理同样也适用于软件开发，软件从来都不是静止的，随着市场和竞争环境的变化，你今天的竞争优势，很可能明天就不是了。很多人都喜欢用静态的眼光看待问题，热衷于各种方案的横向对比，而忽略了进化速度，在这点上，我可能更看重的是同一个产品的纵向对比，举个例子：目前有 A, B, C三个方案，可能当下看这三个方案差距不大，也许在百分之五十之内。但是如果其中一个开源方案每次和自己半年前比都是在翻倍的提升（背后开源社区推动），但是闭源的方案的进步受限于团队规模和资源。这时候的选择除非是那种火烧眉毛的情况，否则一定应该选择一个迭代速度更快，增长率更好，更代表未来的方案，这个也很好理解。这是人的思维的一个惯性，人总是倾向用线性思维去看待问题，于是对非线性增长的事物往往会习惯性的低估。\n说一个更加震撼的例子，我粗略统计了一下，从 2018 到现在，也就短短一年多时间，整个 TiDB 的 SQL 层这么一个项目发生了 30000 多次提交，有接近 60% 的源码被修改。也就是说，每一年的 TiDB 都和上一年是不一样的，是一个更适应当下的，更加进步的一个 TiDB，而且随着社区的不断壮大，迭代的速度会越来越快。我完全不能想象，如果 TiDB 是一个闭源软件，从第一行代码开始写，到现在短短的 5 年时间，如何能够到达现在这个成熟度，这一切都是得益于开源社区的带来的加速度和反复迭代。\n三，如何挣钱？未来在云端 刚才我们聊了很多产品哲学上的东西，我们接下来聊聊商业，以及在云时代开源软件的位置。让我们回到开篇提到的那个话题：担心用户拿到代码，就不给钱了。这个观点背后的一个暗示是，用户付费买的是代码，如果有代码，用户就没有其他理由付钱。其实这个结论是靠不住的，**客户付费买的是解决问题和创造价值，而不是代码，如果拿到你的代码自己折腾付出的成本大于给你的钱（如果你能如实交付价值的话），用户没有任何理由不付钱。**而且这里的成本包括，比较明显的成本，例如人力成本，机器成本。也包括一些经常被人忽略的成本，例如错失市场机会的沉没成本，业务改造迁移成本，学习成本，线上出问题没人懂修带来的风险成本，这些隐性的成本往往是比显性的成本高得多的。\n上面我的解释中暗示了一点：软件的价值取决于它解决了什么问题，创造了什么价值，而不是开源与否。举个例子：一个分布式关系性数据库，一定比一个分布式缓存更加有商业价值，这是由前者的应用场景，存储的数据以及提供的能力决定的，而不是开源与否。所以这就是为什么我们要做通用数据库的核心原因，因为价值天花板更高。\n还有一点需要强调的，开源并不是一个商业模式，而是一种更好的软件开发和分发模式。另外，我认为商业模式和软件本身一样，也是需要设计的，这个设计取决于产品特性和公司的属性，这就意味着适用于 A 产品的商业模式，不一定适用于 B，甚至同一个产品，不同的公司，可能适合的商业模式都是不一样的。\n● 用我很崇敬的华为公司举个例子，华为是一个很厉害的通信设备制造商，很成功的手机终端厂商，很成功的硬件厂商。卖通信设备，卖手机，卖服务器，大家发现共性了吗？ 华为很会卖硬件和盒子，巨大的商业成功带来了很大的惯性，硬件和通讯设备的市场的特点是：各家产品本身能力差不太多（至少没有代差），比拼的是满足客户其他需求的能力以及低价（例如：服务，更快的响应，充分的定制化）。所以不难理解，华为软件的思路会通过低价甚至软件免费进入客户场景，然后通过硬件获取利润的商业模式。这个模式的问题在于，客户不能多，一旦战线拉得太长，项目的预算和硬件的利润都没有办法的抹平定制化软件的研发成本和支持成本时，这个模式就会出现问题。\n我认为如果想要通过软件创造可规模化的持续利润，需要两个关键点：\n 生态，软件能形成生态或者和现有生态有机整合，由生态补齐单一产品的能力，从而才能进一步能形成解决方案。 渠道，高效的分发渠道和支持渠道，这确保在用户规模化后，作为厂商的销售和售后成本不会随着客户的增长而增长（至少成本增长的斜率需要更缓）。  两者缺一不可。对于第一点，开源软件构建生态是很天然的，开发者和解决方案提供商会很自然的通过不同开源软件的组合做到解决方案的覆盖，这个效率是闭源定制化软件很难跟上的，这点不赘述。\n第二点，其实理想的渠道就是云。云标准化了硬件，标准化了计算力，甚至标准化了计算力的交付方式，尤其是公有云。一切都是标准化的好处就是可以自动化，这个对于软件供应商来说才是真正的价值。\n所以开源 + 云的模式，在开源这端，完成了开发者的心智占领和解决方案的成型，然后在云这端完成极其高效的分发和价值传递。看上去很美不是吗？理论上确实没问题，但是一定会有朋友挑战我说：这个模式里面没有你们开源软件厂商什么事情啊？云为什么不自己提供开源软件服务？这几年沸沸扬扬的 AWS 吸血事件逼得一堆开源公司和项目改协议，就是一个例子呀。\n关于这个问题，我的看法可能和主流观点有点不一样：\nCloud is eating Open-source? No, Open-source is eating the cloud.\n云厂商就像当年的运营商一样，占据着和客户对接的第一位置，当然很自然的在关键路径上放自家的产品。但是移动梦网和飞信的故事后来大家都看到了，拿飞信做一个例子，大家还记得作为移动的飞信，当年是没有办法和联通电信的手机号码互通的，直到后来微信的出现，终于事实上打通了各个运营商，所以市场格局就出现了很明显的分水岭，运营商是谁不重要，只要保证网络通信号好就行。对于云也是一样，AWS 肯定不会为 GCP 提供舒服的迁移和打通方案，反过来也不可能，但是对于客户来说，这个选择就像逼着用户选移动的飞信还是联通的沃友一样（我猜你可能都没听说过沃友吧 :) ），用户肯定说：不好意思，两个都不要，我选微信。从另一方面来说，对于在云上提供开源软件服务这件事情，云厂商本身的投入其实不一定有这个开源项目背后的公司多，一个很好的例子是 Databricks 是 Spark 创始团队的公司，也是一个 100% 在 AWS 上提供 Spark 服务的公司，相比起 AWS 的官方 EMR，Databricks 完全不占下风甚至客户和产品都胜过原生的 EMR。就像飞信的开发团队的质量肯定没有微信高，是一样的。\n由于开源软件的中立性，使得开源软件成为用户在多个云厂商之间保持统一体验和统一服务的几乎唯一选项。因为开源软件和开源服务商的存在，市场我相信会进入一个平衡：云厂商会持续优化它擅长的东西，真正的将云基础能力变成水电煤一样的规模化生意，开源软件厂商基于云的标准基础设施构建服务并交付业务价值，开源软件项目和社区由于厂商的持续持续，不断的蓬勃发展，占领更多用户的心智。三者形成一个价值链的闭环。不要着急，让子弹飞一会儿。\n洋洋洒洒写了几千字，聊了聊开源，最后我想用一段《大教堂与集市》书里我很喜欢的一句话作为结尾：\n「**\u0026hellip;Often, the most striking and innovative solutions come from realizing that your concept of the problem was wrong\u0026hellip;\n\u0026hellip;通常，那些最有突破性和最有创新力的解决方案来自于你认识到你对问题的基本观念是错的\u0026hellip;**」\n","permalink":"http://c4pt0r.github.io/posts/oss-in-china/","summary":"作为一个在中国的数据库软件从业者，最近被不少朋友在微信上询问业内某厂商「团队整合」的新闻，我其实并不想对这个事情发表什么评论。我始终坚信：基础软件，未来只有开源一条路。如果不开源，或者说内核不开源的话，产品的生命力是有限的。所以，在这里想分享一些我个人有关开源与闭源的看法，希望大家看完这篇文章后能够有些自己的思考 :）\n顺便提一下，看到这个标题，熟悉开源运动的朋友肯定会心一笑，没错，作为 ESR 的门徒，我从不掩饰对于《大教堂与集市》这篇著作的喜爱。另外作为从事开源的创业者，这几年的实践让我们对于 ESR 的这本书的理解更加的深入，我会试着在这篇文章总结一些我们经常被问到的问题，最后一部分我斗胆给 ESR 的理论在当今云时代的背景下做一些修订，另外我们讨论的软件范围仅限于基础软件（数据库，编译器，操作系统等）。\n一、代码是核心竞争力吗？ 我和一些闭源软件项目的作者聊过，大多数选择闭源的原因不外乎以下几种：\n 觉得自己的核心算法非常厉害，不希望竞争对手模仿 担心用户拿到代码，就不给钱了 没有找到或者建立自己的护城河 代码太丑，不好意思开源 怕被人找到 Bug  其中以前三种答案居多，我非常能理解，这些回答也都是非常正当的理由，只是这篇文章我们好好的就事论事的挨个分析一下，对于第四第五个理由，其实我不想过多展开，我们聊聊前两种，先看第一种，我在后边会聊聊第二种。\n对于第一种原因，我们再深入思考一下，一般可能有下面两种情况：\n 我的核心代码很短，可能是一个很巧妙的算法，或者一套很巧妙的参数 我的工程上的设计和实现得很优秀，系统架构是领先的  ● 对于第一种情况，我一直以来的观点是：如果在同一个行业里面，除非你达到了彻彻底底的人才垄断，那么在一个充分竞争的环境，如果这个问题是一个高价值问题，那么你能想到的短短的 「核心算法」，别人也同样能想得到。天下没有银弹，计算机科学就是在无数种妥协和不完美中寻找平衡的艺术（当然，图灵奖级别的 idea 或者量子计算机这种现象级的东西另说，但是这种机会是很少见的），即使通过闭源创造出短期的垄断优势，但是这个平衡一定会被另一个竞争对手打破，最终也一定会出现一个优质的开源替代品全部吞掉（这个开源事实标准短期看甚至不一定是更好的）。\n其实多数的产品优势是体现在工程实现上，也就是上面的第二种，一群优秀的工程师，在正确的设计下，构建出优质的软件。对于这种情况，无论开源还是不开源，竞争对手都没有办法很好的模仿，就像一个学霸，考了一个100分的答卷，把这个答卷给一个学渣看，学渣朋友肯定也没法马上变成学霸，因为代码只是结果，是什么样的思考和选择得到了这个结果，这个过程是没法开放的，所谓知其然不知其所以然，当然，就算你也很厉害，也有一批优秀工程师，短时间也做出了一个不错的产品，但是没关系，结局和前面提到那种情况也是一样的：只要你是闭源的，这个问题又足够普遍且高价值，那么长远来看一定会有一个开源的解决方案吞掉一切。这背后的原因其实和代码没有什么关系，因为代码在这里其实并不是核心竞争力。关于前面提到的第三种理由，我认为是和第一种类似，作者可能认识到代码并不一定是核心竞争力，但是没有构建好护城河的情况下，只能选择将代码作为护城河。\n二、代码不是核心竞争力，那什么才是？ 在聊真正的核心竞争力之前，我们来聊聊闭源软件的局限性。\n我们看看一个闭源的软件的一生：立项的动机可能是某个公司或者个人对于一个市场机会的洞见找到了一个高价值的场景，通过开发一个软件能够很好的提高效率或创造价值，甚至可能就是一张来自甲方的合同，总之这个公司招募了一伙程序员，设计师，产品经理，开始项目的开发。一切顺利的情况，顺利的满足了甲方的需求，甲方也很开心的付钱了，然后这个公司发现，好像这个软件改一改（甚至不用改）也就能够在同行业另一个客户那边卖出去，这就太好了，感觉找到了一条致富路。可是好境不长，客户这边的场景和需求在变化，原来的软件可能不一定能够满足新的需求了，但是开发团队就这几杆枪，稍有不慎一个方向判断错误，可能时间和机会窗口就错过了。这就意味着，对于项目领头人的要求就很高，要求持续能够引领行业的方向。还有一种方式是挑选一个相对狭窄或迭代不快的领域，存活时间能够延长一些。对于甲方也很难受，总是感觉需求的满足慢半拍，甚至对于有些有着研发能力的甲方，因为受限于没有源码，就算知道如何改进，也只能干瞪眼。\n其实这个问题的本质在于：闭源软件开发商虽然可能是技术的专家，但是并不一定是业务或者场景的专家，软件进化的速度受限于开发团队和产品经理自己的认知和见识的进化速度，除非开发商强大到能够持续引领整个行业的进化方向，否则无解。\n其实这个问题，教员早就给出了答案：「\u0026hellip;凡属正确的领导，必须是从群众中来，到群众中去。这就是说，将群众的意见（分散的无系统的意见）集中起来（经过研究，化为集中的系统的意见），又到群众中去作宣传解释，化为群众的意见，使群众坚持下去，见之于行动，并在群众行动中考验这些意见是否正确。然后再从群众中集中起来，再到群众中坚持下去，如此无限循环，一次比一次地更正确、更生动、更丰富\u0026hellip;」 \u0026mdash; 《关于领导方法的若干问题》, 1943\n要我说教员放在当代，就算是当个程序员，也能是一个大师级别的。教员的这段话，包含两个关键的点，完美的解释了开源软件的生命力的来源，我下面的详细讲讲。\n第一点，开源软件的生命力来自于场景的垄断，而背后更本质的垄断是人才垄断。\n为什么强调从群众中来？回顾刚才我们闭源软件的那段，其实一个关键的点是，软件的初始动机虽然来自于少数人的洞见，但是持续保持洞见并不是一件容易的事情，这就是为什么很多技术团队或者产品团队容易「自嗨」，一旦脱离用户，极易出现这样的问题。闭源软件厂商触及用户的手段不外乎于传统的商业宣传和销售，用户从感兴趣到使用起来的门槛很高，实施的周期也很长，另外通常销售会站在产品团队和客户中间，通过一些信息不对称来获取超额的利润，其中最大的信息不对称就是封闭的源代码本身或者定制化。这导致的问题是，相比流行的开源软件，闭源软件没有办法高效的获取，吸收和理解更多的场景，这对于一个通用的基础软件产品来说通常是一个致命的问题，如果见过的场景不够多，更没有办法判断产品那些需求该做是普遍需求，哪些是伪需求坚决不做，我认为这就是做产品的「触感」。\n对于一个流行的开源软件，本身不会有上面提到的问题：因为有足够多的用户，那么一定能看到足够多的场景，也能看到足够多的稀奇古怪的用法，这一个个用户的反馈，修过的一个个 bug，提出的一个个建议，会持续的产生类似「复利」的效果，你的软件越强壮，见过的场景越广，会进一步让你接触到更大的用户群，帮助软件变得更强大，如此循环。实际上开源软件本质上是通过放弃一部分通过信息不对称产生的潜在利润，换取了极其高效的传播和场景触及效率，但是有意思的是，实际上牺牲掉的这些潜在利润大概率也不一定真的牺牲掉，一来可能本身付费能力有限，二来可能实际上这些用户通过宣传站台二次传播或者代码贡献等方式回馈了项目本身。\n在上面那个过程中还会产生一个更加厉害的效应：人才的垄断。正所谓「事在人为」，上面提到的场景垄断中种种的技术决策和实践都是人来操作的。一个流行的开源软件在变成事实标准的过程中，一定会培养出大量熟悉这个产品的工程师，用户，摇旗呐喊的粉丝，代码贡献者，甚至挑刺吐槽的人。传统意义上，大家理解的开源社区只是狭义上的开发者社区，只有贡献代码才算参与，但是我认为只要和这个产品发生关联的人，都算是社区的一部分，「人尽其材」才是构建开源社区的终极目标。这个优势是会随着时间的流逝不断累积，这个很好理解，举个例子：A 公司的工程师在 A 公司的工作中学习使用了 TiDB 也很好的解决了问题，然后这个工程师作为数据库专家跳槽到了 B 公司，遇到同样的问题时，你猜他会选什么？ :)\n第二点，迭代，迭代，迭代，只有高速迭代才能立于不败之地\n上面教员的话里面有个关键的点，关于正向循环，也就是迭代。这个道理同样也适用于软件开发，软件从来都不是静止的，随着市场和竞争环境的变化，你今天的竞争优势，很可能明天就不是了。很多人都喜欢用静态的眼光看待问题，热衷于各种方案的横向对比，而忽略了进化速度，在这点上，我可能更看重的是同一个产品的纵向对比，举个例子：目前有 A, B, C三个方案，可能当下看这三个方案差距不大，也许在百分之五十之内。但是如果其中一个开源方案每次和自己半年前比都是在翻倍的提升（背后开源社区推动），但是闭源的方案的进步受限于团队规模和资源。这时候的选择除非是那种火烧眉毛的情况，否则一定应该选择一个迭代速度更快，增长率更好，更代表未来的方案，这个也很好理解。这是人的思维的一个惯性，人总是倾向用线性思维去看待问题，于是对非线性增长的事物往往会习惯性的低估。\n说一个更加震撼的例子，我粗略统计了一下，从 2018 到现在，也就短短一年多时间，整个 TiDB 的 SQL 层这么一个项目发生了 30000 多次提交，有接近 60% 的源码被修改。也就是说，每一年的 TiDB 都和上一年是不一样的，是一个更适应当下的，更加进步的一个 TiDB，而且随着社区的不断壮大，迭代的速度会越来越快。我完全不能想象，如果 TiDB 是一个闭源软件，从第一行代码开始写，到现在短短的 5 年时间，如何能够到达现在这个成熟度，这一切都是得益于开源社区的带来的加速度和反复迭代。","title":"大教堂终将倒下，但集市永存"},{"content":"前些天在与友人喝咖啡的时候，正好聊到关于 PingCAP 和 TiDB 的一些历史以及对于开源软件公司核心竞争力的理解，回顾这几年的创业生涯和 TiDB 社区的生长壮大，就像是一场巨大且正在进行中的社会学实验，原本零散的一些想法随着一条主线变得逐渐清晰，就想着写成文章总结一下关于社区对于开源软件以及开源公司到底意味着什么。\n无处不在的网络效应 两种网络效应\n很多人听说过网络效应（梅特卡夫效应：网络的价值与联网用户的平方数成正比），许多伟大的产品和公司通过网络效应构建起了强大的护城河。提到网络效应，经典例子在通信领域，例如手机，每多一个用户，对于所有用户的价值就越大，虽然大家也无意为他人创造价值，但是一旦开始使用，该行为就会帮助这个网络创造价值。很多我们熟知的 to C公司，尤其是社交网络和IM（即时通信软件） ，通过这个效应构建了极高的壁垒。NfX Venture 在他们的一篇博客(https://www.nfx.com/post/network-effects-manual/）中详细描述了很多种网络效应，在介绍社区之前，我想着重介绍下其中和开源软件相关的两种网络效应。\n 基于从众心理的网络效应  这类网络效应通常是从一些意见领袖开始，可能是行业大咖，可能是社交潮人，常常出现在一个新产品要去进攻一个老产品的市场时。尽管这个新产品相比市场的统治者来说不一定成熟，但它通常会带着一些鲜明的特色或者更加前沿的理念，吸引那些对「主流」不满或者希望突显自身前沿视野的意见领袖的支持，造成一种「很酷的人都在用，你不用你就要被淘汰了」的感觉。\n这种感觉会在新用户纷纷加入时，形成从众心理的网络效应，但是**这类网络效应的持续时间不会太长。**细想一下就能知道：如果早期意见领袖只是因为突显「不同」而加入，那么在这个社区成为主流后，这些意见领袖就没有理由留下，追随这些人的粉丝可能会随之而去。另外，对于这个新产品来说，完善程度通常不如老产品，美誉和差评会在早期同时到来。此时，如果不快速通过网络效应打磨产品，获得更好的迭代速度，那么，这个网络效应是根基不牢的。一个好处在于，该效应在早期是事半功倍的。\n回想 TiDB 早期的社区建设，也是因为几个创始人在 Codis 的工作以及在国内基础软件圈中积累的名声，和一些互联网技术圈中朋友的支持，形成最早的背书。\n 基于信仰的网络效应  **所谓「信仰」，就是基于对一个理念的认可而加入，从而形成网络效应。**这点在软件领域也不少见，自由软件运动和开源运动都是很好的例子。人嘛，总是要相信点什么。**这类网络效应的护城河是极深的，而且对于产品缺陷的容忍度极高。**因为信念是一个长期的念想，对于 TiDB 来说，这个念想形如：相信分布式是未来，相信云时代的业务需要像 TiDB 这样的数据库。但是这个目标又是足够有挑战的，值得长期为之努力。\n基于信仰的网络效应可能在最早期和从众心理网络效应有点类似，其中的关键是社区核心人群对于产品背后的理念是否有坚定信仰。反之，如果只是简单地秀优越感，是不会长久的，随着兴趣衰减，网络效应也会崩塌。\n网络效应对于基础软件的意义\n对于基础软件来说，我一直坚持两个观点：\n 基础软件是被“用”出来的，不是“写”出来的。 迭代和进化速度是这类软件的核心竞争力。  这两点恰恰是网络效应能带来的，虽然价值链条不像IM那样明显，但是，网络效应存在的基础是新用户给老用户带来的额外价值。而基础软件的价值，体现为以下几点：\n 可控的风险（稳定性） 更多的场景适应性（发现新的适用场景和持续提升性能） 良好的易用性  对于风险控制来说，越多人用意味着风险被越多人均摊，其中的一个假设是：我不特别，我遇到的问题别人应该也遇到过，一定有人能比我早发现并修复它。这个假设在一个成熟且活跃的基础软件社区是成立的，因为基础软件的场景边界相对清晰，在适用范围内的路径大致相同，同一条路径走多了，坑自然就少了。只要有一个人踩到坑，反馈回社区，不管最后是谁修好的，这个行为对于其他用户都是受益的。\n同样的逻辑，对于场景适应性来说也成立。个体的认知总是带有局限性，即使是项目的创始团队，也不见得对于某个具体的应用场景有深刻理解。社区用户的创造力是无穷的，一些设计外的使用路径可能会出奇地好用，从而发展出新的优势场景。同样地，只要有一个成功案例，那么对于其他具有相似场景的用户来说，软件的价值就增加了， TiDB 和 Flink 组合成的实时 HTAP 数据处理方案，就是一个很好的例子。\n对于易用性改进的逻辑和稳定性类似，我就不赘述了。利用网络效应带来的飞轮效应改进软件，这个思路我在《大教堂终将倒下，但集市永存》一文中也提到过。\n社区的成熟度曲线和必经阶段 社区的诞生\n在 GitHub 上开放你的源代码，甚至使用公开的 Git 工作流，都不是社区诞生的时刻。一个社区真正诞生，是在你和你的代码之外，开始有第三者介入并产生连接的时刻，可能是收到第一个外部 PR，可能是收到第一个外部 issue，这些才是社区的开端。社区始于连接，也成就于连接。开放源代码并不等同于开源，很多团队和项目在开放源代码方面花费了很多时间，却忽略了代码及背后团队的社区化，这是很可惜的。\n死亡鸿沟和希望之坡\n就像《跨越鸿沟》这本书中提到的，开源软件也有自己的生命周期曲线，这是和社区息息相关的。\n图中断层出现的原因是产品成熟度迟迟没有跟上，用户过来以后发现都是坑，随之而来的各种差评会让早期支持者和创始人疲于奔命甚至而失去兴趣。\n**对于一个开源软件，断层的体现可能是经历早期快速增长后，来到长达 1~2 年的静默期，增长几乎停滞。**对于社区来说，几乎所有的精力都用在给早期用户填坑，期间会有用户自然增长但流失率也非常高。这个阶段对于资源的消耗非常大，社区的核心贡献者也会非常累，如果熬不过去就死了，所以说是“死亡鸿沟”。\n好消息是，这个阶段终将会过去，bug 这种东西嘛，改掉一个就少一个，产品也会在这个阶段逐渐摸索到自己的定位和最佳实践，而在最佳实践这个路径上，产品会变得越来越稳定和聚焦。如果定位是市场刚需，**那么就会迎来一个高速增长阶段（成熟期），而社区的生态也会随着产品的普及开始加速度发展。**这个从上图的 Kubernetes 和 TiDB 的搜索指数里面能看到这个鸿沟的一个侧写。\n社区的终局\n一个好的开源软件社区的终局会是什么样子？对于这个问题，其实我们有很多能参考的例子，例如 GNU Linux、Hadoop、Spark、MySQL 等等。我认为，不管一个开源软件及社区是由商业公司发起还是其他方式发起、壮大，到最后一定会出现独立于某公司之外的中立组织来接管这个社区，这也是最自然合理的方式。\n尤其是公司主导的开源项目，在后期会面临中立性的问题。因为对于公司而言，最重要的是客户成功，对商业化的诉求一定会影响开源软件功能设置和开发优先级。而且优先级往往是会变的（可能更紧急且更具体），变化也许会和社区的开发节奏冲突，但我不认为这两者的矛盾不可调和，我会在下文展开来讲。\n**中后期的开源软件已经支撑着太多用户的场景成功和商业利益，由一个中立的委员会来平衡各方的利益及监督各方的责任是目前看来比较成功的实践，**而且开始有这样的组织，也从侧面说明这个项目已经成熟，已经有良好的生态。还没有到达这个阶段的开源软件大多是由项目背后的公司主导社区，在项目成熟阶段，重点是不断地通过优化客户和场景的成功让整个飞轮转动起来，当主导公司之外有越来越多的成员在思考和实践 governance rule，这就是一个积极的信号。\n社区和商业化如何共存 种地和做菜 \u0026amp; 河与岸上的人\n前文留下一个问题，就是开源与商业化的矛盾，不管我如何解释，本质上开源和传统的软件售卖模式一定是冲突的。\n我举一个比较好理解的例子：如果将开源比作种菜，开源软件源代码相当于种子，业务成功相当于长出来的菜，传统的软件商业模式类似于卖种子，但是种地施肥（hosting）都是客户自己的工作。开源软件的种子是免费的，地是客户的，种地的人也是客户的人，所以开源厂商大概只能提供种地指导服务，尤其在一些种子不是太好种的情况下，指导服务是有意义的。但仔细想想，随着种子不断改良（性能、稳定性、易用性等），随便撒到地里就能开花结果，那么专业的种菜服务就没什么必要性了。于是厂商只好卖一些额外的价值，比如保险服务，万一种子生长遇到极端天气，至少有专家团在背后帮忙解决。但是这种商业模式仍然比较别扭，因为价值链条大部分都在客户自己这边。所以，如果厂商看待社区只停留在潜在客户视角，很难做出好产品，因为没有内在动力去持续优化软件。\n一个更好的视角是往后退一步，我再举个好理解的例子：将社区当成一条河流，不属于任何人，大家共同保持河水的清澈和流动性，谁都不要过度捞鱼，不同的组织和个人都可以在河流周边构建自己的生态，至于岸上的人靠什么挣钱，那是另外一个问题，后文再讲。\n客户成功和用户体验：内在的一致性\n虽然开源软件商业公司的第一目标是客户成功，但这和做好社区并不矛盾。**一个常见的误区是在开源软件公司内部，这两个团队形成对立关系。**商业团队认为社区就是给商业化养鱼的，养肥了就要收割，极端点就动不动要闭源；社区团队认为商业化会减慢生态传播的速度，使用门槛上升，极端做法是产生反商业化的倾向。如果都只在自己的位置上思考问题，当然双方都没错，那到底是哪里有问题呢？\n问题出在了“阶段”和“客户选择”，社区用户和商业用户使用开源软件的生命周期可能完全不同，一般的开源软件公司会有两个漏斗，我称之为社区漏斗和商业漏斗。有些说法认为社区漏斗是商业漏斗的上层，我之前也深以为然，但经过几年的实践，我渐渐发现其实并不是那样。这两者是独立的，如果只是简单地作为一个漏斗，那么就会有很多问题，比如经典问题：不会流到商业漏斗的社区用户，其价值到底是什么？所以，肯定不是一个漏斗，而是有很深的内部联系。\n什么联系？为方便理解，还是用种菜举例说明。开源社区孵化出来的东西，例如用户成功案例、社区贡献对产品的打磨、探索出来的适用场景等，就像一个个生的菜和食材，而客户想要一盘鱼香肉丝，并不关心盘子中的肉和菜是怎么来的，所以看到关键点了吗？商业化团队的角色就像是厨师，社区运营团队就像农民，二者的关注点并不一样，厨师关注点是如何做好菜，农民的关注点是如何种好地，产生更好的食材。从食材到一道菜，还要经历很长的过程，但没有好食材，能力再强的厨师也难做出一盘好菜。\n**对于开源软件公司来说，社区和商业这两个团队的内部一致性是：好产品和制胜场景。**根据我们的实践经验，比较好的做法是，社区团队聚焦于两个关键点：\n 社区用户对于产品的打磨（在制胜场景下）； 发现更多的制胜场景。  这两个关键点会形成闭环，社区团队持续产生食材（制胜场景以及持续进化的产品），商业团队聚焦于制胜场景的进一步加工和客户旅程优化，两个团队互相配合拉动整个公司和项目的大循环。例如TiDB商业用户的场景和解决方案，大多是从社区用户中诞生并打磨成熟，尽管可能两个用户群体完全不一样，但是通过 TiDB 形成了一个大的生态——商业化的循环，而PingCAP 就是中间的桥梁。另外，社区和商业化团队会有一个共同的北极星指标：用户体验。\n可规模化变现的唯一出路：云\n一个好的生意应该是可以规模化的，传统开源软件公司的商业模式，问题在于规模化中需要人的介入，销售/售前/售后交付等等，而基于人的生意是没法规模化的。在云诞生前这个问题是无解的，所以开源软件公司需要寻找一个和开源无关的软件商业模式（听起来有点别扭，但是仔细想想确实如此），而云本质上是一个资源租赁生意。\n还是以种菜的例子来说，过去传统的商业模式中，因为土地和种菜人都是客户自己的，所以开源软件公司的位置就比较尴尬，但是在云上，基础软件商业模式本质上是一个hosting服务，让原来价值链条中最重要的一部分“土地”（ hosting资源和基础设施）掌握在了厂商手上，这对于用户来说也是好的，毕竟管理“土地”也是一件费心费力的事情，而且很难做到按需购买。问题在于用户想要的只是一道好菜而已，注意这和开源（种菜）并没有什么关系，因为不管开不开源，用户支付的都是管理和租赁费用，相当于即使种子和食材免费，顾客去饭店吃饭，也需要为菜品买单，因为顾客购买的是好菜和服务体验。\n另外，**很多人认为开源社区是竞争壁垒，其实并不是，真正的壁垒是生态，而开源社区是构建生态的一种高效方式，如果一个产品不用开源也构建起了生态，那么效果是一样的。**一个很好的例子就是 Snowflake，尽管 Snowflake 没有开源，但是2012年诞生伊始，它在云数据仓库这个市场内几乎没有任何竞争对手，留给 Snowflake 足够的时间通过差异化定位和极佳的用户体验构建自己的生态，依托云的崛起和规模化效应取得了巨大成功。\n如何做好社区 上文形而上地讨论了很多关于哲学的内容，接下来聊聊落地实践。想要做好开源社区其实是有方法论的，但前提是有正确的思考方式和思考角度，否则在实践环节你就会发现有无数事情可以做，却不知道哪件或哪些事情是更重要的，更难受的是你发现没法衡量对与错。以下是我的一些思考角度以及思考时考虑的重点指标，可作为社区运营者的参考。\n你是谁？你解决了什么问题？为什么是你？\n好社区的根基一定是好产品，要回答“你是谁”这个问题，一定是通过回答“你解决了什么问题”而得出的，这点和 to C 产品的运营很不一样。一些社区运营者会将注意力转移到各种活动或者宣传拉新，同时夸大产品能力，导致与现实不符，这是最常见的误区。\n很多做社区运营的朋友经常来找我：我也做了很多活动，写了很多文章，为什么看起来没有效果？通常这个时候我会问他：你能一句话说明白你的产品是做什么的吗？到底解决了什么问题？这个问题是普遍问题吗？非你这个产品不可吗？这个时候他就明白：完美的产品是不存在的，好的产品一定是跟随它的优势场景出现的，比如 Redis 显然不能用来做核心金融交易场景，但谁都不会否认Redis在缓存场景下是当之无愧的事实标准。同样的例子还有很多，例如 Spark、ClickHouse 等等。所以对于运营团队，在做任何动作之前要想清楚上面的四个问题。\n好用决定了漏斗的转化率\n找到制胜场景就够了吗？当然不是，如果把整个用户旅程当成一个漏斗，找到制胜场景充其量是找到正确的入口而已，进入漏斗以后，重要的事情就变成了提升各阶段的转化率，**决定转化率的一个关键指标是产品的易用性，**这点和做 to C 产品很像，很多做 to B 的团队会下意识忽略这一点，通常可能是两种原因：\n 不太重视社区用户 Self-service ，项目官方甚至鼓励用户联系官方团队，因为早期知道有人在用这个信息是很重要的，而商业客户基本服务和支持都是官方的，客户无感，对公司而言没有动力优化。 很多产品在诞生初期是救命型的产品，用户没有别的选择。例如早期的 TiDB ，在 MySQL 扩展需求迫在眉睫的时候，用户更关心如何立即把问题解决掉，内核能力更重要，其他的可以先缓缓，忍着就好。  这两种原因导致的结果就是，对易用性和用户体验关注不足，这个错误在市场竞争初期是很隐蔽的。一方面因为流进漏斗的 leads 数量不够大，人肉支持尚可，且市场的竞争还不激烈，用户没有其他选择。试想一下，当这个市场终有一天变得成熟，大量客户被充分教育后流入漏斗，团队的支持带宽肯定是不足的；另一方面，因为市场已经被教育成熟，一定会有竞争对手能做类似的事情，这时，当你不是市场中唯一的救命选择，用户一定会选择用着顺手且省心的一方，这不难理解。这就是为什么在开源软件竞争的中后期，易用性和用户体验要放在至高位置的原因。对于“用着省心”，假设已经通过成熟的生态和案例背书解决了，而在“用着顺手”这一点上，中国诞生的开源软件团队相比世界先进水平而言，差距很大，毕竟海外的开源软件竞争比国内更加激烈，因为国外开源市场诞生时间长，而且业务场景对于基础软件的需求也没有国内极端，通常好几个产品都能搞定同一个场景，那么这时当然就要比拼易用性（省心）和生态（放心）。\n有几个问题，作为开源项目的产品负责人可以问问自己，在你的产品领域里，如何定义好用？最佳实践是什么？世界上最好用的同类水平是怎么样的？我相信思考这些问题对产品发展会有帮助。一个反映易用性的好视角是：用户能够 Self-servicing 的程度，其指标体系较多：比如在云上自助完整整个产品生命周期的比例，在开源社区从接触到使用过程中不用提问的比例，开源社区活跃贡献者数量等等。\n二次传播是达成网络效应的关键\n上文提到过，网络效应产生的前提是，任何一个新用户的使用对于老用户是有价值加成的，所以试想：如果一个社区用户默默地使用了软件，默默地看了文档和最佳实践文章，甚至出了 bug 自己默默地修好（不贡献回来），这对这个社区和产品是有价值的吗？\n我认为是没有的。\n尽管我知道一定会有这样的用户存在，就像沉默的大多数人一样。对于社区运营者来说，**最关键的任务不是让沉默者更多或更深度地使用，而是让他们和网络中的其他用户建立更多的连接，**例如分享经验（写案例文章）、培养贡献者、积极向社区反馈使用中的问题等等，而且一定要将这些内容传递到网络的其他节点，确保产生价值。例如：一个用户的使用场景帮到了另一个用户选型，一个用户反馈帮助产品发现了一个 bug 并修复，这些都是产生价值的例子。切忌让用户变成一个个孤岛，社区运营者如果看不清这个关键点，可能会陷入为了数字（使用量）而追求数字的情况，做了很多工作，但从全局看不到进步。\n网络效应的转移\n社区运营的最高境界是将网络效应从使用者的网络效应转移到基于信仰的网络效应，将社区中心从开源公司内部转移到外部以获得更大的势能。这两者都不容易，对于前者可能更多的是抽象和总结提炼理念以及持续保持长远而正确的 insight（洞察），加之寻找合适的布道者群体，这点并不容易。对于后者来说，只要在以公司为中心的阶段积累足够多的成功案例和优势场景，并且投入资源教育市场，剩下的交给时间就好，这个阶段关注的指标是品牌力。开源软件社区运营是一个指数曲线的游戏，要抱着长期主义的心态去耕耘。\n最后作为结尾，我想谈谈，一个伟大的开源基础软件产品应该是什么样的？\n我眼中一个伟大的基础软件产品不仅仅是解决眼下的具体问题，而是开启一片新的天地，一个新的视角，创造新的可能性。就像智能手机的发明，它作为平台催生出了微信这样的伟大应用，开启了一个全新的世界。就像云、S3 和 EBS 的发明，给开发者提供了新的设计方式，催生出了Snowflake这类的新物种，彻底改变了人们使用分析数据的方式。而开源社区正是这类伟大基础软件诞生的最合适的土壤，就像鱼和水一样。\n我不知道社区会带来什么，我也不敢高估自己能力，毕竟在群体智慧面前，个人的力量永远是渺小的。\n","permalink":"http://c4pt0r.github.io/posts/in-community-we-trust/","summary":"前些天在与友人喝咖啡的时候，正好聊到关于 PingCAP 和 TiDB 的一些历史以及对于开源软件公司核心竞争力的理解，回顾这几年的创业生涯和 TiDB 社区的生长壮大，就像是一场巨大且正在进行中的社会学实验，原本零散的一些想法随着一条主线变得逐渐清晰，就想着写成文章总结一下关于社区对于开源软件以及开源公司到底意味着什么。\n无处不在的网络效应 两种网络效应\n很多人听说过网络效应（梅特卡夫效应：网络的价值与联网用户的平方数成正比），许多伟大的产品和公司通过网络效应构建起了强大的护城河。提到网络效应，经典例子在通信领域，例如手机，每多一个用户，对于所有用户的价值就越大，虽然大家也无意为他人创造价值，但是一旦开始使用，该行为就会帮助这个网络创造价值。很多我们熟知的 to C公司，尤其是社交网络和IM（即时通信软件） ，通过这个效应构建了极高的壁垒。NfX Venture 在他们的一篇博客(https://www.nfx.com/post/network-effects-manual/）中详细描述了很多种网络效应，在介绍社区之前，我想着重介绍下其中和开源软件相关的两种网络效应。\n 基于从众心理的网络效应  这类网络效应通常是从一些意见领袖开始，可能是行业大咖，可能是社交潮人，常常出现在一个新产品要去进攻一个老产品的市场时。尽管这个新产品相比市场的统治者来说不一定成熟，但它通常会带着一些鲜明的特色或者更加前沿的理念，吸引那些对「主流」不满或者希望突显自身前沿视野的意见领袖的支持，造成一种「很酷的人都在用，你不用你就要被淘汰了」的感觉。\n这种感觉会在新用户纷纷加入时，形成从众心理的网络效应，但是**这类网络效应的持续时间不会太长。**细想一下就能知道：如果早期意见领袖只是因为突显「不同」而加入，那么在这个社区成为主流后，这些意见领袖就没有理由留下，追随这些人的粉丝可能会随之而去。另外，对于这个新产品来说，完善程度通常不如老产品，美誉和差评会在早期同时到来。此时，如果不快速通过网络效应打磨产品，获得更好的迭代速度，那么，这个网络效应是根基不牢的。一个好处在于，该效应在早期是事半功倍的。\n回想 TiDB 早期的社区建设，也是因为几个创始人在 Codis 的工作以及在国内基础软件圈中积累的名声，和一些互联网技术圈中朋友的支持，形成最早的背书。\n 基于信仰的网络效应  **所谓「信仰」，就是基于对一个理念的认可而加入，从而形成网络效应。**这点在软件领域也不少见，自由软件运动和开源运动都是很好的例子。人嘛，总是要相信点什么。**这类网络效应的护城河是极深的，而且对于产品缺陷的容忍度极高。**因为信念是一个长期的念想，对于 TiDB 来说，这个念想形如：相信分布式是未来，相信云时代的业务需要像 TiDB 这样的数据库。但是这个目标又是足够有挑战的，值得长期为之努力。\n基于信仰的网络效应可能在最早期和从众心理网络效应有点类似，其中的关键是社区核心人群对于产品背后的理念是否有坚定信仰。反之，如果只是简单地秀优越感，是不会长久的，随着兴趣衰减，网络效应也会崩塌。\n网络效应对于基础软件的意义\n对于基础软件来说，我一直坚持两个观点：\n 基础软件是被“用”出来的，不是“写”出来的。 迭代和进化速度是这类软件的核心竞争力。  这两点恰恰是网络效应能带来的，虽然价值链条不像IM那样明显，但是，网络效应存在的基础是新用户给老用户带来的额外价值。而基础软件的价值，体现为以下几点：\n 可控的风险（稳定性） 更多的场景适应性（发现新的适用场景和持续提升性能） 良好的易用性  对于风险控制来说，越多人用意味着风险被越多人均摊，其中的一个假设是：我不特别，我遇到的问题别人应该也遇到过，一定有人能比我早发现并修复它。这个假设在一个成熟且活跃的基础软件社区是成立的，因为基础软件的场景边界相对清晰，在适用范围内的路径大致相同，同一条路径走多了，坑自然就少了。只要有一个人踩到坑，反馈回社区，不管最后是谁修好的，这个行为对于其他用户都是受益的。\n同样的逻辑，对于场景适应性来说也成立。个体的认知总是带有局限性，即使是项目的创始团队，也不见得对于某个具体的应用场景有深刻理解。社区用户的创造力是无穷的，一些设计外的使用路径可能会出奇地好用，从而发展出新的优势场景。同样地，只要有一个成功案例，那么对于其他具有相似场景的用户来说，软件的价值就增加了， TiDB 和 Flink 组合成的实时 HTAP 数据处理方案，就是一个很好的例子。\n对于易用性改进的逻辑和稳定性类似，我就不赘述了。利用网络效应带来的飞轮效应改进软件，这个思路我在《大教堂终将倒下，但集市永存》一文中也提到过。\n社区的成熟度曲线和必经阶段 社区的诞生\n在 GitHub 上开放你的源代码，甚至使用公开的 Git 工作流，都不是社区诞生的时刻。一个社区真正诞生，是在你和你的代码之外，开始有第三者介入并产生连接的时刻，可能是收到第一个外部 PR，可能是收到第一个外部 issue，这些才是社区的开端。社区始于连接，也成就于连接。开放源代码并不等同于开源，很多团队和项目在开放源代码方面花费了很多时间，却忽略了代码及背后团队的社区化，这是很可惜的。\n死亡鸿沟和希望之坡\n就像《跨越鸿沟》这本书中提到的，开源软件也有自己的生命周期曲线，这是和社区息息相关的。\n图中断层出现的原因是产品成熟度迟迟没有跟上，用户过来以后发现都是坑，随之而来的各种差评会让早期支持者和创始人疲于奔命甚至而失去兴趣。\n**对于一个开源软件，断层的体现可能是经历早期快速增长后，来到长达 1~2 年的静默期，增长几乎停滞。**对于社区来说，几乎所有的精力都用在给早期用户填坑，期间会有用户自然增长但流失率也非常高。这个阶段对于资源的消耗非常大，社区的核心贡献者也会非常累，如果熬不过去就死了，所以说是“死亡鸿沟”。","title":"In Community We Trust"}]