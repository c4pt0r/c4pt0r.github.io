<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Random Access Memroy</title>
    <link>http://c4pt0r.github.io/</link>
    <description>Recent content on Random Access Memroy</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 03 Dec 2021 12:33:24 +0800</lastBuildDate><atom:link href="http://c4pt0r.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>我眼中的分布式系统可观测性</title>
      <link>http://c4pt0r.github.io/posts/observability-keyviz/</link>
      <pubDate>Fri, 03 Dec 2021 12:33:24 +0800</pubDate>
      
      <guid>http://c4pt0r.github.io/posts/observability-keyviz/</guid>
      <description>今天的文章我想从这张模糊的照片说起，相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次「看到」了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓「一图胜千言」很多时候一张图传达的信息超过千言万语。 关于黑洞我不想展开太多，今天我们聊聊「望远镜」。
前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此，在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」，过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。
举几个直观的小例子，你知道 TPC-C 测试「长」什么样子吗？请看下图：
图中横轴是时间，纵轴是数据的分布，左半部分有零星的亮点，是数据导入的过程，，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的局部访问热点（最亮的那条线）。 第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面:
左边比较密集的明亮黄块是导入数据阶段，右半段明暗相间的部分是进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。 如果你看懂了上面两个小例子，下面是一个小作业，这是我们模拟的一个实际用户的生产环境的照片，这个用户的系统遇到了一些瓶颈，你能看出问题吗？
上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。
顾名思义，分布式数据库，数据一定是分散在不同机器上的，对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。
和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。
现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。 然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？ 过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但是很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的，再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。有经验一些的 DBA 可能能从多个指标里通过自己的经验，模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维，老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。现代医学有 CT 有 B 超有核磁共振，这些现代化的手段极大的促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断，在计算机的世界道理也是相通的，最好通过某些工具让人更清晰的看到系统运行的健康状态、帮助诊断“病灶”，从而降低经验门槛和不确定性。 过去经常有朋友问我：「你说我这个业务适不适合使用 TiDB？」这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。有些信息可能是敏感的，也不方便共享。所以“预判 TiDB 到底适不适合某类业务”就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统都或多或少有类似的问题。 在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：</description>
    </item>
    
    <item>
      <title>大教堂终将倒下，但集市永存</title>
      <link>http://c4pt0r.github.io/posts/oss-in-china/</link>
      <pubDate>Fri, 03 Dec 2021 12:16:37 +0800</pubDate>
      
      <guid>http://c4pt0r.github.io/posts/oss-in-china/</guid>
      <description>作为一个在中国的数据库软件从业者，最近被不少朋友在微信上询问业内某厂商「团队整合」的新闻，我其实并不想对这个事情发表什么评论。我始终坚信：基础软件，未来只有开源一条路。如果不开源，或者说内核不开源的话，产品的生命力是有限的。所以，在这里想分享一些我个人有关开源与闭源的看法，希望大家看完这篇文章后能够有些自己的思考 :）
顺便提一下，看到这个标题，熟悉开源运动的朋友肯定会心一笑，没错，作为 ESR 的门徒，我从不掩饰对于《大教堂与集市》这篇著作的喜爱。另外作为从事开源的创业者，这几年的实践让我们对于 ESR 的这本书的理解更加的深入，我会试着在这篇文章总结一些我们经常被问到的问题，最后一部分我斗胆给 ESR 的理论在当今云时代的背景下做一些修订，另外我们讨论的软件范围仅限于基础软件（数据库，编译器，操作系统等）。
一、代码是核心竞争力吗？ 我和一些闭源软件项目的作者聊过，大多数选择闭源的原因不外乎以下几种：
 觉得自己的核心算法非常厉害，不希望竞争对手模仿 担心用户拿到代码，就不给钱了 没有找到或者建立自己的护城河 代码太丑，不好意思开源 怕被人找到 Bug  其中以前三种答案居多，我非常能理解，这些回答也都是非常正当的理由，只是这篇文章我们好好的就事论事的挨个分析一下，对于第四第五个理由，其实我不想过多展开，我们聊聊前两种，先看第一种，我在后边会聊聊第二种。
对于第一种原因，我们再深入思考一下，一般可能有下面两种情况：
 我的核心代码很短，可能是一个很巧妙的算法，或者一套很巧妙的参数 我的工程上的设计和实现得很优秀，系统架构是领先的  ● 对于第一种情况，我一直以来的观点是：如果在同一个行业里面，除非你达到了彻彻底底的人才垄断，那么在一个充分竞争的环境，如果这个问题是一个高价值问题，那么你能想到的短短的 「核心算法」，别人也同样能想得到。天下没有银弹，计算机科学就是在无数种妥协和不完美中寻找平衡的艺术（当然，图灵奖级别的 idea 或者量子计算机这种现象级的东西另说，但是这种机会是很少见的），即使通过闭源创造出短期的垄断优势，但是这个平衡一定会被另一个竞争对手打破，最终也一定会出现一个优质的开源替代品全部吞掉（这个开源事实标准短期看甚至不一定是更好的）。
其实多数的产品优势是体现在工程实现上，也就是上面的第二种，一群优秀的工程师，在正确的设计下，构建出优质的软件。对于这种情况，无论开源还是不开源，竞争对手都没有办法很好的模仿，就像一个学霸，考了一个100分的答卷，把这个答卷给一个学渣看，学渣朋友肯定也没法马上变成学霸，因为代码只是结果，是什么样的思考和选择得到了这个结果，这个过程是没法开放的，所谓知其然不知其所以然，当然，就算你也很厉害，也有一批优秀工程师，短时间也做出了一个不错的产品，但是没关系，结局和前面提到那种情况也是一样的：只要你是闭源的，这个问题又足够普遍且高价值，那么长远来看一定会有一个开源的解决方案吞掉一切。这背后的原因其实和代码没有什么关系，因为代码在这里其实并不是核心竞争力。关于前面提到的第三种理由，我认为是和第一种类似，作者可能认识到代码并不一定是核心竞争力，但是没有构建好护城河的情况下，只能选择将代码作为护城河。
二、代码不是核心竞争力，那什么才是？ 在聊真正的核心竞争力之前，我们来聊聊闭源软件的局限性。
我们看看一个闭源的软件的一生：立项的动机可能是某个公司或者个人对于一个市场机会的洞见找到了一个高价值的场景，通过开发一个软件能够很好的提高效率或创造价值，甚至可能就是一张来自甲方的合同，总之这个公司招募了一伙程序员，设计师，产品经理，开始项目的开发。一切顺利的情况，顺利的满足了甲方的需求，甲方也很开心的付钱了，然后这个公司发现，好像这个软件改一改（甚至不用改）也就能够在同行业另一个客户那边卖出去，这就太好了，感觉找到了一条致富路。可是好境不长，客户这边的场景和需求在变化，原来的软件可能不一定能够满足新的需求了，但是开发团队就这几杆枪，稍有不慎一个方向判断错误，可能时间和机会窗口就错过了。这就意味着，对于项目领头人的要求就很高，要求持续能够引领行业的方向。还有一种方式是挑选一个相对狭窄或迭代不快的领域，存活时间能够延长一些。对于甲方也很难受，总是感觉需求的满足慢半拍，甚至对于有些有着研发能力的甲方，因为受限于没有源码，就算知道如何改进，也只能干瞪眼。
其实这个问题的本质在于：闭源软件开发商虽然可能是技术的专家，但是并不一定是业务或者场景的专家，软件进化的速度受限于开发团队和产品经理自己的认知和见识的进化速度，除非开发商强大到能够持续引领整个行业的进化方向，否则无解。
其实这个问题，教员早就给出了答案：「&amp;hellip;凡属正确的领导，必须是从群众中来，到群众中去。这就是说，将群众的意见（分散的无系统的意见）集中起来（经过研究，化为集中的系统的意见），又到群众中去作宣传解释，化为群众的意见，使群众坚持下去，见之于行动，并在群众行动中考验这些意见是否正确。然后再从群众中集中起来，再到群众中坚持下去，如此无限循环，一次比一次地更正确、更生动、更丰富&amp;hellip;」 &amp;mdash; 《关于领导方法的若干问题》, 1943
要我说教员放在当代，就算是当个程序员，也能是一个大师级别的。教员的这段话，包含两个关键的点，完美的解释了开源软件的生命力的来源，我下面的详细讲讲。
第一点，开源软件的生命力来自于场景的垄断，而背后更本质的垄断是人才垄断。
为什么强调从群众中来？回顾刚才我们闭源软件的那段，其实一个关键的点是，软件的初始动机虽然来自于少数人的洞见，但是持续保持洞见并不是一件容易的事情，这就是为什么很多技术团队或者产品团队容易「自嗨」，一旦脱离用户，极易出现这样的问题。闭源软件厂商触及用户的手段不外乎于传统的商业宣传和销售，用户从感兴趣到使用起来的门槛很高，实施的周期也很长，另外通常销售会站在产品团队和客户中间，通过一些信息不对称来获取超额的利润，其中最大的信息不对称就是封闭的源代码本身或者定制化。这导致的问题是，相比流行的开源软件，闭源软件没有办法高效的获取，吸收和理解更多的场景，这对于一个通用的基础软件产品来说通常是一个致命的问题，如果见过的场景不够多，更没有办法判断产品那些需求该做是普遍需求，哪些是伪需求坚决不做，我认为这就是做产品的「触感」。
对于一个流行的开源软件，本身不会有上面提到的问题：因为有足够多的用户，那么一定能看到足够多的场景，也能看到足够多的稀奇古怪的用法，这一个个用户的反馈，修过的一个个 bug，提出的一个个建议，会持续的产生类似「复利」的效果，你的软件越强壮，见过的场景越广，会进一步让你接触到更大的用户群，帮助软件变得更强大，如此循环。实际上开源软件本质上是通过放弃一部分通过信息不对称产生的潜在利润，换取了极其高效的传播和场景触及效率，但是有意思的是，实际上牺牲掉的这些潜在利润大概率也不一定真的牺牲掉，一来可能本身付费能力有限，二来可能实际上这些用户通过宣传站台二次传播或者代码贡献等方式回馈了项目本身。
在上面那个过程中还会产生一个更加厉害的效应：人才的垄断。正所谓「事在人为」，上面提到的场景垄断中种种的技术决策和实践都是人来操作的。一个流行的开源软件在变成事实标准的过程中，一定会培养出大量熟悉这个产品的工程师，用户，摇旗呐喊的粉丝，代码贡献者，甚至挑刺吐槽的人。传统意义上，大家理解的开源社区只是狭义上的开发者社区，只有贡献代码才算参与，但是我认为只要和这个产品发生关联的人，都算是社区的一部分，「人尽其材」才是构建开源社区的终极目标。这个优势是会随着时间的流逝不断累积，这个很好理解，举个例子：A 公司的工程师在 A 公司的工作中学习使用了 TiDB 也很好的解决了问题，然后这个工程师作为数据库专家跳槽到了 B 公司，遇到同样的问题时，你猜他会选什么？ :)
第二点，迭代，迭代，迭代，只有高速迭代才能立于不败之地
上面教员的话里面有个关键的点，关于正向循环，也就是迭代。这个道理同样也适用于软件开发，软件从来都不是静止的，随着市场和竞争环境的变化，你今天的竞争优势，很可能明天就不是了。很多人都喜欢用静态的眼光看待问题，热衷于各种方案的横向对比，而忽略了进化速度，在这点上，我可能更看重的是同一个产品的纵向对比，举个例子：目前有 A, B, C三个方案，可能当下看这三个方案差距不大，也许在百分之五十之内。但是如果其中一个开源方案每次和自己半年前比都是在翻倍的提升（背后开源社区推动），但是闭源的方案的进步受限于团队规模和资源。这时候的选择除非是那种火烧眉毛的情况，否则一定应该选择一个迭代速度更快，增长率更好，更代表未来的方案，这个也很好理解。这是人的思维的一个惯性，人总是倾向用线性思维去看待问题，于是对非线性增长的事物往往会习惯性的低估。
说一个更加震撼的例子，我粗略统计了一下，从 2018 到现在，也就短短一年多时间，整个 TiDB 的 SQL 层这么一个项目发生了 30000 多次提交，有接近 60% 的源码被修改。也就是说，每一年的 TiDB 都和上一年是不一样的，是一个更适应当下的，更加进步的一个 TiDB，而且随着社区的不断壮大，迭代的速度会越来越快。我完全不能想象，如果 TiDB 是一个闭源软件，从第一行代码开始写，到现在短短的 5 年时间，如何能够到达现在这个成熟度，这一切都是得益于开源社区的带来的加速度和反复迭代。</description>
    </item>
    
    <item>
      <title>In Community We Trust</title>
      <link>http://c4pt0r.github.io/posts/in-community-we-trust/</link>
      <pubDate>Fri, 03 Dec 2021 12:09:52 +0800</pubDate>
      
      <guid>http://c4pt0r.github.io/posts/in-community-we-trust/</guid>
      <description>前些天在与友人喝咖啡的时候，正好聊到关于 PingCAP 和 TiDB 的一些历史以及对于开源软件公司核心竞争力的理解，回顾这几年的创业生涯和 TiDB 社区的生长壮大，就像是一场巨大且正在进行中的社会学实验，原本零散的一些想法随着一条主线变得逐渐清晰，就想着写成文章总结一下关于社区对于开源软件以及开源公司到底意味着什么。
无处不在的网络效应 两种网络效应
很多人听说过网络效应（梅特卡夫效应：网络的价值与联网用户的平方数成正比），许多伟大的产品和公司通过网络效应构建起了强大的护城河。提到网络效应，经典例子在通信领域，例如手机，每多一个用户，对于所有用户的价值就越大，虽然大家也无意为他人创造价值，但是一旦开始使用，该行为就会帮助这个网络创造价值。很多我们熟知的 to C公司，尤其是社交网络和IM（即时通信软件） ，通过这个效应构建了极高的壁垒。NfX Venture 在他们的一篇博客(https://www.nfx.com/post/network-effects-manual/）中详细描述了很多种网络效应，在介绍社区之前，我想着重介绍下其中和开源软件相关的两种网络效应。
 基于从众心理的网络效应  这类网络效应通常是从一些意见领袖开始，可能是行业大咖，可能是社交潮人，常常出现在一个新产品要去进攻一个老产品的市场时。尽管这个新产品相比市场的统治者来说不一定成熟，但它通常会带着一些鲜明的特色或者更加前沿的理念，吸引那些对「主流」不满或者希望突显自身前沿视野的意见领袖的支持，造成一种「很酷的人都在用，你不用你就要被淘汰了」的感觉。
这种感觉会在新用户纷纷加入时，形成从众心理的网络效应，但是**这类网络效应的持续时间不会太长。**细想一下就能知道：如果早期意见领袖只是因为突显「不同」而加入，那么在这个社区成为主流后，这些意见领袖就没有理由留下，追随这些人的粉丝可能会随之而去。另外，对于这个新产品来说，完善程度通常不如老产品，美誉和差评会在早期同时到来。此时，如果不快速通过网络效应打磨产品，获得更好的迭代速度，那么，这个网络效应是根基不牢的。一个好处在于，该效应在早期是事半功倍的。
回想 TiDB 早期的社区建设，也是因为几个创始人在 Codis 的工作以及在国内基础软件圈中积累的名声，和一些互联网技术圈中朋友的支持，形成最早的背书。
 基于信仰的网络效应  **所谓「信仰」，就是基于对一个理念的认可而加入，从而形成网络效应。**这点在软件领域也不少见，自由软件运动和开源运动都是很好的例子。人嘛，总是要相信点什么。**这类网络效应的护城河是极深的，而且对于产品缺陷的容忍度极高。**因为信念是一个长期的念想，对于 TiDB 来说，这个念想形如：相信分布式是未来，相信云时代的业务需要像 TiDB 这样的数据库。但是这个目标又是足够有挑战的，值得长期为之努力。
基于信仰的网络效应可能在最早期和从众心理网络效应有点类似，其中的关键是社区核心人群对于产品背后的理念是否有坚定信仰。反之，如果只是简单地秀优越感，是不会长久的，随着兴趣衰减，网络效应也会崩塌。
网络效应对于基础软件的意义
对于基础软件来说，我一直坚持两个观点：
 基础软件是被“用”出来的，不是“写”出来的。 迭代和进化速度是这类软件的核心竞争力。  这两点恰恰是网络效应能带来的，虽然价值链条不像IM那样明显，但是，网络效应存在的基础是新用户给老用户带来的额外价值。而基础软件的价值，体现为以下几点：
 可控的风险（稳定性） 更多的场景适应性（发现新的适用场景和持续提升性能） 良好的易用性  对于风险控制来说，越多人用意味着风险被越多人均摊，其中的一个假设是：我不特别，我遇到的问题别人应该也遇到过，一定有人能比我早发现并修复它。这个假设在一个成熟且活跃的基础软件社区是成立的，因为基础软件的场景边界相对清晰，在适用范围内的路径大致相同，同一条路径走多了，坑自然就少了。只要有一个人踩到坑，反馈回社区，不管最后是谁修好的，这个行为对于其他用户都是受益的。
同样的逻辑，对于场景适应性来说也成立。个体的认知总是带有局限性，即使是项目的创始团队，也不见得对于某个具体的应用场景有深刻理解。社区用户的创造力是无穷的，一些设计外的使用路径可能会出奇地好用，从而发展出新的优势场景。同样地，只要有一个成功案例，那么对于其他具有相似场景的用户来说，软件的价值就增加了， TiDB 和 Flink 组合成的实时 HTAP 数据处理方案，就是一个很好的例子。
对于易用性改进的逻辑和稳定性类似，我就不赘述了。利用网络效应带来的飞轮效应改进软件，这个思路我在《大教堂终将倒下，但集市永存》一文中也提到过。
社区的成熟度曲线和必经阶段 社区的诞生
在 GitHub 上开放你的源代码，甚至使用公开的 Git 工作流，都不是社区诞生的时刻。一个社区真正诞生，是在你和你的代码之外，开始有第三者介入并产生连接的时刻，可能是收到第一个外部 PR，可能是收到第一个外部 issue，这些才是社区的开端。社区始于连接，也成就于连接。开放源代码并不等同于开源，很多团队和项目在开放源代码方面花费了很多时间，却忽略了代码及背后团队的社区化，这是很可惜的。
死亡鸿沟和希望之坡
就像《跨越鸿沟》这本书中提到的，开源软件也有自己的生命周期曲线，这是和社区息息相关的。
图中断层出现的原因是产品成熟度迟迟没有跟上，用户过来以后发现都是坑，随之而来的各种差评会让早期支持者和创始人疲于奔命甚至而失去兴趣。
**对于一个开源软件，断层的体现可能是经历早期快速增长后，来到长达 1~2 年的静默期，增长几乎停滞。**对于社区来说，几乎所有的精力都用在给早期用户填坑，期间会有用户自然增长但流失率也非常高。这个阶段对于资源的消耗非常大，社区的核心贡献者也会非常累，如果熬不过去就死了，所以说是“死亡鸿沟”。</description>
    </item>
    
  </channel>
</rss>
